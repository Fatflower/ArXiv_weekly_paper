1. [Mamba State-Space Models Can Be Strong Downstream Learners](https://arxiv.org/abs/2406.00209)
2. [A Survey of Deep Learning Audio Generation Methods](https://arxiv.org/abs/2406.00146)
3. [Anomaly Detection in Dynamic Graphs: A Comprehensive Survey](https://arxiv.org/abs/2406.00134)
4. [Dual Process Learning: Controlling Use of In-Context vs. In-Weights Strategies with Weight Forgetting](https://arxiv.org/abs/2406.00053)
5. [LocMoE+: Enhanced Router with Token Feature Awareness for Efficient LLM Pre-Training](https://arxiv.org/abs/2406.00023)
6. [An Early Investigation into the Utility of Multimodal Large Language Models in Medical Imaging](https://arxiv.org/abs/2406.00667)
7. [Dual Hyperspectral Mamba for Efficient Spectral Compressive Imaging](https://arxiv.org/abs/2406.00449)
8. [Hybrid attention structure preserving network for reconstruction of under-sampled OCT images](https://arxiv.org/abs/2406.00279)
9. [A Comparative Study of CNN, ResNet, and Vision Transformers for Multi-Classification of Chest Diseases](https://arxiv.org/abs/2406.00237)
10. [Generalization Beyond Data Imbalance: A Controlled Study on CLIP for Transferable Insights](https://arxiv.org/abs/2405.21070)
11. [Spectrum-Aware Parameter Efficient Fine-Tuning for Diffusion Models](https://arxiv.org/abs/2405.21050)
12. [A-PETE: Adaptive Prototype Explanations of Tree Ensembles](https://arxiv.org/abs/2405.21036)
13. [Hard Cases Detection in Motion Prediction by Vision-Language Foundation Models](https://arxiv.org/abs/2405.20991)
14. [Ovis: Structural Embedding Alignment for Multimodal Large Language Model](https://arxiv.org/abs/2405.20797)
15. [Information Theoretic Text-to-Image Alignment](https://arxiv.org/abs/2405.20759)
16. [Language Augmentation in CLIP for Improved Anatomy Detection on Multi-modal Medical Images](https://arxiv.org/abs/2405.20735)
17. [GenMix: Combining Generative and Mixture Data Augmentation for Medical Image Classification](https://arxiv.org/abs/2405.20650)
18. [Large Language Models Enhanced Sequential Recommendation for Long-tail User and Item](https://arxiv.org/abs/2405.20646)
19. ["Forgetting" in Machine Learning and Beyond: A Survey](https://arxiv.org/abs/2405.20620)
20. [Textual Inversion and Self-supervised Refinement for Radiology Report Generation](https://arxiv.org/abs/2405.20607)
21. [SimSAM: Zero-shot Medical Image Segmentation via Simulated Interaction](https://arxiv.org/abs/2406.00663)
22. [Ultrasound Report Generation with Cross-Modality Feature Alignment via Unsupervised Guidance](https://arxiv.org/abs/2406.00644)
23. [Transforming Computer Security and Public Trust Through the Exploration of Fine-Tuning Large Language Models](https://arxiv.org/abs/2406.00628)
24. [LLMs Could Autonomously Learn Without External Supervision](https://arxiv.org/abs/2406.00606)
25. [Memory-guided Network with Uncertainty-based Feature Augmentation for Few-shot Semantic Segmentation](https://arxiv.org/abs/2406.00545)
26. [Breast Cancer Diagnosis: A Comprehensive Exploration of Explainable Artificial Intelligence (XAI) Techniques](https://arxiv.org/abs/2406.00532)
27. [On the Use of Anchoring for Training Vision Models](https://arxiv.org/abs/2406.00529)
28. [Learning Background Prompts to Discover Implicit Knowledge for Open Vocabulary Object Detection](https://arxiv.org/abs/2406.00510)
29. [Posterior Label Smoothing for Node Classification](https://arxiv.org/abs/2406.00410)
30. [DeCoOp: Robust Prompt Tuning with Out-of-Distribution Detection](https://arxiv.org/abs/2406.00345)
31. [Less is More: Pseudo-Label Filtering for Continual Test-Time Adaptation](https://arxiv.org/abs/2406.02609)
32. [Computation-Efficient Era: A Comprehensive Survey of State Space Models in Medical Image Analysis](https://arxiv.org/abs/2406.03430)
33. [Multi-Task Multi-Scale Contrastive Knowledge Distillation for Efficient Medical Image Segmentation](https://arxiv.org/abs/2406.03173)
34. [Leveraging Visual Tokens for Extended Text Contexts in Multi-Modal Learning](https://arxiv.org/abs/2406.02547)
35. [To Believe or Not to Believe Your LLM](https://arxiv.org/abs/2406.02543)
36. [Parrot: Multilingual Visual Instruction Tuning](https://arxiv.org/abs/2406.02539)
37. [Generative Active Learning for Long-tailed Instance Segmentation](https://arxiv.org/abs/2406.02435)
38. [Harnessing Neural Unit Dynamics for Effective and Scalable Class-Incremental Learning](https://arxiv.org/abs/2406.02428)
39. [Flash Diffusion: Accelerating Any Conditional Diffusion Model for Few Steps Image Generation](https://arxiv.org/abs/2406.02347)
40. [Continual Unsupervised Out-of-Distribution Detection](https://arxiv.org/abs/2406.02327)
41. [Can CLIP help CLIP in learning 3D?](https://arxiv.org/abs/2406.02202)
42. [Enhance Image-to-Image Generation with LLaVA Prompt and Negative Prompt](https://arxiv.org/abs/2406.01956)
43. [An Empirical Study of Excitation and Aggregation Design Adaptions in CLIP4Clip for Video-Text Retrieval](https://arxiv.org/abs/2406.01604)
44. [Fairness Evolution in Continual Learning for Medical Imaging](https://arxiv.org/abs/2406.02480)
45. [Decomposing and Interpreting Image Representations via Text in ViTs Beyond CLIP](https://arxiv.org/abs/2406.01583)
46. [Long and Short Guidance in Score identity Distillation for One-Step Text-to-Image Generation](https://arxiv.org/abs/2406.01561)
47. [ED-SAM: An Efficient Diffusion Sampling Approach to Domain Generalization in Vision-Language Foundation Models](https://arxiv.org/abs/2406.01432)
48. [FreeTumor: Advance Tumor Segmentation via Large-Scale Tumor Synthesis](https://arxiv.org/abs/2406.01264)
49. [GeminiFusion: Efficient Pixel-wise Multimodal Fusion for Vision Transformer](https://arxiv.org/abs/2406.01210)
50. [Scaling Up Deep Clustering Methods Beyond ImageNet-1K](https://arxiv.org/abs/2406.01203)
51. [Zero-Shot Out-of-Distribution Detection with Outlier Label Exposure](https://arxiv.org/abs/2406.01170)
52. [MultiEdits: Simultaneous Multi-Aspect Editing with Text-to-Image Diffusion Models](https://arxiv.org/abs/2406.00985)
53. [Navigating Conflicting Views: Harnessing Trust for Learning](https://arxiv.org/abs/2406.00958)
54. [Improving Segment Anything on the Fly: Auxiliary Online Learning and Adaptive Fusion for Medical Image Segmentation](https://arxiv.org/abs/2406.00956)
55. [A Survey of Useful LLM Evaluation](https://arxiv.org/abs/2406.00936)
56. [Envisioning Outlier Exposure by Large Language Models for Out-of-Distribution Detection](https://arxiv.org/abs/2406.00806)
57. [Task-oriented Embedding Counts: Heuristic Clustering-driven Feature Fine-tuning for Whole Slide Image Classification](https://arxiv.org/abs/2406.00672)
58. [Cascade-CLIP: Cascaded Vision-Language Embeddings Alignment for Zero-Shot Semantic Segmentation](https://arxiv.org/abs/2406.00670)
59. [Sample-specific Masks for Visual Reprogramming-based Prompting](https://arxiv.org/abs/2406.03150)
60. [Tiny models from tiny data: Textual and null-text inversion for few-shot distillation](https://arxiv.org/abs/2406.03146)
61. [Continual Traffic Forecasting via Mixture of Experts](https://arxiv.org/abs/2406.03140)
62. [Decision Boundary-aware Knowledge Consolidation Generates Better Instance-Incremental Learner](https://arxiv.org/abs/2406.03065)
63. [Visual-Text Cross Alignment: Refining the Similarity Score in Vision-Language Models](https://arxiv.org/abs/2406.02915)
64. [Choice of PEFT Technique in Continual Learning: Prompt Tuning is Not All You Need](https://arxiv.org/abs/2406.03216)
65. [Interactive Text-to-Image Retrieval with Large Language Models: A Plug-and-Play Approach](https://arxiv.org/abs/2406.03411)
66. [Noisy Data Visualization using Functional Data Analysis](https://arxiv.org/abs/2406.03396)
67. [Learning Visual Prompts for Guiding the Attention of Vision Transformers](https://arxiv.org/abs/2406.03303)
68. [Verbalized Machine Learning: Revisiting Machine Learning with Language Models](https://arxiv.org/abs/2406.04344)
69. [Coarse-To-Fine Tensor Trains for Compact Visual Representations](https://arxiv.org/abs/2406.04332)
70. [The Brain's Bitter Lesson: Scaling Speech Decoding With Self-Supervised Learning](https://arxiv.org/abs/2406.04328)
71. [Semantically Diverse Language Generation for Uncertainty Estimation in Language Models](https://arxiv.org/abs/2406.04306)
72. [Vision-LSTM: xLSTM as Generic Vision Backbone](https://arxiv.org/abs/2406.04303)
73. [What is Dataset Distillation Learning?](https://arxiv.org/abs/2406.04284)
74. [Generative AI-in-the-loop: Integrating LLMs and GPTs into the Next Generation Networks](https://arxiv.org/abs/2406.04276)
75. [Matching Anything by Segmenting Anything](https://arxiv.org/abs/2406.04221)
76. [CDMamba: Remote Sensing Image Change Detection with Mamba](https://arxiv.org/abs/2406.04207)
77. [Zero-Painter: Training-Free Layout Control for Text-to-Image Synthesis](https://arxiv.org/abs/2406.04032)
78. [Jailbreak Vision Language Models via Bi-Modal Adversarial Prompt](https://arxiv.org/abs/2406.04031)
79. [Frequency-based Matcher for Long-tailed Semantic Segmentation](https://arxiv.org/abs/2406.03917)
80. [BLSP-Emo: Towards Empathetic Large Speech-Language Models](https://arxiv.org/abs/2406.03872)
81. [Low-Rank Similarity Mining for Multimodal Dataset Distillation](https://arxiv.org/abs/2406.03793)
82. [Light-PEFT: Lightening Parameter-Efficient Fine-Tuning via Early Pruning](https://arxiv.org/abs/2406.03792)
83. [FastGAS: Fast Graph-based Annotation Selection for In-Context Learning](https://arxiv.org/abs/2406.03730)
84. [Is Free Self-Alignment Possible?](https://arxiv.org/abs/2406.03642)
85. [CountCLIP -- [Re](https://arxiv.org/abs/2406.03586)
86. [LLMs Meet Multimodal Generation and Editing: A Survey](https://arxiv.org/abs/2405.19334)
87. [C^2RV: Cross-Regional and Cross-View Learning for Sparse-View CBCT Reconstruction](https://arxiv.org/abs/2406.03902)
88. [Synthetic Oversampling: Theory and A Practical Approach Using LLMs to Address Data Imbalance](https://arxiv.org/abs/2406.03628)
89. [Wings: Learning Multimodal LLMs without Text-only Forgetting](https://arxiv.org/abs/2406.03496)
90. [LW-DETR: A Transformer Replacement to YOLO for Real-Time Detection](https://arxiv.org/abs/2406.03459)
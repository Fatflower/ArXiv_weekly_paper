1. [DEPICT: Diffusion-Enabled Permutation Importance for Image Classification Tasks](https://arxiv.org/abs/2407.14509)
2. [Enhancing Layout Hotspot Detection Efficiency with YOLOv8 and PCA-Guided Augmentation](https://arxiv.org/abs/2407.14498)
3. [Controllable and Efficient Multi-Class Pathology Nuclei Data Augmentation using Text-Conditioned Diffusion Models](https://arxiv.org/abs/2407.14426)
4. [DEAL: Disentangle and Localize Concept-level Explanations for VLMs](https://arxiv.org/abs/2407.14412)
5. [Enhancing Zero-shot Audio Classification using Sound Attribute Knowledge from Large Language Models](https://arxiv.org/abs/2407.14355)
6. [As Generative Models Improve, People Adapt Their Prompts](https://arxiv.org/abs/2407.14333)
7. [Dyn-Adapter: Towards Disentangled Representation for Efficient Visual Recognition](https://arxiv.org/abs/2407.14302)
8. [An Attention-based Representation Distillation Baseline for Multi-Label Continual Learning](https://arxiv.org/abs/2407.14249)
9. [EVLM: An Efficient Vision-Language Model for Visual Understanding](https://arxiv.org/abs/2407.14177)
10. [Rethinking Visual Content Refinement in Low-Shot CLIP Adaptation](https://arxiv.org/abs/2407.14117)
11. [PASS++: A Dual Bias Reduction Framework for Non-Exemplar Class-Incremental Learning](https://arxiv.org/abs/2407.14029)
12. [Continual Learning for Remote Physiological Measurement: Minimize Forgetting and Simplify Inference](https://arxiv.org/abs/2407.13974)
13. [Continual Distillation Learning](https://arxiv.org/abs/2407.13911)
14. [ESP-MedSAM: Efficient Self-Prompting SAM for Universal Domain-Generalized Medical Image Segmentation](https://arxiv.org/abs/2407.14153)
15. [Early Preparation Pays Off: New Classifier Pre-tuning for Class Incremental Semantic Segmentation](https://arxiv.org/abs/2407.14142)
16. [CoAPT: Context Attribute words for Prompt Tuning](https://arxiv.org/abs/2407.13808)
17. [AdaCLIP: Adapting CLIP with Hybrid Learnable Prompts for Zero-Shot Anomaly Detection](https://arxiv.org/abs/2407.15795)
18. [CLIP with Generative Latent Replay: a Strong Baseline for Incremental Learning](https://arxiv.org/abs/2407.15793)
19. [Zero-Shot Embeddings Inform Learning and Forgetting with Vision-Language Encoders](https://arxiv.org/abs/2407.15731)
20. [SETTP: Style Extraction and Tunable Inference via Dual-level Transferable Prompt Learning](https://arxiv.org/abs/2407.15556)
21. [Pre-Training and Prompting for Few-Shot Node Classification on Text-Attributed Graphs](https://arxiv.org/abs/2407.15431)
22. [Enhancing Retinal Disease Classification from OCTA Images via Active Learning Techniques](https://arxiv.org/abs/2407.15293)
23. [D$^4$M: Dataset Distillation via Disentangled Diffusion Model](https://arxiv.org/abs/2407.15138)
24. [CBCTLiTS: A Synthetic, Paired CBCT/CT Dataset For Segmentation And Style Transfer](https://arxiv.org/abs/2407.14853)
25. [FairViT: Fair Vision Transformer via Adaptive Masking](https://arxiv.org/abs/2407.14799)
26. [Compact Language Models via Pruning and Knowledge Distillation](https://arxiv.org/abs/2407.14679)
27. [On Learning Discriminative Features from Synthesized Data for Self-Supervised Fine-Grained Visual Recognition](https://arxiv.org/abs/2407.14676)
28. [Learning Visual Grounding from Generative Vision and Language Model](https://arxiv.org/abs/2407.14563)
29. [Addressing Imbalance for Class Incremental Learning in Medical Image Classification](https://arxiv.org/abs/2407.13768)
30. [Aggregated Attributions for Explanatory Analysis of 3D Segmentation Models](https://arxiv.org/abs/2407.16653)
31. [Imperfect Vision Encoders: Efficient and Robust Tuning for Vision-Language Models](https://arxiv.org/abs/2407.16526)
32. [Navigating Uncertainty in Medical Image Segmentation](https://arxiv.org/abs/2407.16367)
33. [Optimizing Robotic Manipulation with Decision-RWKV: A Recurrent Sequence Modeling Approach for Lifelong Learning](https://arxiv.org/abs/2407.16306)
34. [Multimodal Unlearnable Examples: Protecting Data against Multimodal Contrastive Learning](https://arxiv.org/abs/2407.16307)
35. [HSVLT: Hierarchical Scale-Aware Vision-Language Transformer for Multi-Label Image Classification](https://arxiv.org/abs/2407.16244)
36. [A Survey of Explainable Artificial Intelligence (XAI) in Financial Time Series Forecasting](https://arxiv.org/abs/2407.15909)
37. [Craft: Cross-modal Aligned Features Improve Robustness of Prompt Tuning](https://arxiv.org/abs/2407.15894)
38. [A Survey on Trustworthiness in Foundation Models for Medical Image Analysis](https://arxiv.org/abs/2407.15851)
39. [Towards Latent Masked Image Modeling for Self-Supervised Visual Representation Learning](https://arxiv.org/abs/2407.15837)
40. [AbdomenAtlas: A Large-Scale, Detailed-Annotated, & Multi-Center Dataset for Efficient Transfer Learning and Open Algorithmic Benchmarking](https://arxiv.org/abs/2407.16697)
41. [SAM-CP: Marrying SAM with Composable Prompts for Versatile Segmentation](https://arxiv.org/abs/2407.16682)
1. [DEPICT: Diffusion-Enabled Permutation Importance for Image Classification Tasks](https://arxiv.org/abs/2407.14509)
2. [Enhancing Layout Hotspot Detection Efficiency with YOLOv8 and PCA-Guided Augmentation](https://arxiv.org/abs/2407.14498)
3. [Controllable and Efficient Multi-Class Pathology Nuclei Data Augmentation using Text-Conditioned Diffusion Models](https://arxiv.org/abs/2407.14426)
4. [DEAL: Disentangle and Localize Concept-level Explanations for VLMs](https://arxiv.org/abs/2407.14412)
5. [Enhancing Zero-shot Audio Classification using Sound Attribute Knowledge from Large Language Models](https://arxiv.org/abs/2407.14355)
6. [As Generative Models Improve, People Adapt Their Prompts](https://arxiv.org/abs/2407.14333)
7. [Dyn-Adapter: Towards Disentangled Representation for Efficient Visual Recognition](https://arxiv.org/abs/2407.14302)
8. [An Attention-based Representation Distillation Baseline for Multi-Label Continual Learning](https://arxiv.org/abs/2407.14249)
9. [EVLM: An Efficient Vision-Language Model for Visual Understanding](https://arxiv.org/abs/2407.14177)
10. [Rethinking Visual Content Refinement in Low-Shot CLIP Adaptation](https://arxiv.org/abs/2407.14117)
11. [PASS++: A Dual Bias Reduction Framework for Non-Exemplar Class-Incremental Learning](https://arxiv.org/abs/2407.14029)
12. [Continual Learning for Remote Physiological Measurement: Minimize Forgetting and Simplify Inference](https://arxiv.org/abs/2407.13974)
13. [Continual Distillation Learning](https://arxiv.org/abs/2407.13911)
14. [ESP-MedSAM: Efficient Self-Prompting SAM for Universal Domain-Generalized Medical Image Segmentation](https://arxiv.org/abs/2407.14153)
15. [Early Preparation Pays Off: New Classifier Pre-tuning for Class Incremental Semantic Segmentation](https://arxiv.org/abs/2407.14142)
16. [CoAPT: Context Attribute words for Prompt Tuning](https://arxiv.org/abs/2407.13808)
17. [AdaCLIP: Adapting CLIP with Hybrid Learnable Prompts for Zero-Shot Anomaly Detection](https://arxiv.org/abs/2407.15795)
18. [CLIP with Generative Latent Replay: a Strong Baseline for Incremental Learning](https://arxiv.org/abs/2407.15793)
19. [Zero-Shot Embeddings Inform Learning and Forgetting with Vision-Language Encoders](https://arxiv.org/abs/2407.15731)
20. [SETTP: Style Extraction and Tunable Inference via Dual-level Transferable Prompt Learning](https://arxiv.org/abs/2407.15556)
21. [Pre-Training and Prompting for Few-Shot Node Classification on Text-Attributed Graphs](https://arxiv.org/abs/2407.15431)
22. [Enhancing Retinal Disease Classification from OCTA Images via Active Learning Techniques](https://arxiv.org/abs/2407.15293)
23. [D$^4$M: Dataset Distillation via Disentangled Diffusion Model](https://arxiv.org/abs/2407.15138)
24. [CBCTLiTS: A Synthetic, Paired CBCT/CT Dataset For Segmentation And Style Transfer](https://arxiv.org/abs/2407.14853)
25. [FairViT: Fair Vision Transformer via Adaptive Masking](https://arxiv.org/abs/2407.14799)
26. [Compact Language Models via Pruning and Knowledge Distillation](https://arxiv.org/abs/2407.14679)
27. [On Learning Discriminative Features from Synthesized Data for Self-Supervised Fine-Grained Visual Recognition](https://arxiv.org/abs/2407.14676)
28. [Learning Visual Grounding from Generative Vision and Language Model](https://arxiv.org/abs/2407.14563)
29. [Addressing Imbalance for Class Incremental Learning in Medical Image Classification](https://arxiv.org/abs/2407.13768)
30. [Aggregated Attributions for Explanatory Analysis of 3D Segmentation Models](https://arxiv.org/abs/2407.16653)
31. [Imperfect Vision Encoders: Efficient and Robust Tuning for Vision-Language Models](https://arxiv.org/abs/2407.16526)
32. [Navigating Uncertainty in Medical Image Segmentation](https://arxiv.org/abs/2407.16367)
33. [Optimizing Robotic Manipulation with Decision-RWKV: A Recurrent Sequence Modeling Approach for Lifelong Learning](https://arxiv.org/abs/2407.16306)
34. [Multimodal Unlearnable Examples: Protecting Data against Multimodal Contrastive Learning](https://arxiv.org/abs/2407.16307)
35. [HSVLT: Hierarchical Scale-Aware Vision-Language Transformer for Multi-Label Image Classification](https://arxiv.org/abs/2407.16244)
36. [A Survey of Explainable Artificial Intelligence (XAI) in Financial Time Series Forecasting](https://arxiv.org/abs/2407.15909)
37. [Craft: Cross-modal Aligned Features Improve Robustness of Prompt Tuning](https://arxiv.org/abs/2407.15894)
38. [A Survey on Trustworthiness in Foundation Models for Medical Image Analysis](https://arxiv.org/abs/2407.15851)
39. [Towards Latent Masked Image Modeling for Self-Supervised Visual Representation Learning](https://arxiv.org/abs/2407.15837)
40. [AbdomenAtlas: A Large-Scale, Detailed-Annotated, & Multi-Center Dataset for Efficient Transfer Learning and Open Algorithmic Benchmarking](https://arxiv.org/abs/2407.16697)
41. [SAM-CP: Marrying SAM with Composable Prompts for Versatile Segmentation](https://arxiv.org/abs/2407.16682)
42. [CMR Scaling Law: Predicting Critical Mixture Ratios for Continual Pre-training of Language Models](https://arxiv.org/abs/2407.17467)
43. [Scalify: scale propagation for efficient low-precision LLM training](https://arxiv.org/abs/2407.17353)
44. [Multi-label Cluster Discrimination for Visual Representation Learning](https://arxiv.org/abs/2407.17331)
45. [Embedding-Free Transformer with Inference Spatial Reduction for Efficient Semantic Segmentation](https://arxiv.org/abs/2407.17261)
46. [Graph Neural Networks: A suitable Alternative to MLPs in Latent 3D Medical Image Classification?](https://arxiv.org/abs/2407.17219)
47. [When Text and Images Don't Mix: Bias-Correcting Language-Image Similarity Scores for Anomaly Detection](https://arxiv.org/abs/2407.17083)
48. [High Efficiency Image Compression for Large Visual-Language Models](https://arxiv.org/abs/2407.17060)
49. [Selective Vision-Language Subspace Projection for Few-shot CLIP](https://arxiv.org/abs/2407.16977)
50. [Open Challenges on Fairness of Artificial Intelligence in Medical Imaging Applications](https://arxiv.org/abs/2407.16953)
51. [Automatic Categorization of GitHub Actions with Transformers and Few-shot Learning](https://arxiv.org/abs/2407.16946)
52. [Train-Attention: Meta-Learning Where to Focus in Continual Knowledge Learning](https://arxiv.org/abs/2407.16920)
53. [SINDER: Repairing the Singular Defects of DINOv2](https://arxiv.org/abs/2407.16826)
54. [LoRA-Pro: Are Low-Rank Adapters Properly Optimized?](https://arxiv.org/abs/2407.18242)
55. [Automated Ensemble Multimodal Machine Learning for Healthcare](https://arxiv.org/abs/2407.18227)
56. [DINOv2 Rocks Geological Image Analysis: Classification, Segmentation, and Interpretability](https://arxiv.org/abs/2407.18100)
57. [PEFT-U: Parameter-Efficient Fine-Tuning for User Personalization](https://arxiv.org/abs/2407.18078)
58. [How to Train the Teacher Model for Effective Knowledge Distillation](https://arxiv.org/abs/2407.18041)
59. [Keep the Cost Down: A Review on Methods to Optimize LLM' s KV-Cache Consumption](https://arxiv.org/abs/2407.18003)
60. [Unified Lexical Representation for Interpretable Visual-Language Alignment](https://arxiv.org/abs/2407.17827)
61. [NC-NCD: Novel Class Discovery for Node Classification](https://arxiv.org/abs/2407.17816)
62. [Cost-effective Instruction Learning for Pathology Vision and Language Analysis](https://arxiv.org/abs/2407.17734)
63. [Revisiting Machine Unlearning with Dimensional Alignment](https://arxiv.org/abs/2407.17710)
64. [SAM-MIL: A Spatial Contextual Aware Multiple Instance Learning Approach for Whole Slide Image Classification](https://arxiv.org/abs/2407.17689)
65. [Robust Adaptation of Foundation Models with Black-Box Visual Prompting](https://arxiv.org/abs/2407.17491)
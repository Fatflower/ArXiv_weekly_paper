1. [FaBERT: Pre-training BERT on Persian Blogs](https://arxiv.org/abs/2402.06617)
2. [More than the Sum of Its Parts: Ensembling Backbone Networks for Few-Shot Segmentation](https://arxiv.org/abs/2402.06581)
3. [Diffusion-ES: Gradient-free Planning with Diffusion for Autonomous Driving and Zero-Shot Instruction Following](https://arxiv.org/abs/2402.06559)
4. [Bryndza at ClimateActivism 2024: Stance, Target and Hate Event Detection via Retrieval-Augmented GPT-4 and LLaMA](https://arxiv.org/abs/2402.06549)
5. [Calibrating Long-form Generations from Large Language Models](https://arxiv.org/abs/2402.06544)
6. [Feature Density Estimation for Out-of-Distribution Detection via Normalizing Flows](https://arxiv.org/abs/2402.06537)
7. [Refining Myocardial Infarction Detection: A Novel Multi-Modal Composite Kernel Strategy in One-Class Classification](https://arxiv.org/abs/2402.06530)
8. [BarlowTwins-CXR : Enhancing Chest X-Ray abnormality localization in heterogeneous data with cross-domain self-supervised learning](https://arxiv.org/abs/2402.06499)
9. [Iris-SAM: Iris Segmentation Using a Foundational Model](https://arxiv.org/abs/2402.06497)
10. [Large Language Models for Captioning and Retrieving Remote Sensing Images](https://arxiv.org/abs/2402.06475)
11. [Where is the Truth? The Risk of Getting Confounded in a Continual World](https://arxiv.org/abs/2402.06434)
12. [Continual Learning on Graphs: A Survey](https://arxiv.org/abs/2402.06330)
13. [Taking Class Imbalance Into Account in Open Set Recognition Evaluation](https://arxiv.org/abs/2402.06331)
14. [A Unified Causal View of Instruction Tuning](https://arxiv.org/abs/2402.06220)
15. [ViGoR: Improving Visual Grounding of Large Vision Language Models with Fine-Grained Reward Modeling](https://arxiv.org/abs/2402.06118)
16. [Rethinking Data Selection for Supervised Fine-Tuning](https://arxiv.org/abs/2402.06094)
17. [Exploring Visual Culture Awareness in GPT-4V: A Comprehensive Probing](https://arxiv.org/abs/2402.06015)
18. [A Survey on Transformer Compression](https://arxiv.org/abs/2402.05964)
19. [EasyFS: an Efficient Model-free Feature Selection Framework via Elastic Transformation of Features](https://arxiv.org/abs/2402.05954)
20. [FAST: Factorizable Attention for Speeding up Transformers](https://arxiv.org/abs/2402.07901)
21. [Label-Efficient Model Selection for Text Generation](https://arxiv.org/abs/2402.07891)
22. [Scaling Laws for Fine-Grained Mixture of Experts](https://arxiv.org/abs/2402.07871)
23. [Prismatic VLMs: Investigating the Design Space of Visually-Conditioned Language Models](https://arxiv.org/abs/2402.07865)
24. [On Computationally Efficient Multi-Class Calibration](https://arxiv.org/abs/2402.07821)
25. [Multi-Intent Attribute-Aware Text Matching in Searching](https://arxiv.org/abs/2402.07788)
26. [HYPO: Hyperspherical Out-of-Distribution Generalization](https://arxiv.org/abs/2402.07785)
27. [Complete Instances Mining for Weakly Supervised Instance Segmentation](https://arxiv.org/abs/2402.07633)
28. [SLIT: Boosting Audio-Text Pre-Training via Multi-Stage Learning and Instruction Tuning](https://arxiv.org/abs/2402.07485)
29. [A Closer Look at the Robustness of Contrastive Language-Image Pre-Training (CLIP)](https://arxiv.org/abs/2402.07410)
30. [Make it more specific: A novel uncertainty based airway segmentation application on 3D U-Net and its variants](https://arxiv.org/abs/2402.07403)
31. [Deep Learning for Medical Image Segmentation with Imprecise Annotation](https://arxiv.org/abs/2402.07330)
32. [The Bias of Harmful Label Associations in Vision-Language Models](https://arxiv.org/abs/2402.07329)
33. [TransGPT: Multi-modal Generative Pre-trained Transformer for Transportation](https://arxiv.org/abs/2402.07233)
34. [A novel spatial-frequency domain network for zero-shot incremental learning](https://arxiv.org/abs/2402.07216)
35. [3D Gaussian as a New Vision Era: A Survey](https://arxiv.org/abs/2402.07181)
36. [Two-Stage Multi-task Self-Supervised Learning for Medical Image Segmentation](https://arxiv.org/abs/2402.07119)
37. [SpeechCLIP+: Self-supervised multi-task representation learning for speech via CLIP and speech-image data](https://arxiv.org/abs/2402.06959)
38. [Assessing Uncertainty Estimation Methods for 3D Image Segmentation under Distribution Shifts](https://arxiv.org/abs/2402.06937)
39. [ChemLLM: A Chemical Large Language Model](https://arxiv.org/abs/2402.06852)
40. [Reasoning Grasping via Multimodal Large Language Model](https://arxiv.org/abs/2402.06798)
41. [Private Knowledge Sharing in Distributed Learning: A Survey](https://arxiv.org/abs/2402.06682)
42. [Comparative Analysis of ImageNet Pre-Trained Deep Learning Models and DINOv2 in Medical Imaging Classification](https://arxiv.org/abs/2402.07595)
43. [Re-DiffiNet: Modeling discrepancies in tumor segmentation using diffusion](https://arxiv.org/abs/2402.07354)
44. [Semi-Mamba-UNet: Pixel-Level Contrastive Cross-Supervised Visual Mamba-based UNet for Semi-Supervised Medical Image Segmentation](https://arxiv.org/abs/2402.07245)
45. [Distal Interference: Exploring the Limits of Model-Based Continual Learning](https://arxiv.org/abs/2402.08255)
46. [BBox-Adapter: Lightweight Adapting for Black-Box Large Language Models](https://arxiv.org/abs/2402.08219)
47. [Fine-Tuning Text-To-Image Diffusion Models for Class-Wise Spurious Feature Generation](https://arxiv.org/abs/2402.08200)
48. [Addressing cognitive bias in medical language models](https://arxiv.org/abs/2402.08113)
49. [Which Pretrain Samples to Rehearse when Finetuning Pretrained Models?](https://arxiv.org/abs/2402.08096)
50. [BASE TTS: Lessons from building a billion-parameter Text-to-Speech model on 100K hours of data](https://arxiv.org/abs/2402.08093)
51. [Text-centric Alignment for Multi-Modality Learning](https://arxiv.org/abs/2402.08086)
52. [Rethinking U-net Skip Connections for Biomedical Image Segmentation](https://arxiv.org/abs/2402.08276)
53. [IM-3D: Iterative Multiview Diffusion and Reconstruction for High-Quality 3D Generation](https://arxiv.org/abs/2402.08682)
54. [Mitigating Object Hallucination in Large Vision-Language Models via Classifier-Free Guidance](https://arxiv.org/abs/2402.08680)
55. [Learning Continuous 3D Words for Text-to-Image Generation](https://arxiv.org/abs/2402.08654)
56. [Bayesian Multi-Task Transfer Learning for Soft Prompt Tuning](https://arxiv.org/abs/2402.08594)
57. [FESS Loss: Feature-Enhanced Spatial Segmentation Loss for Optimizing Medical Image Analysis](https://arxiv.org/abs/2402.08582)
58. [Higher Layers Need More LoRA Experts](https://arxiv.org/abs/2402.08562)
59. [Concept-1K: A Novel Benchmark for Instance Incremental Learning](https://arxiv.org/abs/2402.08526)
60. [Intriguing Differences Between Zero-Shot and Systematic Evaluations of Vision-Language Transformer Models](https://arxiv.org/abs/2402.08473)
61. [LlaSMol: Advancing Large Language Models for Chemistry with a Large-Scale, Comprehensive, High-Quality Instruction Tuning Dataset](https://arxiv.org/abs/2402.09391)
62. [HGOT: Hierarchical Graph of Thoughts for Retrieval-Augmented In-Context Learning in Factuality Evaluation](https://arxiv.org/abs/2402.09390)
63. [DoRA: Weight-Decomposed Low-Rank Adaptation](https://arxiv.org/abs/2402.09353)
64. [Few-Shot Object Detection with Sparse Context Transformers](https://arxiv.org/abs/2402.09315)
65. [Self-Alignment for Factuality: Mitigating Hallucinations in LLMs via Self-Evaluation](https://arxiv.org/abs/2402.09267)
66. [SyntaxShap: Syntax-aware Explainability Method for Text Generation](https://arxiv.org/abs/2402.09259)
67. [Into the Unknown: Self-Learning Large Language Models](https://arxiv.org/abs/2402.09147)
68. [Affine transformation estimation improves visual self-supervised learning](https://arxiv.org/abs/2402.09071)
69. [Solid Waste Detection in Remote Sensing Images: A Survey](https://arxiv.org/abs/2402.09066)
70. [Pretraining Vision-Language Model for Difference Visual Question Answering in Longitudinal Chest X-rays](https://arxiv.org/abs/2402.08966)
71. [DUEL: Duplicate Elimination on Active Memory for Self-Supervised Class-Imbalanced Learning](https://arxiv.org/abs/2402.08963)
72. [RanDumb: A Simple Approach that Questions the Efficacy of Continual Representation Learning](https://arxiv.org/abs/2402.08823)
73. [BEFUnet: A Hybrid CNN-Transformer Architecture for Precise Medical Image Segmentation](https://arxiv.org/abs/2402.08793)
74. [Learning How To Ask: Cycle-Consistency Refines Prompts in Multimodal Foundation Models](https://arxiv.org/abs/2402.08756)
75. [Experts Don't Cheat: Learning What You Don't Know By Predicting Pairs](https://arxiv.org/abs/2402.08733)
76. [Deep Rib Fracture Instance Segmentation and Classification from CT on the RibFrac Challenge](https://arxiv.org/abs/2402.09372)
77. [OmniMedVQA: A New Large-Scale Comprehensive Evaluation Benchmark for Medical LVLM](https://arxiv.org/abs/2402.09181)
78. [Extreme Video Compression with Pre-trained Diffusion Models](https://arxiv.org/abs/2402.08934)
79. [Self-Play Fine-Tuning of Diffusion Models for Text-to-Image Generation](https://arxiv.org/abs/2402.10210)
80. [Recovering the Pre-Fine-Tuning Weights of Generative Models](https://arxiv.org/abs/2402.10208)
81. [Hierarchical State Space Models for Continuous Sequence-to-Sequence Modeling](https://arxiv.org/abs/2402.10211)
82. [Unlocking the Potential of Transformers in Time Series Forecasting with Sharpness-Aware Minimization and Channel-Wise Attention](https://arxiv.org/abs/2402.10198)
83. [Selective Reflection-Tuning: Student-Selected Data Recycling for LLM Instruction-Tuning](https://arxiv.org/abs/2402.10110)
84. [Tuning In: Analysis of Audio Classifier Performance in Clinical Settings with Limited Data](https://arxiv.org/abs/2402.10100)
85. [Balancing the Causal Effects in Class-Incremental Learning](https://arxiv.org/abs/2402.10063)
86. [Optimal Parameter and Neuron Pruning for Out-of-Distribution Detection](https://arxiv.org/abs/2402.10062)
87. [Textual Localization: Decomposing Multi-concept Images for Subject-Driven Text-to-Image Generation](https://arxiv.org/abs/2402.09966)
88. [Generative Representational Instruction Tuning](https://arxiv.org/abs/2402.09906)
89. [DreamMatcher: Appearance Matching Self-Attention for Semantically-Consistent Text-to-Image Personalization](https://arxiv.org/abs/2402.09812)
90. [EFUF: Efficient Fine-grained Unlearning Framework for Mitigating Hallucinations in Multimodal Large Language Models](https://arxiv.org/abs/2402.09801)
91. [Model Compression and Efficient Inference for Large Language Models: A Survey](https://arxiv.org/abs/2402.09748)
92. [QuRating: Selecting High-Quality Data for Training Language Models](https://arxiv.org/abs/2402.09739)
93. [Prompt-based Personalized Federated Learning for Medical Visual Question Answering](https://arxiv.org/abs/2402.09677)
94. [How to Train Data-Efficient LLMs](https://arxiv.org/abs/2402.09668)
95. [VisIRNet: Deep Image Alignment for UAV-taken Visible and Infrared Image Pairs](https://arxiv.org/abs/2402.09635)
96. [Quantified Task Misalignment to Inform PEFT: An Exploration of Domain Generalization and Catastrophic Forgetting in CLIP](https://arxiv.org/abs/2402.09613)
97. [Domain Adaptation for Contrastive Audio-Language Models](https://arxiv.org/abs/2402.09585)
98. [Learning From Lessons Learned: Preliminary Findings From a Study of Learning From Failure](https://arxiv.org/abs/2402.09538)
1. [Resultant: Incremental Effectiveness on Likelihood for Unsupervised Out-of-Distribution Detection](https://arxiv.org/abs/2409.03801)
2. [Evaluating Machine Learning-based Skin Cancer Diagnosis](https://arxiv.org/abs/2409.03794)
3. [Learning vs Retrieval: The Role of In-Context Examples in Regression with LLMs](https://arxiv.org/abs/2409.04318)
4. [FS-MedSAM2: Exploring the Potential of SAM2 for Few-Shot Medical Image Segmentation without Fine-tuning](https://arxiv.org/abs/2409.04298)
5. [Fast Forwarding Low-Rank Training](https://arxiv.org/abs/2409.04206)
6. [Can OpenSource beat ChatGPT? -- A Comparative Study of Large Language Models for Text-to-Code Generation](https://arxiv.org/abs/2409.04164)
7. [A Coin Has Two Sides: A Novel Detector-Corrector Framework for Chinese Spelling Correction](https://arxiv.org/abs/2409.04150)
8. [Large Margin Prototypical Network for Few-shot Relation Classification with Fine-grained Features](https://arxiv.org/abs/2409.04009)
9. [Qihoo-T2X: An Efficiency-Focused Diffusion Transformer via Proxy Tokens for Text-to-Any-Task](https://arxiv.org/abs/2409.04005)
10. [Deep Clustering of Remote Sensing Scenes through Heterogeneous Transfer Learning](https://arxiv.org/abs/2409.03938)
11. [Data-Efficient Generation for Dataset Distillation](https://arxiv.org/abs/2409.03929)
12. [Few-shot Adaptation of Medical Vision-Language Models](https://arxiv.org/abs/2409.03868)
13. [Exploring Foundation Models for Synthetic Medical Imaging: A Study on Chest X-Rays and Fine-Tuning Techniques](https://arxiv.org/abs/2409.04424)
14. [Optical Coherence Tomography Angiography-OCTA dataset for the study of Diabetic Retinopathy](https://arxiv.org/abs/2409.04137)
15. [VILA-U: a Unified Foundation Model Integrating Visual Understanding and Generation](https://arxiv.org/abs/2409.04429)
16. [Theory, Analysis, and Best Practices for Sigmoid Self-Attention](https://arxiv.org/abs/2409.04431)
17. [LSVOS Challenge Report: Large-scale Complex and Long Video Object Segmentation](https://arxiv.org/abs/2409.05847)
18. [A CLIP-based siamese approach for meme classification](https://arxiv.org/abs/2409.05772)
19. [Zero-shot Outlier Detection via Prior-data Fitted Networks: Model Selection Bygone!](https://arxiv.org/abs/2409.05672)
20. [Joint Input and Output Coordination for Class-Incremental Learning](https://arxiv.org/abs/2409.05620)
21. [CustomContrast: A Multilevel Contrastive Perspective For Subject-Driven Text-to-Image Customization](https://arxiv.org/abs/2409.05606)
22. [StratXplore: Strategic Novelty-seeking and Instruction-aligned Exploration for Vision and Language Navigation](https://arxiv.org/abs/2409.05593)
23. [Seeing is Believing? Enhancing Vision-Language Navigation using Visual Perturbations](https://arxiv.org/abs/2409.05552)
24. [Elsevier Arena: Human Evaluation of Chemistry/Biology/Health Foundational Large Language Models](https://arxiv.org/abs/2409.05486)
25. [Proto-OOD: Enhancing OOD Object Detection with Prototype Feature Similarity](https://arxiv.org/abs/2409.05466)
26. [TextToucher: Fine-Grained Text-to-Touch Generation](https://arxiv.org/abs/2409.05427)
27. [TAVP: Task-Adaptive Visual Prompt for Cross-domain Few-shot Segmentation](https://arxiv.org/abs/2409.05393)
28. [Shaking Up VLMs: Comparing Transformers and Structured State Space Models for Vision & Language Modeling](https://arxiv.org/abs/2409.05395)
29. [Boosting CLIP Adaptation for Image Quality Assessment via Meta-Prompt Learning and Gradient Regularization](https://arxiv.org/abs/2409.05381)
30. [FIF-UNet: An Efficient UNet Using Feature Interaction and Fusion for Medical Image Segmentation](https://arxiv.org/abs/2409.05324)
31. [Open-World Dynamic Prompt and Continual Visual Representation Learning](https://arxiv.org/abs/2409.05312)
32. [A Survey on Mixup Augmentations and Beyond](https://arxiv.org/abs/2409.05202)
33. [Can OOD Object Detectors Learn from Foundation Models?](https://arxiv.org/abs/2409.05162)
34. [Deep Self-cleansing for Medical Image Segmentation with Noisy Labels](https://arxiv.org/abs/2409.05024)
35. [Visual Grounding with Multi-modal Conditional Adaptation](https://arxiv.org/abs/2409.04999)
36. [PatchAlign:Fair and Accurate Skin Disease Image Classification by Alignment with Clinical Labels](https://arxiv.org/abs/2409.04975)
37. [SGSeg: Enabling Text-free Inference in Language-guided Segmentation of Chest X-rays via Self-guidance](https://arxiv.org/abs/2409.04758)
38. [Cross-Organ Domain Adaptive Neural Network for Pancreatic Endoscopic Ultrasound Image Segmentation](https://arxiv.org/abs/2409.04718)
39. [MuAP: Multi-step Adaptive Prompt Learning for Vision-Language Model with Missing Modality](https://arxiv.org/abs/2409.04693)
40. [Multi-Conditioned Denoising Diffusion Probabilistic Model (mDDPM) for Medical Image Synthesis](https://arxiv.org/abs/2409.04670)
41. [Zero-Shot Whole Slide Image Retrieval in Histopathology Using Embeddings of Foundation Models](https://arxiv.org/abs/2409.04631)
42. [High-Performance Few-Shot Segmentation with Foundation Models: An Empirical Study](https://arxiv.org/abs/2409.06305)
43. [Revisiting Prompt Pretraining of Vision-Language Models](https://arxiv.org/abs/2409.06166)
44. [SVFit: Parameter-Efficient Fine-Tuning of Large Pre-Trained Models Using Singular Values](https://arxiv.org/abs/2409.05926)
45. [DA-MoE: Towards Dynamic Expert Allocation for Mixture-of-Experts Models](https://arxiv.org/abs/2409.06669)
46. [SaRA: High-Efficient Diffusion Model Fine-tuning with Progressive Sparse Low-Rank Adaptation](https://arxiv.org/abs/2409.06633)
47. [Elucidating Optimal Reward-Diversity Tradeoffs in Text-to-Image Diffusion Models](https://arxiv.org/abs/2409.06493)
48. [Knowledge Distillation via Query Selection for Detection Transformer](https://arxiv.org/abs/2409.06443)
1. [Detecting Dataset Abuse in Fine-Tuning Stable Diffusion Models for Text-to-Image Synthesis](https://arxiv.org/abs/2409.18897)
2. [Emu3: Next-Token Prediction is All You Need](https://arxiv.org/abs/2409.18869)
3. [LW2G: Learning Whether to Grow for Prompt-based Continual Learning](https://arxiv.org/abs/2409.18860)
4. [LLM With Tools: A Survey](https://arxiv.org/abs/2409.18807)
5. [A Novel Unified Architecture for Low-Shot Counting by Detection and Segmentation](https://arxiv.org/abs/2409.18686)
6. [SinoSynth: A Physics-based Domain Randomization Approach for Generalizable CBCT Image Enhancement](https://arxiv.org/abs/2409.18355)
7. [Task-recency bias strikes back: Adapting covariances in Exemplar-Free Class Incremental Learning](https://arxiv.org/abs/2409.18265)
8. [Trustworthy Text-to-Image Diffusion Models: A Timely and Focused Survey](https://arxiv.org/abs/2409.18214)
9. [Multi-modal Medical Image Fusion For Non-Small Cell Lung Cancer Classification](https://arxiv.org/abs/2409.18715)
10. [Med-IC: Fusing a Single Layer Involution with Convolutions for Enhanced Medical Image Classification and Segmentation](https://arxiv.org/abs/2409.18506)
11. [MM1.5: Methods, Analysis & Insights from Multimodal LLM Fine-tuning](https://arxiv.org/abs/2409.20566)
12. [Scaling Proprioceptive-Visual Learning with Heterogeneous Pre-trained Transformers](https://arxiv.org/abs/2409.20537)
13. [AUCSeg: AUC-oriented Pixel-level Long-tail Semantic Segmentation](https://arxiv.org/abs/2409.20398)
14. [CableInspect-AD: An Expert-Annotated Anomaly Detection Dataset](https://arxiv.org/abs/2409.20353)
15. [Automating MedSAM by Learning Prompts with Weak Few-Shot Supervision](https://arxiv.org/abs/2409.20293)
16. [Forecasting Disease Progression with Parallel Hyperplanes in Longitudinal Retinal OCT](https://arxiv.org/abs/2409.20195)
17. [VMAD: Visual-enhanced Multimodal Large Language Model for Zero-Shot Anomaly Detection](https://arxiv.org/abs/2409.20146)
18. [Magnet: We Never Know How Text-to-Image Diffusion Models Work, Until We Learn How Vision-Language Models Function](https://arxiv.org/abs/2409.19967)
19. [Can Models Learn Skill Composition from Examples?](https://arxiv.org/abs/2409.19808)
20. [Balancing the Scales: A Comprehensive Study on Tackling Class Imbalance in Binary Classification](https://arxiv.org/abs/2409.19751)
21. [Pear: Pruning and Sharing Adapters in Visual Parameter-Efficient Fine-Tuning](https://arxiv.org/abs/2409.19733)
22. [FAST: A Dual-tier Few-Shot Learning Paradigm for Whole Slide Image Classification](https://arxiv.org/abs/2409.19720)
23. [Simple and Fast Distillation of Diffusion Models](https://arxiv.org/abs/2409.19681)
24. [MedViLaM: A multimodal large language model with advanced generalizability and explainability for medical data understanding and generation](https://arxiv.org/abs/2409.19684)
25. [All-in-One Image Coding for Joint Human-Machine Vision with Multi-Path Aggregation](https://arxiv.org/abs/2409.19660)
26. [Hybrid Mamba for Few-Shot Segmentation](https://arxiv.org/abs/2409.19613)
27. [MedCLIP-SAMv2: Towards Universal Text-Driven Medical Image Segmentation](https://arxiv.org/abs/2409.19483)
28. [FairPIVARA: Reducing and Assessing Biases in CLIP-Based Multimodal Models](https://arxiv.org/abs/2409.19474)
29. [Restore Anything with Masks: Leveraging Mask Image Modeling for Blind All-in-One Image Restoration](https://arxiv.org/abs/2409.19403)
30. [X-Prompt: Multi-modal Visual Prompt for Video Object Segmentation](https://arxiv.org/abs/2409.19342)
31. [3D-CT-GPT: Generating 3D Radiology Reports through Integration of Large Vision-Language Models](https://arxiv.org/abs/2409.19330)
32. [CLIP-MoE: Towards Building Mixture of Experts for CLIP with Diversified Multiplet Upcycling](https://arxiv.org/abs/2409.19291)
33. [Forgetting, Ignorance or Myopia: Revisiting Key Challenges in Online Continual Learning](https://arxiv.org/abs/2409.19245)
34. [KANDU-Net:A Dual-Channel U-Net with KAN for Medical Image Segmentation](https://arxiv.org/abs/2409.20414)
35. [Dual Consolidation for Pre-Trained Model-Based Domain-Incremental Learning](https://arxiv.org/abs/2410.00911)
36. [Fine-Grained Gradient Restriction: A Simple Approach for Mitigating Catastrophic Forgetting](https://arxiv.org/abs/2410.00868)
37. [Improved Generation of Synthetic Imaging Data Using Feature-Aligned Diffusion](https://arxiv.org/abs/2410.00731)
38. [Mining Your Own Secrets: Diffusion Classifier Scores for Continual Personalization of Text-to-Image Diffusion Models](https://arxiv.org/abs/2410.00700)
39. [ICL-TSVD: Bridging Theory and Practice in Continual Learning with Pre-trained Models](https://arxiv.org/abs/2410.00645)
40. [MCGM: Mask Conditional Text-to-Image Generative Model](https://arxiv.org/abs/2410.00483)
41. [UniAdapt: A Universal Adapter for Knowledge Calibration](https://arxiv.org/abs/2410.00454)
42. [Vision Language Models See What You Want but not What You See](https://arxiv.org/abs/2410.00324)
43. [Zero-Shot Classification of Crisis Tweets Using Instruction-Finetuned Large Language Models](https://arxiv.org/abs/2410.00182)
44. [GaNDLF-Synth: A Framework to Democratize Generative AI for (Bio)Medical Imaging](https://arxiv.org/abs/2410.00173)
45. [A Survey on Diffusion Models for Inverse Problems](https://arxiv.org/abs/2410.00083)
46. [Linear Projections of Teacher Embeddings for Few-Class Distillation](https://arxiv.org/abs/2409.20449)
47. [SegEarth-OV: Towards Traning-Free Open-Vocabulary Segmentation for Remote Sensing Images](https://arxiv.org/abs/2410.01768)
48. [Leopard: A Vision Language Model For Text-Rich Multi-Image Tasks](https://arxiv.org/abs/2410.01744)
49. [ComfyGen: Prompt-Adaptive Workflows for Text-to-Image Generation](https://arxiv.org/abs/2410.01731)
50. [Visual Perception in Text Strings](https://arxiv.org/abs/2410.01733)
51. [LMOD: A Large Multimodal Ophthalmology Dataset and Benchmark for Large Vision-Language Models](https://arxiv.org/abs/2410.01620)
52. [PASS:Test-Time Prompting to Adapt Styles and Semantic Shapes in Medical Image Segmentation](https://arxiv.org/abs/2410.01573)
53. [Revisiting Hierarchical Text Classification: Inference and Metrics](https://arxiv.org/abs/2410.01305)
54. [Speculative Coreset Selection for Task-Specific Fine-tuning](https://arxiv.org/abs/2410.01296)
55. [Integrating Visual and Textual Inputs for Searching Large-Scale Map Collections with CLIP](https://arxiv.org/abs/2410.01190)
56. [Uncertainty-Guided Enhancement on Driving Perception System via Foundation Models](https://arxiv.org/abs/2410.01144)
57. [RobustEMD: Domain Robust Matching for Cross-domain Few-shot Medical Image Segmentation](https://arxiv.org/abs/2410.01110)
58. [Formula-Driven Data Augmentation and Partial Retinal Layer Copying for Retinal Layer Segmentation](https://arxiv.org/abs/2410.01185)
59. [Interpreting and Editing Vision-Language Representations to Mitigate Hallucinations](https://arxiv.org/abs/2410.02762)
60. [Erasing Conceptual Knowledge from Language Models](https://arxiv.org/abs/2410.02760)
61. [Loong: Generating Minute-level Long Videos with Autoregressive Language Models](https://arxiv.org/abs/2410.02757)
62. [CriSPO: Multi-Aspect Critique-Suggestion-guided Automatic Prompt Optimization for Text Generation](https://arxiv.org/abs/2410.02748)
63. [Contrastive Localized Language-Image Pre-Training](https://arxiv.org/abs/2410.02746)
64. [AVG-LLaVA: A Multimodal Large Model with Adaptive Visual Granularity](https://arxiv.org/abs/2410.02745)
65. [Revisit Large-Scale Image-Caption Data in Pre-training Multimodal Foundation Models](https://arxiv.org/abs/2410.02740)
66. [OOD-Chameleon: Is Algorithm Selection for OOD Generalization Learnable?](https://arxiv.org/abs/2410.02735)
67. [LLaVA-Critic: Learning to Evaluate Multimodal Models](https://arxiv.org/abs/2410.02712)
68. [SteerDiff: Steering towards Safe Text-to-Image Diffusion Models](https://arxiv.org/abs/2410.02710)
69. [Selective Attention Improves Transformer](https://arxiv.org/abs/2410.02703)
70. [Understanding and Mitigating Miscalibration in Prompt Tuning for Vision-Language Models](https://arxiv.org/abs/2410.02681)
71. [Large Language Model for Multi-Domain Translation: Benchmarking and Domain CoT Fine-tuning](https://arxiv.org/abs/2410.02631)
72. [Metrics Revolutions: Groundbreaking Insights into the Implementation of Metrics for Biomedical Image Segmentation](https://arxiv.org/abs/2410.02630)
73. [LoGra-Med: Long Context Multi-Graph Alignment for Medical Vision-Language Model](https://arxiv.org/abs/2410.02615)
74. [SAFLEX: Self-Adaptive Augmentation via Feature Label Extrapolation](https://arxiv.org/abs/2410.02512)
75. [DTVLT: A Multi-modal Diverse Text Benchmark for Visual Language Tracking Based on LLM](https://arxiv.org/abs/2410.02492)
76. [BiSSL: Bilevel Optimization for Self-Supervised Pre-Training and Fine-Tuning](https://arxiv.org/abs/2410.02387)
77. [Unleashing the Potential of the Diffusion Model in Few-shot Semantic Segmentation](https://arxiv.org/abs/2410.02369)
78. [From Concrete to Abstract: A Multimodal Generative Approach to Abstract Concept Learning](https://arxiv.org/abs/2410.02365)
79. [ProtoSeg: A Prototype-Based Point Cloud Instance Segmentation Method](https://arxiv.org/abs/2410.02352)
80. [Self-eXplainable AI for Medical Image Analysis: A Survey and New Outlooks](https://arxiv.org/abs/2410.02331)
81. [Hard Negative Sample Mining for Whole Slide Image Classification](https://arxiv.org/abs/2410.02212)
82. [Adapting Segment Anything Model to Melanoma Segmentation in Microscopy Slide Images](https://arxiv.org/abs/2410.02207)
83. [Dataset Distillation via Knowledge Distillation: Towards Efficient Self-Supervised Pre-Training of Deep Networks](https://arxiv.org/abs/2410.02116)
84. [EMMA: Efficient Visual Alignment in Multi-Modal LLMs](https://arxiv.org/abs/2410.02080)
85. [DisEnvisioner: Disentangled and Enriched Visual Prompt for Customized Image Generation](https://arxiv.org/abs/2410.02067)
86. [Inspection and Control of Self-Generated-Text Recognition Ability in Llama3-8b-Instruct](https://arxiv.org/abs/2410.02064)
87. [Differentially Private Parameter-Efficient Fine-tuning for Large ASR Models](https://arxiv.org/abs/2410.01948)
88. [NEAT: Nonlinear Parameter-efficient Adaptation of Pre-trained Models](https://arxiv.org/abs/2410.01870)
89. [Med-TTT: Vision Test-Time Training model for Medical Image Segmentation](https://arxiv.org/abs/2410.02523)
90. [MedVisionLlama: Leveraging Pre-Trained Large Language Model Layers to Enhance Medical Image Segmentation](https://arxiv.org/abs/2410.02458)
91. [MONICA: Benchmarking on Long-tailed Medical Image Classification](https://arxiv.org/abs/2410.02010)
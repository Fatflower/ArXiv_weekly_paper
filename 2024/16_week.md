1. [Text Prompt with Normality Guidance for Weakly Supervised Video Anomaly Detection](https://arxiv.org/abs/2404.08531)
2. [Pay Attention to Your Neighbours: Training-Free Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2404.08181)
3. [Latent Guard: a Safety Framework for Text-to-image Generation](https://arxiv.org/abs/2404.08031)
4. [A Large-Scale Evaluation of Speech Foundation Models](https://arxiv.org/abs/2404.09385)
5. [Diffusion Models Meet Remote Sensing: Principles, Methods, and Perspectives](https://arxiv.org/abs/2404.08926)
6. [PM2: A New Prompting Multi-modal Model Paradigm for Few-shot Medical Image Classification](https://arxiv.org/abs/2404.08915)
7. [EIVEN: Efficient Implicit Attribute Value Extraction using Multimodal LLM](https://arxiv.org/abs/2404.08886)
8. [Is Next Token Prediction Sufficient for GPT? Exploration on Code Logic Comprehension](https://arxiv.org/abs/2404.08885)
9. [Generative AI Agent for Next-Generation MIMO Design: Fundamentals, Challenges, and Vision](https://arxiv.org/abs/2404.08878)
10. [Aligning LLMs for FL-free Program Repair](https://arxiv.org/abs/2404.08877)
11. [LLM In-Context Recall is Prompt Dependent](https://arxiv.org/abs/2404.08865)
12. [Voice Attribute Editing with Text Prompt](https://arxiv.org/abs/2404.08857)
13. [The Illusion of State in State-Space Models](https://arxiv.org/abs/2404.08819)
14. [Detecting AI-Generated Images via CLIP](https://arxiv.org/abs/2404.08788)
15. [LLM-Seg: Bridging Image Segmentation and Large Language Model Reasoning](https://arxiv.org/abs/2404.08767)
16. [`Eyes of a Hawk and Ears of a Fox': Part Prototype Network for Generalized Zero-Shot Learning](https://arxiv.org/abs/2404.08761)
17. [Your Finetuned Large Language Model is Already a Powerful Out-of-distribution Detector](https://arxiv.org/abs/2404.08679)
18. [MaxFusion: Plug&Play Multi-Modal Generation in Text-to-Image Diffusion Models](https://arxiv.org/abs/2404.09977)
19. [How to build the best medical image segmentation algorithm using foundation models: a comprehensive empirical study with Segment Anything Model](https://arxiv.org/abs/2404.09957)
20. [Evolving Interpretable Visual Classifiers with Large Language Models](https://arxiv.org/abs/2404.09941)
21. [Foundational Challenges in Assuring Alignment and Safety of Large Language Models](https://arxiv.org/abs/2404.09932)
22. [Evaluating the Explainability of Attributes and Prototypes for a Medical Classification Model](https://arxiv.org/abs/2404.09917)
23. [Conditional Prototype Rectification Prompt Learning](https://arxiv.org/abs/2404.09872)
24. [Impact of Preference Noise on the Alignment Performance of Generative Language Models](https://arxiv.org/abs/2404.09824)
25. [TextCoT: Zoom In for Enhanced Multimodal Text-Rich Image Understanding](https://arxiv.org/abs/2404.09797)
26. [The Devil is in the Few Shots: Iterative Visual Knowledge Completion for Few-shot Learning](https://arxiv.org/abs/2404.09778)
27. [nnU-Net Revisited: A Call for Rigorous Validation in 3D Medical Image Segmentation](https://arxiv.org/abs/2404.09556)
28. [State Space Model for New-Generation Network Alternative to Transformers: A Survey](https://arxiv.org/abs/2404.09516)
29. [Q2A: Querying Implicit Fully Continuous Feature Pyramid to Align Features for Medical Image Segmentation](https://arxiv.org/abs/2404.09472)
30. [RankCLIP: Ranking-Consistent Language-Image Pretraining](https://arxiv.org/abs/2404.09387)
31. [Towards Practical Tool Usage for Continually Learning LLMs](https://arxiv.org/abs/2404.09339)
32. [Weight Copy and Low-Rank Adaptation for Few-Shot Distillation of Vision Transformers](https://arxiv.org/abs/2404.09326)
33. [DetCLIPv3: Towards Versatile Generative Open-vocabulary Object Detection](https://arxiv.org/abs/2404.09216)
34. [TextHawk: Exploring Efficient Fine-Grained Perception of Multimodal Large Language Models](https://arxiv.org/abs/2404.09204)
35. [Change Guiding Network: Incorporating Change Prior to Guide Change Detection in Remote Sensing Imagery](https://arxiv.org/abs/2404.09179)
36. [GeMQuAD : Generating Multilingual Question Answering Datasets from Large Language Models using Few Shot Learning](https://arxiv.org/abs/2404.09163)
37. [Fusion-Mamba for Cross-modality Object Detection](https://arxiv.org/abs/2404.09146)
38. [MING-MOE: Enhancing Medical Multi-Task Learning in Large Language Models with Sparse Mixture of Low-Rank Adapter Experts](https://arxiv.org/abs/2404.09027)
39. [Navigating the Landscape of Large Language Models: A Comprehensive Review and Analysis of Paradigms and Fine-Tuning Strategies](https://arxiv.org/abs/2404.09022)
40. [Intuition-aware Mixture-of-Rank-1-Experts for Parameter Efficient Finetuning](https://arxiv.org/abs/2404.08985)
41. [MCPNet: An Interpretable Classifier via Multi-Level Concept Prototypes](https://arxiv.org/abs/2404.08968)
42. [AMU-Tuning: Effective Logit Bias for CLIP-based Few-shot Learning](https://arxiv.org/abs/2404.08958)
43. [Constructing and Exploring Intermediate Domains in Mixed Domain Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2404.08951)
44. [Label-free Anomaly Detection in Aerial Agricultural Images with Masked Image Modeling](https://arxiv.org/abs/2404.08931)
45. [MOWA: Multiple-in-One Image Warping Model](https://arxiv.org/abs/2404.10716)
46. [Contextrast: Contextual Contrastive Learning for Semantic Segmentation](https://arxiv.org/abs/2404.10633)
47. [Private Attribute Inference from Images with Vision-Language Models](https://arxiv.org/abs/2404.10618)
48. [Construction of Domain-specified Japanese Large Language Model for Finance through Continual Pre-training](https://arxiv.org/abs/2404.10555)
49. [A Sentiment Analysis of Medical Text Based on Deep Learning](https://arxiv.org/abs/2404.10503)
50. [Self-Supervised Visual Preference Alignment](https://arxiv.org/abs/2404.10501)
51. [Toward a Realistic Benchmark for Out-of-Distribution Detection](https://arxiv.org/abs/2404.10474)
52. [Optimization of Prompt Learning via Multi-Knowledge Representation for Vision-Language Models](https://arxiv.org/abs/2404.10357)
53. [Domain-Rectifying Adapter for Cross-Domain Few-Shot Segmentation](https://arxiv.org/abs/2404.10322)
54. [Hierarchical Context Merging: Better Long Context Understanding for Pre-trained LLMs](https://arxiv.org/abs/2404.10308)
55. [MoE-TinyMed: Mixture of Experts for Tiny Medical Large Vision-Language Models](https://arxiv.org/abs/2404.10237)
56. [Closed-Loop Open-Vocabulary Mobile Manipulation with GPT-4V](https://arxiv.org/abs/2404.10220)
57. [Salient Object-Aware Background Generation using Text-Guided Diffusion Models](https://arxiv.org/abs/2404.10157)
58. [SegFormer3D: an Efficient Transformer for 3D Medical Image Segmentation](https://arxiv.org/abs/2404.10156)
59. [Dual Modalities of Text: Visual and Textual Generative Pre-training](https://arxiv.org/abs/2404.10710)
60. [Mixed Prototype Consistency Learning for Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2404.10717)
61. [LaDiC: Are Diffusion Models Really Inferior to Autoregressive Counterparts for Image-to-Text Generation?](https://arxiv.org/abs/2404.10763)
62. [Watch Your Step: Optimal Retrieval for Continual Learning at Scale](https://arxiv.org/abs/2404.10758)
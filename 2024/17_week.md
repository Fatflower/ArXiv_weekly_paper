1. [Sample Design Engineering: An Empirical Study of What Makes Good Downstream Fine-Tuning Samples for LLMs](https://arxiv.org/abs/2404.13033)
2. [LaPA: Latent Prompt Assist Model For Medical Visual Question Answering](https://arxiv.org/abs/2404.13039)
3. [MoVA: Adapting Mixture of Vision Experts to Multimodal Context](https://arxiv.org/abs/2404.13046)
4. [Next Generation Loss Function for Image Classification](https://arxiv.org/abs/2404.12948)
5. [Is Retain Set All You Need in Machine Unlearning? Restoring Performance of Unlearned Models with Out-Of-Distribution Images](https://arxiv.org/abs/2404.12922)
6. [Robust CLIP-Based Detector for Exposing Diffusion Model-Generated Images](https://arxiv.org/abs/2404.12908)
7. [How Does the Textual Information Affect the Retrieval of Multimodal In-Context Learning?](https://arxiv.org/abs/2404.12866)
8. [ECOR: Explainable CLIP for Object Recognition](https://arxiv.org/abs/2404.12839)
9. [TextSquare: Scaling up Text-Centric Visual Instruction Tuning](https://arxiv.org/abs/2404.12803)
10. [Cross-Modal Adapter: Parameter-Efficient Transfer Learning Approach for Vision-Language Models](https://arxiv.org/abs/2404.12588)
11. [GenVideo: One-shot Target-image and Shape Aware Video Editing using T2I Diffusion Models](https://arxiv.org/abs/2404.12541)
12. [Adaptive Memory Replay for Continual Learning](https://arxiv.org/abs/2404.12526)
13. [IMO: Greedy Layer-Wise Sparse Representation Learning for Out-of-Distribution Text Classification with Pre-trained Models](https://arxiv.org/abs/2404.13504)
14. [Beyond Pixel-Wise Supervision for Medical Image Segmentation: From Traditional Models to Foundation Models](https://arxiv.org/abs/2404.13239)
15. [PEMMA: Parameter-Efficient Multi-Modal Adaptation for Medical Image Segmentation](https://arxiv.org/abs/2404.13704)
16. [Diagnosis of Multiple Fundus Disorders Amidst a Scarcity of Medical Experts Via Self-supervised Machine Learning](https://arxiv.org/abs/2404.13388)
17. [ToNNO: Tomographic Reconstruction of a Neural Network's Output for Weakly Supervised Segmentation of 3D Medical Images](https://arxiv.org/abs/2404.13103)
18. [A Survey on Efficient Inference for Large Language Models](https://arxiv.org/abs/2404.14294)
19. [MultiBooth: Towards Generating All Your Concepts in an Image from Text](https://arxiv.org/abs/2404.14239)
20. [DynaMMo: Dynamic Model Merging for Efficient Class Incremental Learning for Medical Images](https://arxiv.org/abs/2404.14099)
21. [Towards Large-Scale Training of Pathology Foundation Models](https://arxiv.org/abs/2404.15217)
22. [Lossless and Near-Lossless Compression for Foundation Models](https://arxiv.org/abs/2404.15198)
23. [MixLoRA: Enhancing Large Language Models Fine-Tuning with LoRA based Mixture of Experts](https://arxiv.org/abs/2404.15159)
24. [MedDr: Diagnosis-Guided Bootstrapping for Large-Scale Medical Vision-Language Learning](https://arxiv.org/abs/2404.15127)
25. [Multimodal Large Language Model is a Human-Aligned Annotator for Text-to-Image Generation](https://arxiv.org/abs/2404.15100)
26. [Multi-Head Mixture-of-Experts](https://arxiv.org/abs/2404.15045)
27. [Traditional to Transformers: A Survey on Current Trends and Future Prospects for Hyperspectral Image Classification](https://arxiv.org/abs/2404.14955)
28. [Visual-Augmented Dynamic Semantic Prototype for Generative Zero-Shot Learning](https://arxiv.org/abs/2404.14808)
29. [Enhancing Prompt Following with Visual Control Through Training-Free Mask-Guided Diffusion](https://arxiv.org/abs/2404.14768)
30. [Grounded Knowledge-Enhanced Medical VLP for Chest X-Ray](https://arxiv.org/abs/2404.14750)
31. [Q-Tuning: Queue-based Prompt Tuning for Lifelong Few-shot Language Learning](https://arxiv.org/abs/2404.14607)
32. [Brain-Inspired Continual Learning-Robust Feature Distillation and Re-Consolidation for Class Incremental Learning](https://arxiv.org/abs/2404.14588)
33. [Narrative Action Evaluation with Prompt-Guided Multimodal Interaction](https://arxiv.org/abs/2404.14471)
34. [How Far Are We to GPT-4V? Closing the Gap to Commercial Multimodal Models with Open-Source Suites](https://arxiv.org/abs/2404.16821)
35. [Meta-Transfer Derm-Diagnosis: Exploring Few-Shot Learning and Transfer Learning for Skin Disease Classification in Long-Tail Distribution](https://arxiv.org/abs/2404.16814)
36. [AAPL: Adding Attributes to Prompt Learning for Vision-Language Models](https://arxiv.org/abs/2404.16804)
37. [Weak-to-Strong Extrapolation Expedites Alignment](https://arxiv.org/abs/2404.16792)
38. [SEED-Bench-2-Plus: Benchmarking Multimodal Large Language Models with Text-Rich Visual Comprehension](https://arxiv.org/abs/2404.16790)
39. [Continual Learning of Large Language Models: A Comprehensive Survey](https://arxiv.org/abs/2404.16789)
40. [Modeling Selective Feature Attention for Representation-based Siamese Text Matching](https://arxiv.org/abs/2404.16776)
41. [Prefix Text as a Yarn: Eliciting Non-English Alignment in Foundation Language Model](https://arxiv.org/abs/2404.16766)
42. [EmoVIT: Revolutionizing Emotion Insights with Visual Instruction Tuning](https://arxiv.org/abs/2404.16670)
43. [DAVE -- A Detect-and-Verify Paradigm for Low-Shot Counting](https://arxiv.org/abs/2404.16622)
44. [MuseumMaker: Continual Style Customization without Catastrophic Forgetting](https://arxiv.org/abs/2404.16612)
45. [SFMViT: SlowFast Meet ViT in Chaotic World](https://arxiv.org/abs/2404.16609)
46. [Revisiting Relevance Feedback for CLIP-based Interactive Image Retrieval](https://arxiv.org/abs/2404.16398)
47. [Efficiency in Focus: LayerNorm as a Catalyst for Fine-tuning Medical Visual Language Pre-trained Models](https://arxiv.org/abs/2404.16385)
48. [List Items One by One: A New Data Source and Learning Paradigm for Multimodal LLMs](https://arxiv.org/abs/2404.16375)
49. [Multimodal Information Interaction for Medical Image Segmentation](https://arxiv.org/abs/2404.16371)
50. [Integration of Mixture of Experts and Multimodal Generative AI in Internet of Vehicles: A Survey](https://arxiv.org/abs/2404.16356)
51. [Dual Expert Distillation Network for Generalized Zero-Shot Learning](https://arxiv.org/abs/2404.16348)
52. [Training-Free Unsupervised Prompt for Vision-Language Models](https://arxiv.org/abs/2404.16339)
53. [IMWA: Iterative Model Weight Averaging Benefits Class-Imbalanced Learning Tasks](https://arxiv.org/abs/2404.16331)
54. [Semantic Segmentation Refiner for Ultrasound Applications with Zero-Shot Foundation Models](https://arxiv.org/abs/2404.16325)
55. [TI2V-Zero: Zero-Shot Image Conditioning for Text-to-Video Diffusion Models](https://arxiv.org/abs/2404.16306)
56. [Semantically consistent Video-to-Audio Generation using Multimodal Language Large Model](https://arxiv.org/abs/2404.16305)
57. [Style Adaptation for Domain-adaptive Semantic Segmentation](https://arxiv.org/abs/2404.16301)
58. [When Fuzzing Meets LLMs: Challenges and Opportunities](https://arxiv.org/abs/2404.16297)
59. [Towards Efficient Patient Recruitment for Clinical Trials: Application of a Prompt-Based Learning Model](https://arxiv.org/abs/2404.16198)
60. [Fusion of Domain-Adapted Vision and Language Models for Medical Visual Question Answering](https://arxiv.org/abs/2404.16192)
61. [Quantitative Characterization of Retinal Features in Translated OCTA](https://arxiv.org/abs/2404.16133)
62. [FairDeDup: Detecting and Mitigating Vision-Language Fairness Disparities in Semantic Dataset Deduplication](https://arxiv.org/abs/2404.16123)
63. [Interactive Visual Learning for Stable Diffusion](https://arxiv.org/abs/2404.16069)
64. [A Survey on Generative AI and LLM for Video Generation, Understanding, and Streaming](https://arxiv.org/abs/2404.16038)
65. [Cantor: Inspiring Multimodal Chain-of-Thought of MLLM](https://arxiv.org/abs/2404.16033)
66. [MoDE: CLIP Data Experts via Clustering](https://arxiv.org/abs/2404.16030)
67. [Boosting Architectural Generation via Prompts: Report](https://arxiv.org/abs/2404.15971)
68. [Mammo-CLIP: Leveraging Contrastive Language-Image Pre-training (CLIP) for Enhanced Breast Cancer Diagnosis with Multi-view Mammography](https://arxiv.org/abs/2404.15946)
69. [A Comprehensive Survey on Evaluating Large Language Model Applications in the Medical Industry](https://arxiv.org/abs/2404.15777)
70. [ChEX: Interactive Localization and Region Description in Chest X-rays](https://arxiv.org/abs/2404.15770)
71. [No Train but Gain: Language Arithmetic for training-free Language Adapters enhancement](https://arxiv.org/abs/2404.15737)
72. [Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs](https://arxiv.org/abs/2404.15676)
73. [HybridVC: Efficient Voice Style Conversion with Text and Audio Prompts](https://arxiv.org/abs/2404.15637)
74. [A Survey of Deep Long-Tail Classification Advancements](https://arxiv.org/abs/2404.15593)
75. [MiM: Mask in Mask Self-Supervised Pre-Training for 3D Medical Image Analysis](https://arxiv.org/abs/2404.15580)
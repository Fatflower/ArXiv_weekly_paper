1. [VITA: Towards Open-Source Interactive Omni Multimodal LLM](https://arxiv.org/abs/2408.05211)
2. [TaSL: Task Skill Localization and Consolidation for Language Model Continual Learning](https://arxiv.org/abs/2408.05200)
3. [Cautious Calibration in Binary Classification](https://arxiv.org/abs/2408.05120)
4. [Order Matters in Hallucination: Reasoning Order as Benchmark and Reflexive Prompting for Large-Language-Models](https://arxiv.org/abs/2408.05093)
5. [UNIC: Universal Classification Models via Multi-teacher Distillation](https://arxiv.org/abs/2408.05088)
6. [In Defense of Lazy Visual Grounding for Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2408.04961)
7. [Avoid Wasted Annotation Costs in Open-set Active Learning with Pre-trained Vision-Language Model](https://arxiv.org/abs/2408.04917)
8. [GuidedNet: Semi-Supervised Multi-Organ Segmentation via Labeled Data Guide Unlabeled Data](https://arxiv.org/abs/2408.04914)
9. [ProxyCLIP: Proxy Attention Improves CLIP for Open-Vocabulary Segmentation](https://arxiv.org/abs/2408.04883)
10. [On the Element-Wise Representation and Reasoning in Zero-Shot Image Recognition: A Systematic Survey](https://arxiv.org/abs/2408.04879)
11. [Your Classifier Can Be Secretly a Likelihood-Based OOD Detector](https://arxiv.org/abs/2408.04851)
12. [Mitigating Hallucinations in Large Vision-Language Models (LVLMs) via Language-Contrastive Decoding (LCD)](https://arxiv.org/abs/2408.04664)
13. [Beyond the Eye: A Relational Model for Early Dementia Detection Using Retinal OCTA Images](https://arxiv.org/abs/2408.05117)
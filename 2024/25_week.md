1. [Unveiling Encoder-Free Vision-Language Models](https://arxiv.org/abs/2406.11832)
2. [Task Me Anything](https://arxiv.org/abs/2406.11775)
3. [Prior Normality Prompt Transformer for Multi-class Industrial Image Anomaly Detection](https://arxiv.org/abs/2406.11507)
4. [An Empirical Investigation of Matrix Factorization Methods for Pre-trained Transformers](https://arxiv.org/abs/2406.11307)
5. [Dynamic Data Mixing Maximizes Instruction Tuning for Mixture-of-Experts](https://arxiv.org/abs/2406.11256)
6. [Mining Open Semantics from CLIP: A Relation Transition Perspective for Few-Shot Learning](https://arxiv.org/abs/2406.11252)
7. [Frozen CLIP: A Strong Backbone for Weakly Supervised Semantic Segmentation](https://arxiv.org/abs/2406.11189)
8. [TIFG: Text-Informed Feature Generation with Large Language Models](https://arxiv.org/abs/2406.11177)
9. [Fine-grained Classes and How to Find Them](https://arxiv.org/abs/2406.11070)
10. [Boosting Medical Image Classification with Segmentation Foundation Model](https://arxiv.org/abs/2406.11026)
11. [Open-Vocabulary X-ray Prohibited Item Detection via Fine-tuning CLIP](https://arxiv.org/abs/2406.10961)
12. [ALPS: An Auto-Labeling and Pre-training Scheme for Remote Sensing Segmentation With Segment Anything Model](https://arxiv.org/abs/2406.10855)
13. [Saliency-guided and Patch-based Mixup for Long-tailed Skin Cancer Image Classification](https://arxiv.org/abs/2406.10801)
14. [Dynamic Domains, Dynamic Solutions: DPCore for Continual Test-Time Adaptation](https://arxiv.org/abs/2406.10737)
15. [Aqulia-Med LLM: Pioneering Full-Process Open-Source Medical Language Models](https://arxiv.org/abs/2406.12182)
16. [Not All Prompts Are Made Equal: Prompt-based Pruning of Text-to-Image Diffusion Models](https://arxiv.org/abs/2406.12042)
17. [Soft Prompting for Unlearning in Large Language Models](https://arxiv.org/abs/2406.12038)
18. [Self-MoE: Towards Compositional Large Language Models with Self-Specialized Experts](https://arxiv.org/abs/2406.12034)
19. [CLIP-Branches: Interactive Fine-Tuning for Text-Image Retrieval](https://arxiv.org/abs/2406.13322)
20. [Enhancing Cross-Prompt Transferability in Vision-Language Models through Contextual Injection of Target Tokens](https://arxiv.org/abs/2406.13294)
21. [AdaMoE: Token-Adaptive Routing with Null Experts for Mixture-of-Experts Language Models](https://arxiv.org/abs/2406.13233)
22. [Boosting Consistency in Dual Training for Long-Tailed Semi-Supervised Learning](https://arxiv.org/abs/2406.13187)
23. [M3T: Multi-Modal Medical Transformer to bridge Clinical Context with Visual Insights for Retinal Image Medical Description Generation](https://arxiv.org/abs/2406.13129)
24. [GROD: Enhancing Generalization of Transformer with Out-of-Distribution Detection](https://arxiv.org/abs/2406.12915)
25. [Automatic Labels are as Effective as Manual Labels in Biomedical Images Classification with Deep Learning](https://arxiv.org/abs/2406.14351)
26. [AITTI: Learning Adaptive Inclusive Token for Text-to-Image Generation](https://arxiv.org/abs/2406.12805)
27. [MAC: A Benchmark for Multiple Attributes Compositional Zero-Shot Learning](https://arxiv.org/abs/2406.12757)
28. [Probabilistic Conceptual Explainers: Trustworthy Conceptual Explanations for Vision Foundation Models](https://arxiv.org/abs/2406.12649)
29. [Efficient and Long-Tailed Generalization for Pre-trained Vision-Language Model](https://arxiv.org/abs/2406.12638)
30. [Unleashing the Potential of Open-set Noisy Samples Against Label Noise for Medical Image Classification](https://arxiv.org/abs/2406.12293)
31. [Mitigate Negative Transfer with Similarity Heuristic Lifelong Prompt Tuning](https://arxiv.org/abs/2406.12251)
32. [The Solution for CVPR2024 Foundational Few-Shot Object Detection Challenge](https://arxiv.org/abs/2406.12225)
33. [A Survey of Multimodal-Guided Image Editing with Text-to-Image Diffusion Models](https://arxiv.org/abs/2406.14555)
34. [Invertible Consistency Distillation for Text-Guided Image Editing in Around 7 Steps](https://arxiv.org/abs/2406.14539)
35. [Visible-Thermal Tiny Object Detection: A Benchmark Dataset and Baselines](https://arxiv.org/abs/2406.14482)
36. [Revealing Vision-Language Integration in the Brain with Multimodal Networks](https://arxiv.org/abs/2406.14481)
37. [Can you trust your explanations? A robustness test for feature attribution methods](https://arxiv.org/abs/2406.14349)
38. [Infusing clinical knowledge into tokenisers for language models](https://arxiv.org/abs/2406.14312)
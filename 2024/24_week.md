1. [Advanced Payment Security System:XGBoost, CatBoost and SMOTE Integrated](https://arxiv.org/abs/2406.04658)
2. [CLoG: Benchmarking Continual Learning of Image Generation Models](https://arxiv.org/abs/2406.04584)
3. [Attention Fusion Reverse Distillation for Multi-Lighting Image Anomaly Detection](https://arxiv.org/abs/2406.04573)
4. [OCCAM: Towards Cost-Efficient and Accuracy-Aware Image Classification Inference](https://arxiv.org/abs/2406.04508)
5. [MAIRA-2: Grounded Radiology Report Generation](https://arxiv.org/abs/2406.04449)
6. [Can Language Models Use Forecasting Strategies?](https://arxiv.org/abs/2406.04446)
7. [Can Language Models Serve as Text-Based World Simulators?](https://arxiv.org/abs/2406.06485)
8. [Towards a Personal Health Large Language Model](https://arxiv.org/abs/2406.06474)
9. [Husky: A Unified, Open-Source Language Agent for Multi-Step Reasoning](https://arxiv.org/abs/2406.06469)
10. [Towards Lifelong Learning of Large Language Models: A Survey](https://arxiv.org/abs/2406.06391)
11. [Cascading Unknown Detection with Known Classification for Open Set Recognition](https://arxiv.org/abs/2406.06351)
12. [A Statistical Theory of Regularization-Based Continual Learning](https://arxiv.org/abs/2406.06213)
13. [Robust Latent Representation Tuning for Image-text Classification](https://arxiv.org/abs/2406.06048)
14. [Aligning Large Language Models with Representation Editing: A Control Perspective](https://arxiv.org/abs/2406.05954)
15. [Mamba YOLO: SSMs-Based YOLO For Object Detection](https://arxiv.org/abs/2406.05835)
16. [F-LMM: Grounding Frozen Large Multimodal Models](https://arxiv.org/abs/2406.05821)
17. [Visual Prompt Tuning in Null Space for Continual Learning](https://arxiv.org/abs/2406.05658)
18. [CCSI: Continual Class-Specific Impression for Data-free Class Incremental Learning](https://arxiv.org/abs/2406.05631)
19. [A Comprehensive Evaluation of Parameter-Efficient Fine-Tuning on Automated Program Repair](https://arxiv.org/abs/2406.05639)
20. [Domain Generalization Guided by Large-Scale Pre-Trained Priors](https://arxiv.org/abs/2406.05628)
21. [Aligning Human Knowledge with Visual Concepts Towards Explainable Medical Image Classification](https://arxiv.org/abs/2406.05596)
22. [Regularized Training with Generated Datasets for Name-Only Transfer of Vision-Language Models](https://arxiv.org/abs/2406.05432)
23. [LoCoCo: Dropping In Convolutions for Long Context Compression](https://arxiv.org/abs/2406.05317)
24. [SuperPos-Prompt: Enhancing Soft Prompt Tuning of Language Models with Superposition of Multi Token Embeddings](https://arxiv.org/abs/2406.05279)
25. [USE: Universal Segment Embeddings for Open-Vocabulary Image Segmentation](https://arxiv.org/abs/2406.05271)
26. [CPLIP: Zero-Shot Learning for Histopathology with Comprehensive Vision-Language Alignment](https://arxiv.org/abs/2406.05205)
27. [MHS-VM: Multi-Head Scanning in Parallel Subspaces for Vision Mamba](https://arxiv.org/abs/2406.05992)
28. [GCtx-UNet: Efficient Network for Medical Image Segmentation](https://arxiv.org/abs/2406.05891)
29. [MSAGPT: Neural Prompting Protein Structure Prediction via MSA Generative Pre-Training](https://arxiv.org/abs/2406.05347)
30. [An Empirical Study on Parameter-Efficient Fine-Tuning for MultiModal Large Language Models](https://arxiv.org/abs/2406.05130)
31. [Prototype Correlation Matching and Class-Relation Reasoning for Few-Shot Medical Image Segmentation](https://arxiv.org/abs/2406.05054)
32. [AttnDreamBooth: Towards Text-Aligned Personalized Text-to-Image Generation](https://arxiv.org/abs/2406.05000)
33. [ProMotion: Prototypes As Motion Learners](https://arxiv.org/abs/2406.04999)
34. [MEFT: Memory-Efficient Fine-Tuning through Sparse Adapter](https://arxiv.org/abs/2406.04984)
35. [MA-AVT: Modality Alignment for Parameter-Efficient Audio-Visual Transformers](https://arxiv.org/abs/2406.04930)
36. [Revisiting Catastrophic Forgetting in Large Language Model Tuning](https://arxiv.org/abs/2406.04836)
37. [BERTs are Generative In-Context Learners](https://arxiv.org/abs/2406.04823)
38. [REP: Resource-Efficient Prompting for On-device Continual Learning](https://arxiv.org/abs/2406.04772)
39. [MGIMM: Multi-Granularity Instruction Multimodal Model for Attribute-Guided Remote Sensing Image Detailed Description](https://arxiv.org/abs/2406.04716)
40. [Mixture-of-Agents Enhances Large Language Model Capabilities](https://arxiv.org/abs/2406.04692)
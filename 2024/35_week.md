1. [Enhancing Few-Shot Transfer Learning with Optimized Multi-Task Prompt Tuning through Modular Prompt Composition](https://arxiv.org/abs/2408.13227)
2. [EAViT: External Attention Vision Transformer for Audio Classification](https://arxiv.org/abs/2408.13201)
3. [Multimodal Contrastive In-Context Learning](https://arxiv.org/abs/2408.12959)
4. [Image Segmentation in Foundation Model Era: A Survey](https://arxiv.org/abs/2408.12957)
5. [Unleashing the Potential of SAM2 for Biomedical Images and Videos: A Survey](https://arxiv.org/abs/2408.12889)
6. [MergeUp-augmented Semi-Weakly Supervised Learning for WSI Classification](https://arxiv.org/abs/2408.12825)
7. [MultiMed: Massively Multimodal and Multitask Medical Understanding](https://arxiv.org/abs/2408.12682)
8. [Research on Improved U-net Based Remote Sensing Image Segmentation Algorithm](https://arxiv.org/abs/2408.12672)
9. [Image-Feature Weak-to-Strong Consistency: An Enhanced Paradigm for Semi-Supervised Learning](https://arxiv.org/abs/2408.12614)
10. [Towards Non-invasive and Personalized Management of Breast Cancer Patients from Multiparametric MRI via A Large Mixture-of-Modality-Experts Model](https://arxiv.org/abs/2408.12606)
11. [The Mamba in the Llama: Distilling and Accelerating Hybrid Models](https://arxiv.org/abs/2408.15237)
12. [Learning-based Multi-View Stereo: A Survey](https://arxiv.org/abs/2408.15235)
13. [CLIP-AGIQA: Boosting the Performance of AI-Generated Image Quality Assessment with CLIP](https://arxiv.org/abs/2408.15098)
14. [Pre-training Everywhere: Parameter-Efficient Fine-Tuning for Medical Image Analysis via Target Parameter Pre-training](https://arxiv.org/abs/2408.15011)
15. [Prior-free Balanced Replay: Uncertainty-guided Reservoir Sampling for Long-Tailed Continual Learning](https://arxiv.org/abs/2408.14976)
16. [CVPT: Cross-Attention help Visual Prompt Tuning adapt visual task](https://arxiv.org/abs/2408.14961)
17. [Applying ViT in Generalized Few-shot Semantic Segmentation](https://arxiv.org/abs/2408.14957)
18. [ZeroMamba: Exploring Visual State Space Model for Zero-Shot Learning](https://arxiv.org/abs/2408.14868)
19. [Diffusion based Semantic Outlier Generation via Nuisance Awareness for Out-of-Distribution Detection](https://arxiv.org/abs/2408.14841)
20. [MROVSeg: Breaking the Resolution Curse of Vision-Language Models in Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2408.14776)
21. [Text-guided Foundation Model Adaptation for Long-Tailed Medical Image Classification](https://arxiv.org/abs/2408.14770)
22. [GeoTransfer : Generalizable Few-Shot Multi-View Reconstruction via Transfer Learning](https://arxiv.org/abs/2408.14724)
23. [CURLoRA: Stable LLM Continual Fine-Tuning and Catastrophic Forgetting Mitigation](https://arxiv.org/abs/2408.14572)
24. [A New Era in Computational Pathology: A Survey on Foundation and Vision-Language Models](https://arxiv.org/abs/2408.14496)
25. [SAM & SAM 2 in 3D Slicer: SegmentWithSAM Extension for Annotating Medical Images](https://arxiv.org/abs/2408.15224)
26. [Fundus2Video: Cross-Modal Angiography Video Generation from Static Fundus Photography with Clinical Knowledge Guidance](https://arxiv.org/abs/2408.15217)
27. [Intraoperative Glioma Segmentation with YOLO + SAM for Improved Accuracy in Tumor Resection](https://arxiv.org/abs/2408.14847)
28. [BreakNet: Discontinuity-Resilient Multi-Scale Transformer Segmentation of Retinal Layers](https://arxiv.org/abs/2408.14606)
29. [Foundation Models for Music: A Survey](https://arxiv.org/abs/2408.14340)
30. [LSM-YOLO: A Compact and Effective ROI Detector for Medical Detection](https://arxiv.org/abs/2408.14087)
31. [Let Video Teaches You More: Video-to-Image Knowledge Distillation using DEtection TRansformer for Medical Video Lesion Detection](https://arxiv.org/abs/2408.14051)
32. [Avatar Concept Slider: Manipulate Concepts In Your Human Avatar With Fine-grained Control](https://arxiv.org/abs/2408.13995)
33. [Dual-CBA: Improving Online Continual Learning via Dual Continual Bias Adaptors from a Bi-level Optimization Perspective](https://arxiv.org/abs/2408.13991)
34. [FusionSAM: Latent Space driven Segment Anything Model for Multimodal Fusion and Segmentation](https://arxiv.org/abs/2408.13980)
35. [LowCLIP: Adapting the CLIP Model Architecture for Low-Resource Languages in Multimodal Image Retrieval Task](https://arxiv.org/abs/2408.13909)
36. [Evaluating Attribute Comprehension in Large Vision-Language Models](https://arxiv.org/abs/2408.13898)
37. [PropSAM: A Propagation-Based Model for Segmenting Any 3D Objects in Multi-Modal Medical Images](https://arxiv.org/abs/2408.13836)
38. [Biomedical Large Languages Models Seem not to be Superior to Generalist Models on Unseen Medical Data](https://arxiv.org/abs/2408.13833)
39. [Localization and Expansion: A Decoupled Framework for Point Cloud Few-shot Semantic Segmentation](https://arxiv.org/abs/2408.13752)
40. [MSVM-UNet: Multi-Scale Vision Mamba UNet for Medical Image Segmentation](https://arxiv.org/abs/2408.13735)
41. [CNN-Transformer Rectified Collaborative Learning for Medical Image Segmentation](https://arxiv.org/abs/2408.13698)
42. [Studying the Effect of Audio Filters in Pre-Trained Models for Environmental Sound Classification](https://arxiv.org/abs/2408.13644)
43. [Size Aware Cross-shape Scribble Supervision for Medical Image Segmentation](https://arxiv.org/abs/2408.13639)
44. [SpeechCraft: A Fine-grained Expressive Speech Dataset with Natural Language Description](https://arxiv.org/abs/2408.13608)
45. [A Practitioner's Guide to Continual Multimodal Pretraining](https://arxiv.org/abs/2408.14471)
46. [Attend-Fusion: Efficient Audio-Visual Fusion for Video Classification](https://arxiv.org/abs/2408.14441)
47. [Explainable Concept Generation through Vision-Language Preference Learning](https://arxiv.org/abs/2408.13438)
1. [Enhancing Few-Shot Transfer Learning with Optimized Multi-Task Prompt Tuning through Modular Prompt Composition](https://arxiv.org/abs/2408.13227)
2. [EAViT: External Attention Vision Transformer for Audio Classification](https://arxiv.org/abs/2408.13201)
3. [Multimodal Contrastive In-Context Learning](https://arxiv.org/abs/2408.12959)
4. [Image Segmentation in Foundation Model Era: A Survey](https://arxiv.org/abs/2408.12957)
5. [Unleashing the Potential of SAM2 for Biomedical Images and Videos: A Survey](https://arxiv.org/abs/2408.12889)
6. [MergeUp-augmented Semi-Weakly Supervised Learning for WSI Classification](https://arxiv.org/abs/2408.12825)
7. [MultiMed: Massively Multimodal and Multitask Medical Understanding](https://arxiv.org/abs/2408.12682)
8. [Research on Improved U-net Based Remote Sensing Image Segmentation Algorithm](https://arxiv.org/abs/2408.12672)
9. [Image-Feature Weak-to-Strong Consistency: An Enhanced Paradigm for Semi-Supervised Learning](https://arxiv.org/abs/2408.12614)
10. [Towards Non-invasive and Personalized Management of Breast Cancer Patients from Multiparametric MRI via A Large Mixture-of-Modality-Experts Model](https://arxiv.org/abs/2408.12606)
11. [The Mamba in the Llama: Distilling and Accelerating Hybrid Models](https://arxiv.org/abs/2408.15237)
12. [Learning-based Multi-View Stereo: A Survey](https://arxiv.org/abs/2408.15235)
13. [CLIP-AGIQA: Boosting the Performance of AI-Generated Image Quality Assessment with CLIP](https://arxiv.org/abs/2408.15098)
14. [Pre-training Everywhere: Parameter-Efficient Fine-Tuning for Medical Image Analysis via Target Parameter Pre-training](https://arxiv.org/abs/2408.15011)
15. [Prior-free Balanced Replay: Uncertainty-guided Reservoir Sampling for Long-Tailed Continual Learning](https://arxiv.org/abs/2408.14976)
16. [CVPT: Cross-Attention help Visual Prompt Tuning adapt visual task](https://arxiv.org/abs/2408.14961)
17. [Applying ViT in Generalized Few-shot Semantic Segmentation](https://arxiv.org/abs/2408.14957)
18. [ZeroMamba: Exploring Visual State Space Model for Zero-Shot Learning](https://arxiv.org/abs/2408.14868)
19. [Diffusion based Semantic Outlier Generation via Nuisance Awareness for Out-of-Distribution Detection](https://arxiv.org/abs/2408.14841)
20. [MROVSeg: Breaking the Resolution Curse of Vision-Language Models in Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2408.14776)
21. [Text-guided Foundation Model Adaptation for Long-Tailed Medical Image Classification](https://arxiv.org/abs/2408.14770)
22. [GeoTransfer : Generalizable Few-Shot Multi-View Reconstruction via Transfer Learning](https://arxiv.org/abs/2408.14724)
23. [CURLoRA: Stable LLM Continual Fine-Tuning and Catastrophic Forgetting Mitigation](https://arxiv.org/abs/2408.14572)
24. [A New Era in Computational Pathology: A Survey on Foundation and Vision-Language Models](https://arxiv.org/abs/2408.14496)
25. [SAM & SAM 2 in 3D Slicer: SegmentWithSAM Extension for Annotating Medical Images](https://arxiv.org/abs/2408.15224)
26. [Fundus2Video: Cross-Modal Angiography Video Generation from Static Fundus Photography with Clinical Knowledge Guidance](https://arxiv.org/abs/2408.15217)
27. [Intraoperative Glioma Segmentation with YOLO + SAM for Improved Accuracy in Tumor Resection](https://arxiv.org/abs/2408.14847)
28. [BreakNet: Discontinuity-Resilient Multi-Scale Transformer Segmentation of Retinal Layers](https://arxiv.org/abs/2408.14606)
29. [Foundation Models for Music: A Survey](https://arxiv.org/abs/2408.14340)
30. [LSM-YOLO: A Compact and Effective ROI Detector for Medical Detection](https://arxiv.org/abs/2408.14087)
31. [Let Video Teaches You More: Video-to-Image Knowledge Distillation using DEtection TRansformer for Medical Video Lesion Detection](https://arxiv.org/abs/2408.14051)
32. [Avatar Concept Slider: Manipulate Concepts In Your Human Avatar With Fine-grained Control](https://arxiv.org/abs/2408.13995)
33. [Dual-CBA: Improving Online Continual Learning via Dual Continual Bias Adaptors from a Bi-level Optimization Perspective](https://arxiv.org/abs/2408.13991)
34. [FusionSAM: Latent Space driven Segment Anything Model for Multimodal Fusion and Segmentation](https://arxiv.org/abs/2408.13980)
35. [LowCLIP: Adapting the CLIP Model Architecture for Low-Resource Languages in Multimodal Image Retrieval Task](https://arxiv.org/abs/2408.13909)
36. [Evaluating Attribute Comprehension in Large Vision-Language Models](https://arxiv.org/abs/2408.13898)
37. [PropSAM: A Propagation-Based Model for Segmenting Any 3D Objects in Multi-Modal Medical Images](https://arxiv.org/abs/2408.13836)
38. [Biomedical Large Languages Models Seem not to be Superior to Generalist Models on Unseen Medical Data](https://arxiv.org/abs/2408.13833)
39. [Localization and Expansion: A Decoupled Framework for Point Cloud Few-shot Semantic Segmentation](https://arxiv.org/abs/2408.13752)
40. [MSVM-UNet: Multi-Scale Vision Mamba UNet for Medical Image Segmentation](https://arxiv.org/abs/2408.13735)
41. [CNN-Transformer Rectified Collaborative Learning for Medical Image Segmentation](https://arxiv.org/abs/2408.13698)
42. [Studying the Effect of Audio Filters in Pre-Trained Models for Environmental Sound Classification](https://arxiv.org/abs/2408.13644)
43. [Size Aware Cross-shape Scribble Supervision for Medical Image Segmentation](https://arxiv.org/abs/2408.13639)
44. [SpeechCraft: A Fine-grained Expressive Speech Dataset with Natural Language Description](https://arxiv.org/abs/2408.13608)
45. [A Practitioner's Guide to Continual Multimodal Pretraining](https://arxiv.org/abs/2408.14471)
46. [Attend-Fusion: Efficient Audio-Visual Fusion for Video Classification](https://arxiv.org/abs/2408.14441)
47. [Explainable Concept Generation through Vision-Language Preference Learning](https://arxiv.org/abs/2408.13438)
48. [Mamba or Transformer for Time Series Forecasting? Mixture of Universals (MoU) Is All You Need](https://arxiv.org/abs/2408.15997)
49. [Eagle: Exploring The Design Space for Multimodal LLMs with Mixture of Encoders](https://arxiv.org/abs/2408.15998)
50. [In-Context Imitation Learning via Next-Token Prediction](https://arxiv.org/abs/2408.15980)
51. [Local Descriptors Weighted Adaptive Threshold Filtering For Few-Shot Learning](https://arxiv.org/abs/2408.15924)
52. [LLaVA-MoD: Making LLaVA Tiny via MoE Knowledge Distillation](https://arxiv.org/abs/2408.15881)
53. [GenDDS: Generating Diverse Driving Video Scenarios with Prompt-to-Video Generative Model](https://arxiv.org/abs/2408.15868)
54. [Evaluating Named Entity Recognition Using Few-Shot Prompting with Large Language Models](https://arxiv.org/abs/2408.15796)
55. [A Survey on Evaluation of Multimodal Large Language Models](https://arxiv.org/abs/2408.15769)
56. [MambaPlace:Text-to-Point-Cloud Cross-Modal Place Recognition with Attention Mamba Mechanisms](https://arxiv.org/abs/2408.15740)
57. [Auxiliary-Loss-Free Load Balancing Strategy for Mixture-of-Experts](https://arxiv.org/abs/2408.15664)
58. [TeFF: Tracking-enhanced Forgetting-free Few-shot 3D LiDAR Semantic Segmentation](https://arxiv.org/abs/2408.15657)
59. [MMDRFuse: Distilled Mini-Model with Dynamic Refresh for Multi-Modality Image Fusion](https://arxiv.org/abs/2408.15641)
60. [Hierarchical Visual Categories Modeling: A Joint Representation Learning and Density Estimation Framework for Out-of-Distribution Detection](https://arxiv.org/abs/2408.15580)
61. [TagOOD: A Novel Approach to Out-of-Distribution Detection via Vision-Language Representations and Class Center Learning](https://arxiv.org/abs/2408.15566)
62. [SciLitLLM: How to Adapt LLMs for Scientific Literature Understanding](https://arxiv.org/abs/2408.15545)
63. [PromptSmooth: Certifying Robustness of Medical Vision-Language Models via Prompt Learning](https://arxiv.org/abs/2408.16769)
64. [SAM2Point: Segment Any 3D as Videos in Zero-shot and Promptable Manners](https://arxiv.org/abs/2408.16768)
65. [CSGO: Content-Style Composition in Text-to-Image Generation](https://arxiv.org/abs/2408.16766)
66. [Smaller, Weaker, Yet Better: Training LLM Reasoners via Compute-Optimal Sampling](https://arxiv.org/abs/2408.16737)
67. [Prediction-Feedback DETR for Temporal Action Detection](https://arxiv.org/abs/2408.16729)
68. [RLCP: A Reinforcement Learning-based Copyright Protection Method for Text-to-Image Diffusion Model](https://arxiv.org/abs/2408.16634)
69. [Seeking the Sufficiency and Necessity Causal Features in Multimodal Representation Learning](https://arxiv.org/abs/2408.16577)
70. [Adapting Vision-Language Models to Open Classes via Test-Time Prompt Tuning](https://arxiv.org/abs/2408.16486)
71. [A Comparative Study of Hyperparameter Tuning Methods](https://arxiv.org/abs/2408.16425)
72. [Neural Spectral Decomposition for Dataset Distillation](https://arxiv.org/abs/2408.16236)
73. [LLaVA-SG: Leveraging Scene Graphs as Visual Semantic Expression in Vision-Language Models](https://arxiv.org/abs/2408.16224)
74. [Training-free Video Temporal Grounding using Large-scale Pre-trained Models](https://arxiv.org/abs/2408.16219)
75. [DLM-VMTL:A Double Layer Mapper for heterogeneous data video Multi-task prompt learning](https://arxiv.org/abs/2408.16195)
76. [VLM4Bio: A Benchmark Dataset to Evaluate Pretrained Vision-Language Models for Trait Discovery from Biological Images](https://arxiv.org/abs/2408.16176)
77. [Using Backbone Foundation Model for Evaluating Fairness in Chest Radiography Without Demographic Data](https://arxiv.org/abs/2408.16130)
78. [A More Unified Theory of Transfer Learning](https://arxiv.org/abs/2408.16189)
1. [SAM2-UNet: Segment Anything 2 Makes Strong Encoder for Natural and Medical Image Segmentation](https://arxiv.org/abs/2408.08870)
2. [Visual Agents as Fast and Slow Thinkers](https://arxiv.org/abs/2408.08862)
3. [DPA: Dual Prototypes Alignment for Unsupervised Adaptation of Vision-Language Models](https://arxiv.org/abs/2408.08855)
4. [Retrieval-augmented Few-shot Medical Image Segmentation with Foundation Models](https://arxiv.org/abs/2408.08813)
5. [Adaptive Layer Selection for Efficient Vision Transformer Fine-Tuning](https://arxiv.org/abs/2408.08670)
6. [Extracting polygonal footprints in off-nadir images with Segment Anything Model](https://arxiv.org/abs/2408.08645)
7. [Learning A Low-Level Vision Generalist via Visual Task Prompt](https://arxiv.org/abs/2408.08601)
8. [Segment Anything for Videos: A Systematic Survey](https://arxiv.org/abs/2408.08315)
9. [Efficient Data-Sketches and Fine-Tuning for Early Detection of Distributional Drift in Medical Imaging](https://arxiv.org/abs/2408.08456)
10. [xGen-MM (BLIP-3): A Family of Open Large Multimodal Models](https://arxiv.org/abs/2408.08872)
11. [SMILE: Zero-Shot Sparse Mixture of Low-Rank Experts Construction From Pre-Trained Foundation Models](https://arxiv.org/abs/2408.10174)
12. [In-Context Learning with Representations: Contextual Generalization of Trained Transformers](https://arxiv.org/abs/2408.10147)
13. [Video Object Segmentation via SAM 2: The 4th Solution for LSVOS Challenge VOS Track](https://arxiv.org/abs/2408.10125)
14. [Exploiting Fine-Grained Prototype Distribution for Boosting Unsupervised Class Incremental Learning](https://arxiv.org/abs/2408.10046)
15. [CLIPCleaner: Cleaning Noisy Labels with CLIP](https://arxiv.org/abs/2408.10012)
16. ["Image, Tell me your story!" Predicting the original meta-context of visual misinformation](https://arxiv.org/abs/2408.09939)
17. [SAM-UNet:Enhancing Zero-Shot Segmentation of SAM for Universal Medical Images](https://arxiv.org/abs/2408.09886)
18. [R2GenCSR: Retrieving Context Samples for Large Language Model based X-ray Medical Report Generation](https://arxiv.org/abs/2408.09743)
19. [MePT: Multi-Representation Guided Prompt Tuning for Vision-Language Model](https://arxiv.org/abs/2408.09706)
20. [PA-LLaVA: A Large Language-Vision Assistant for Human Pathology Image Understanding](https://arxiv.org/abs/2408.09530)
21. [MedMAP: Promoting Incomplete Multi-modal Brain Tumor Segmentation with Alignment](https://arxiv.org/abs/2408.09465)
22. [Advancements in Molecular Property Prediction: A Survey of Single and Multimodal Approaches](https://arxiv.org/abs/2408.09461)
23. [CLIP-CID: Efficient CLIP Distillation via Cluster-Instance Discrimination](https://arxiv.org/abs/2408.09441)
24. [GoodSAM++: Bridging Domain and Capacity Gaps via Segment Anything Model for Panoramic Semantic Segmentation](https://arxiv.org/abs/2408.09115)
25. [Depth-guided Texture Diffusion for Image Semantic Segmentation](https://arxiv.org/abs/2408.09097)
26. [Learning to Route for Dynamic Adapter Composition in Continual Learning with Language Models](https://arxiv.org/abs/2408.09053)
27. [Towards Effective Authorship Attribution: Integrating Class-Incremental Learning](https://arxiv.org/abs/2408.08900)
28. [Cross-Species Data Integration for Enhanced Layer Segmentation in Kidney Pathology](https://arxiv.org/abs/2408.09278)
29. [U-MedSAM: Uncertainty-aware MedSAM for Medical Image Segmentation](https://arxiv.org/abs/2408.08881)
30. [A Survey on Symbolic Knowledge Distillation of Large Language Models](https://arxiv.org/abs/2408.10210)
31. [Scaling Law with Learning Rate Annealing](https://arxiv.org/abs/2408.11029)
32. [ViLReF: A Chinese Vision-Language Retinal Foundation Model](https://arxiv.org/abs/2408.10894)
33. [EELE: Exploring Efficient and Extensible LoRA Integration in Emotional Text-to-Speech](https://arxiv.org/abs/2408.10852)
34. [Representation Norm Amplification for Out-of-Distribution Detection in Long-Tail Learning](https://arxiv.org/abs/2408.10676)
35. [Subspace Prototype Guidance for Mitigating Class Imbalance in Point Cloud Semantic Segmentation](https://arxiv.org/abs/2408.10537)
36. [AIR: Analytic Imbalance Rectifier for Continual Learning](https://arxiv.org/abs/2408.10349)
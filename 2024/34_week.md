1. [SAM2-UNet: Segment Anything 2 Makes Strong Encoder for Natural and Medical Image Segmentation](https://arxiv.org/abs/2408.08870)
2. [Visual Agents as Fast and Slow Thinkers](https://arxiv.org/abs/2408.08862)
3. [DPA: Dual Prototypes Alignment for Unsupervised Adaptation of Vision-Language Models](https://arxiv.org/abs/2408.08855)
4. [Retrieval-augmented Few-shot Medical Image Segmentation with Foundation Models](https://arxiv.org/abs/2408.08813)
5. [Adaptive Layer Selection for Efficient Vision Transformer Fine-Tuning](https://arxiv.org/abs/2408.08670)
6. [Extracting polygonal footprints in off-nadir images with Segment Anything Model](https://arxiv.org/abs/2408.08645)
7. [Learning A Low-Level Vision Generalist via Visual Task Prompt](https://arxiv.org/abs/2408.08601)
8. [Segment Anything for Videos: A Systematic Survey](https://arxiv.org/abs/2408.08315)
9. [Efficient Data-Sketches and Fine-Tuning for Early Detection of Distributional Drift in Medical Imaging](https://arxiv.org/abs/2408.08456)
10. [xGen-MM (BLIP-3): A Family of Open Large Multimodal Models](https://arxiv.org/abs/2408.08872)
11. [SMILE: Zero-Shot Sparse Mixture of Low-Rank Experts Construction From Pre-Trained Foundation Models](https://arxiv.org/abs/2408.10174)
12. [In-Context Learning with Representations: Contextual Generalization of Trained Transformers](https://arxiv.org/abs/2408.10147)
13. [Video Object Segmentation via SAM 2: The 4th Solution for LSVOS Challenge VOS Track](https://arxiv.org/abs/2408.10125)
14. [Exploiting Fine-Grained Prototype Distribution for Boosting Unsupervised Class Incremental Learning](https://arxiv.org/abs/2408.10046)
15. [CLIPCleaner: Cleaning Noisy Labels with CLIP](https://arxiv.org/abs/2408.10012)
16. ["Image, Tell me your story!" Predicting the original meta-context of visual misinformation](https://arxiv.org/abs/2408.09939)
17. [SAM-UNet:Enhancing Zero-Shot Segmentation of SAM for Universal Medical Images](https://arxiv.org/abs/2408.09886)
18. [R2GenCSR: Retrieving Context Samples for Large Language Model based X-ray Medical Report Generation](https://arxiv.org/abs/2408.09743)
19. [MePT: Multi-Representation Guided Prompt Tuning for Vision-Language Model](https://arxiv.org/abs/2408.09706)
20. [PA-LLaVA: A Large Language-Vision Assistant for Human Pathology Image Understanding](https://arxiv.org/abs/2408.09530)
21. [MedMAP: Promoting Incomplete Multi-modal Brain Tumor Segmentation with Alignment](https://arxiv.org/abs/2408.09465)
22. [Advancements in Molecular Property Prediction: A Survey of Single and Multimodal Approaches](https://arxiv.org/abs/2408.09461)
23. [CLIP-CID: Efficient CLIP Distillation via Cluster-Instance Discrimination](https://arxiv.org/abs/2408.09441)
24. [GoodSAM++: Bridging Domain and Capacity Gaps via Segment Anything Model for Panoramic Semantic Segmentation](https://arxiv.org/abs/2408.09115)
25. [Depth-guided Texture Diffusion for Image Semantic Segmentation](https://arxiv.org/abs/2408.09097)
26. [Learning to Route for Dynamic Adapter Composition in Continual Learning with Language Models](https://arxiv.org/abs/2408.09053)
27. [Towards Effective Authorship Attribution: Integrating Class-Incremental Learning](https://arxiv.org/abs/2408.08900)
28. [Cross-Species Data Integration for Enhanced Layer Segmentation in Kidney Pathology](https://arxiv.org/abs/2408.09278)
29. [U-MedSAM: Uncertainty-aware MedSAM for Medical Image Segmentation](https://arxiv.org/abs/2408.08881)
30. [A Survey on Symbolic Knowledge Distillation of Large Language Models](https://arxiv.org/abs/2408.10210)
31. [Scaling Law with Learning Rate Annealing](https://arxiv.org/abs/2408.11029)
32. [ViLReF: A Chinese Vision-Language Retinal Foundation Model](https://arxiv.org/abs/2408.10894)
33. [EELE: Exploring Efficient and Extensible LoRA Integration in Emotional Text-to-Speech](https://arxiv.org/abs/2408.10852)
34. [Representation Norm Amplification for Out-of-Distribution Detection in Long-Tail Learning](https://arxiv.org/abs/2408.10676)
35. [Subspace Prototype Guidance for Mitigating Class Imbalance in Point Cloud Semantic Segmentation](https://arxiv.org/abs/2408.10537)
36. [AIR: Analytic Imbalance Rectifier for Continual Learning](https://arxiv.org/abs/2408.10349)
37. [SEA: Supervised Embedding Alignment for Token-Level Visual-Textual Integration in MLLMs](https://arxiv.org/abs/2408.11813)
38. [EmbodiedSAM: Online Segment Any 3D Thing in Real Time](https://arxiv.org/abs/2408.11811)
39. [DH-Bench: Probing Depth and Height Perception of Large Visual-Language Models](https://arxiv.org/abs/2408.11748)
40. [Open-Ended 3D Point Cloud Instance Segmentation](https://arxiv.org/abs/2408.11747)
41. [SAM-REF: Rethinking Image-Prompt Synergy for Refinement in Segment Anything](https://arxiv.org/abs/2408.11535)
42. [MSCPT: Few-shot Whole Slide Image Classification with Multi-scale and Context-focused Prompt Tuning](https://arxiv.org/abs/2408.11505)
43. [Clinical Context-aware Radiology Report Generation from Medical Images using Transformers](https://arxiv.org/abs/2408.11344)
44. [BURExtract-Llama: An LLM for Clinical Concept Extraction in Breast Ultrasound Reports](https://arxiv.org/abs/2408.11334)
45. [Making Large Vision Language Models to be Good Few-shot Learners](https://arxiv.org/abs/2408.11297)
46. [A Short Review and Evaluation of SAM2's Performance in 3D CT Image Segmentation](https://arxiv.org/abs/2408.11210)
47. [HMT-UNet: A hybird Mamba-Transformer Vision UNet for Medical Image Segmentation](https://arxiv.org/abs/2408.11289)
48. [Controllable Text Generation for Large Language Models: A Survey](https://arxiv.org/abs/2408.12599)
49. [Sapiens: Foundation for Human Vision Models](https://arxiv.org/abs/2408.12569)
50. [Generalized SAM: Efficient Fine-Tuning of SAM for Variable Input Image Sizes](https://arxiv.org/abs/2408.12406)
51. [SAM-SP: Self-Prompting Makes SAM Great Again](https://arxiv.org/abs/2408.12364)
52. [Rebalancing Multi-Label Class-Incremental Learning](https://arxiv.org/abs/2408.12161)
53. [Fast Training Dataset Attribution via In-Context Learning](https://arxiv.org/abs/2408.11852)
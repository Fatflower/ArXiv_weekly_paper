1. [OMG-Seg: Is One Model Good Enough For All Segmentation?](https://arxiv.org/abs/2401.10229)
2. [RAP-SAM: Towards Real-Time All-Purpose Segment Anything](https://arxiv.org/abs/2401.10228)
3. [ChatQA: Building GPT-4 Level Conversational QA Models](https://arxiv.org/abs/2401.10225)
4. [Supervised Fine-tuning in turn Improves Visual Foundation Models](https://arxiv.org/abs/2401.10222)
5. [AutoFT: Robust Fine-Tuning by Optimizing Hyperparameters on OOD Data](https://arxiv.org/abs/2401.10220)
6. [Edit One for All: Interactive Batch Image Editing](https://arxiv.org/abs/2401.10219)
7. [Divide and not forget: Ensemble of selectively trained experts in Continual Learning](https://arxiv.org/abs/2401.10191)
8. [Fast Kronecker Matrix-Matrix Multiplication on GPUs](https://arxiv.org/abs/2401.10187)
9. [Comprehensive OOD Detection Improvements](https://arxiv.org/abs/2401.10176)
10. [Evolutionary Computation in the Era of Large Language Model: Survey and Roadmap](https://arxiv.org/abs/2401.10034)
11. [Question-Answer Cross Language Image Matching for Weakly Supervised Semantic Segmentation](https://arxiv.org/abs/2401.09883)
12. [Boosting Few-Shot Segmentation via Instance-Aware Data Augmentation and Local Consensus Guided Cross Attention](https://arxiv.org/abs/2401.09866)
13. [Improving fine-grained understanding in image-text pre-training](https://arxiv.org/abs/2401.09865)
14. [Boosting Few-Shot Semantic Segmentation Via Segment Anything Model](https://arxiv.org/abs/2401.09826)
15. [SEINE: Structure Encoding and Interaction Network for Nuclei Instance Segmentation](https://arxiv.org/abs/2401.09773)
16. [SlideAVSR: A Dataset of Paper Explanation Videos for Audio-Visual Speech Recognition](https://arxiv.org/abs/2401.09759)
17. [HCVP: Leveraging Hierarchical Contrastive Visual Prompt for Domain Generalization](https://arxiv.org/abs/2401.09716)
18. [Improving Classification Performance With Human Feedback: Label a few, we label the rest](https://arxiv.org/abs/2401.09555)
19. [Learning to Generalize over Subpartitions for Heterogeneity-aware Domain Adaptive Nuclei Segmentation](https://arxiv.org/abs/2401.09496)
20. [Voila-A: Aligning Vision-Language Models with User's Gaze Attention](https://arxiv.org/abs/2401.09454)
21. [Sub2Full: split spectrum to boost OCT despeckling without clean data](https://arxiv.org/abs/2401.10128)
22. [Ventricular Segmentation: A Brief Comparison of U-Net Derivatives](https://arxiv.org/abs/2401.09980)
23. [CT Liver Segmentation via PVT-based Encoding and Refined Decoding](https://arxiv.org/abs/2401.09630)
24. [Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model](https://arxiv.org/abs/2401.09417)
25. [Beyond Anti-Forgetting: Multimodal Continual Instruction Tuning with Positive Forward Transfer](https://arxiv.org/abs/2401.09181)
26. [Remote Sensing ChatGPT: Solving Remote Sensing Tasks with ChatGPT and Visual Models](https://arxiv.org/abs/2401.09083)
27. [Cross-modality Guidance-aided Multi-modal Learning with Dual Attention for MRI Brain Tumor Grading](https://arxiv.org/abs/2401.09029)
28. [FedLoGe: Joint Local and Generic Federated Learning under Long-tailed Data](https://arxiv.org/abs/2401.08977)
29. [COCO is "ALL'' You Need for Visual Instruction Fine-tuning](https://arxiv.org/abs/2401.08968)
30. [B-Cos Aligned Transformers Learn Human-Interpretable Features](https://arxiv.org/abs/2401.08868)
31. [The Effect of Intrinsic Dataset Properties on Generalization: Unraveling Learning Differences Between Natural and Medical Images](https://arxiv.org/abs/2401.08865)
32. [Cross-Level Multi-Instance Distillation for Self-Supervised Fine-Grained Visual Categorization](https://arxiv.org/abs/2401.08860)
33. [Shabari: Delayed Decision-Making for Faster and Efficient Serverless Function](https://arxiv.org/abs/2401.08859)
34. [Improving ASR Contextual Biasing with Guided Attention](https://arxiv.org/abs/2401.08835)
35. [An Empirical Study of Counterfactual Visualization to Support Visual Causal Inference](https://arxiv.org/abs/2401.08822)
36. [Decoupled Prototype Learning for Reliable Test-Time Adaptation](https://arxiv.org/abs/2401.08703)
37. [Concept Alignment](https://arxiv.org/abs/2401.08672)
38. [Change Detection Between Optical Remote Sensing Imagery and Map Data via Segment Anything Model (SAM)](https://arxiv.org/abs/2401.09019)
39. [RIDGE: Reproducibility, Integrity, Dependability, Generalizability, and Efficiency Assessment of Medical Image Segmentation Models](https://arxiv.org/abs/2401.08847)
40. [Connect, Collapse, Corrupt: Learning Cross-Modal Tasks with Uni-Modal Data](https://arxiv.org/abs/2401.08567)
41. [ValUES: A Framework for Systematic Validation of Uncertainty Estimation in Semantic Segmentation](https://arxiv.org/abs/2401.08501)
42. [Instilling Multi-round Thinking to Text-guided Image Generation](https://arxiv.org/abs/2401.08472)
43. [Cross-Domain Few-Shot Segmentation via Iterative Support-Query Correspondence Mining](https://arxiv.org/abs/2401.08407)
44. [Hidden Flaws Behind Expert-Level Accuracy of GPT-4 Vision in Medicine](https://arxiv.org/abs/2401.08396)
45. [Generative Multi-Modal Knowledge Retrieval with Large Language Models](https://arxiv.org/abs/2401.08206)
46. [Completely Occluded and Dense Object Instance Segmentation Using Box Prompt-Based Segmentation Foundation Models](https://arxiv.org/abs/2401.08174)
47. [A Survey of Resource-efficient LLM and Multimodal Foundation Models](https://arxiv.org/abs/2401.08092)
48. [Foundation Models for Biomedical Image Segmentation: A Survey](https://arxiv.org/abs/2401.07654)
49. [PMFSNet: Polarized Multi-scale Feature Self-attention Network For Lightweight Medical Image Segmentation](https://arxiv.org/abs/2401.07579)
50. [Concept-Guided Prompt Learning for Generalization in Vision-Language Models](https://arxiv.org/abs/2401.07457)
51. [A Strong Inductive Bias: Gzip for binary image classification](https://arxiv.org/abs/2401.07392)
52. [MapGPT: Map-Guided Prompting for Unified Vision-and-Language Navigation](https://arxiv.org/abs/2401.07314)
53. [MIMIC: Mask Image Pre-training with Mix Contrastive Fine-tuning for Facial Expression Recognition](https://arxiv.org/abs/2401.07245)
54. [Dual-View Data Hallucination with Semantic Relation Guidance for Few-Shot Image Recognition](https://arxiv.org/abs/2401.07061)
55. [Beyond the Surface: A Global-Scale Analysis of Visual Stereotypes in Text-to-Image Generation](https://arxiv.org/abs/2401.06310)
56. [AffordanceLLM: Grounding Affordance from Vision Language Models](https://arxiv.org/abs/2401.06341)
57. [Enhancing Consistency and Mitigating Bias: A Data Replay Approach for Incremental Learning](https://arxiv.org/abs/2401.06548)
58. [APLe: Token-Wise Adaptive for Multi-Modal Prompt Learning](https://arxiv.org/abs/2401.06827)
59. [Enhanced Few-Shot Class-Incremental Learning via Ensemble Models](https://arxiv.org/abs/2401.07208)
60. [LLaVA-Phi: Efficient Multi-Modal Assistant with Small Language Model](https://arxiv.org/abs/2401.02330)
1. [Towards Zero-Shot Annotation of the Built Environment with Vision-Language Models (Vision Paper)](https://arxiv.org/abs/2408.00932)
2. [Medical SAM 2: Segment medical images as video via Segment Anything Model 2](https://arxiv.org/abs/2408.00874)
3. [PINNs for Medical Image Analysis: A Survey](https://arxiv.org/abs/2408.01026)
4. [Conditional LoRA Parameter Generation](https://arxiv.org/abs/2408.01415)
5. [Pre-trained Language Models Improve the Few-shot Prompt Ability of Decision Transformer](https://arxiv.org/abs/2408.01402)
6. [NOLO: Navigate Only Look Once](https://arxiv.org/abs/2408.01384)
7. [Balanced Residual Distillation Learning for 3D Point Cloud Class-Incremental Semantic Segmentation](https://arxiv.org/abs/2408.01356)
8. [Hallu-PI: Evaluating Hallucination in Multi-modal Large Language Models within Perturbed Inputs](https://arxiv.org/abs/2408.01355)
9. [A Survey of Mamba](https://arxiv.org/abs/2408.01129)
10. [Task Prompt Vectors: Effective Initialization through Multi-Task Soft-Prompt Transfer](https://arxiv.org/abs/2408.01119)
11. [Exploiting the Semantic Knowledge of Pre-trained Text-Encoders for Continual Learning](https://arxiv.org/abs/2408.01076)
12. [Boosting Gaze Object Prediction via Pixel-level Supervision from Vision Foundation Model](https://arxiv.org/abs/2408.01044)
13. [POA: Pre-training Once for Models of All Sizes](https://arxiv.org/abs/2408.01031)
14. [FBSDiff: Plug-and-Play Frequency Band Substitution of Diffusion Features for Highly Controllable Text-Driven Image Translation](https://arxiv.org/abs/2408.00998)
15. [Prototype Learning for Micro-gesture Classification](https://arxiv.org/abs/2408.03097)
16. [Diffusion Model Meets Non-Exemplar Class-Incremental Learning and Beyond](https://arxiv.org/abs/2408.02983)
17. [The Need for a Big World Simulator: A Scientific Challenge for Continual Learning](https://arxiv.org/abs/2408.02930)
18. [LLaVA-OneVision: Easy Visual Task Transfer](https://arxiv.org/abs/2408.03326)
19. [Biomedical SAM 2: Segment Anything in Biomedical Images and Videos](https://arxiv.org/abs/2408.03286)
20. [Learning to Learn without Forgetting using Attention](https://arxiv.org/abs/2408.03219)
21. [How Well Can Vision Language Models See Image Details?](https://arxiv.org/abs/2408.03940)
22. [AdapMTL: Adaptive Pruning Framework for Multitask Learning Model](https://arxiv.org/abs/2408.03913)
23. [Target Prompting for Information Extraction with Vision Language Model](https://arxiv.org/abs/2408.03834)
24. [AI Foundation Models in Remote Sensing: A Survey](https://arxiv.org/abs/2408.03464)
25. [SAM2-PATH: A better segment anything model for semantic segmentation in digital pathology](https://arxiv.org/abs/2408.03651)
26. [Distillation Learning Guided by Image Reconstruction for One-Shot Medical Image Segmentation](https://arxiv.org/abs/2408.03616)
27. [Transformer Explainer: Interactive Learning of Text-Generative Models](https://arxiv.org/abs/2408.04619)
28. [Img-Diff: Contrastive Data Synthesis for Multimodal Large Language Models](https://arxiv.org/abs/2408.04594)
29. [Learn To Learn More Precisely](https://arxiv.org/abs/2408.04590)
30. [Unveiling the Power of Sparse Neural Networks for Feature Selection](https://arxiv.org/abs/2408.04583)
31. [SAM2-Adapter: Evaluating & Adapting Segment Anything 2 in Downstream Tasks: Camouflage, Shadow, Medical Image Segmentation, and More](https://arxiv.org/abs/2408.04579)
32. [How Transformers Utilize Multi-Head Attention in In-Context Learning? A Case Study on Sparse Linear Regression](https://arxiv.org/abs/2408.04532)
33. [What could go wrong? Discovering and describing failure modes in computer vision](https://arxiv.org/abs/2408.04471)
34. [MM-Forecast: A Multimodal Approach to Temporal Event Forecasting with Large Language Models](https://arxiv.org/abs/2408.04388)
35. [AggSS: An Aggregated Self-Supervised Approach for Class-Incremental Learning](https://arxiv.org/abs/2408.04347)
36. [CoBooM: Codebook Guided Bootstrapping for Medical Image Representation Learning](https://arxiv.org/abs/2408.04262)
37. [ComKD-CLIP: Comprehensive Knowledge Distillation for Contrastive Language-Image Pre-traning Model](https://arxiv.org/abs/2408.04145)
38. [Is SAM 2 Better than SAM in Medical Image Segmentation?](https://arxiv.org/abs/2408.04212)
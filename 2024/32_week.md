1. [Towards Zero-Shot Annotation of the Built Environment with Vision-Language Models (Vision Paper)](https://arxiv.org/abs/2408.00932)
2. [Medical SAM 2: Segment medical images as video via Segment Anything Model 2](https://arxiv.org/abs/2408.00874)
3. [PINNs for Medical Image Analysis: A Survey](https://arxiv.org/abs/2408.01026)
4. [Conditional LoRA Parameter Generation](https://arxiv.org/abs/2408.01415)
5. [Pre-trained Language Models Improve the Few-shot Prompt Ability of Decision Transformer](https://arxiv.org/abs/2408.01402)
6. [NOLO: Navigate Only Look Once](https://arxiv.org/abs/2408.01384)
7. [Balanced Residual Distillation Learning for 3D Point Cloud Class-Incremental Semantic Segmentation](https://arxiv.org/abs/2408.01356)
8. [Hallu-PI: Evaluating Hallucination in Multi-modal Large Language Models within Perturbed Inputs](https://arxiv.org/abs/2408.01355)
9. [A Survey of Mamba](https://arxiv.org/abs/2408.01129)
10. [Task Prompt Vectors: Effective Initialization through Multi-Task Soft-Prompt Transfer](https://arxiv.org/abs/2408.01119)
11. [Exploiting the Semantic Knowledge of Pre-trained Text-Encoders for Continual Learning](https://arxiv.org/abs/2408.01076)
12. [Boosting Gaze Object Prediction via Pixel-level Supervision from Vision Foundation Model](https://arxiv.org/abs/2408.01044)
13. [POA: Pre-training Once for Models of All Sizes](https://arxiv.org/abs/2408.01031)
14. [FBSDiff: Plug-and-Play Frequency Band Substitution of Diffusion Features for Highly Controllable Text-Driven Image Translation](https://arxiv.org/abs/2408.00998)
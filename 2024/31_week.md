1. [Benchmarking Dependence Measures to Prevent Shortcut Learning in Medical Imaging](https://arxiv.org/abs/2407.18792)
2. [Constructing Enhanced Mutual Information for Online Class-Incremental Learning](https://arxiv.org/abs/2407.18526)
3. [AI Safety in Generative AI Large Language Models: A Survey](https://arxiv.org/abs/2407.18369)
4. [Towards A Generalizable Pathology Foundation Model via Unified Knowledge Distillation](https://arxiv.org/abs/2407.18449)
5. [Reproducibility Study of "ITI-GEN: Inclusive Text-to-Image Generation"](https://arxiv.org/abs/2407.19996)
6. [HOBOTAN: Efficient Higher Order Binary Optimization Solver with Tensor Networks and PyTorch](https://arxiv.org/abs/2407.19987)
7. [Mixture of Nested Experts: Adaptive Processing of Visual Tokens](https://arxiv.org/abs/2407.19985)
8. [Self-Supervised Learning for Text Recognition: A Critical Survey](https://arxiv.org/abs/2407.19889)
9. [Yucca: A Deep Learning Framework For Medical Image Analysis](https://arxiv.org/abs/2407.19888)
10. [Normality Addition via Normality Detection in Industrial Image Anomaly Detection Models](https://arxiv.org/abs/2407.19849)
11. [ML-Mamba: Efficient Multi-Modal Large Language Model Utilizing Mamba-2](https://arxiv.org/abs/2407.19832)
12. [Cool-Fusion: Fuse Large Language Models without Training](https://arxiv.org/abs/2407.19807)
13. [VolDoGer: LLM-assisted Datasets for Domain Generalization in Vision-Language Tasks](https://arxiv.org/abs/2407.19795)
14. [Multimodal Large Language Models for Bioimage Analysis](https://arxiv.org/abs/2407.19778)
15. [Harnessing Large Vision and Language Models in Agriculture: A Review](https://arxiv.org/abs/2407.19679)
16. [ComNeck: Bridging Compressed Image Latents and Multimodal LLMs via Universal Transform-Neck](https://arxiv.org/abs/2407.19651)
17. [Forecast-PEFT: Parameter-Efficient Fine-Tuning for Pre-trained Motion Forecasting Models](https://arxiv.org/abs/2407.19564)
18. [XLIP: Cross-modal Attention Masked Modelling for Medical Language-Image Pre-Training](https://arxiv.org/abs/2407.19546)
19. [Large-scale cervical precancerous screening via AI-assisted cytology whole slide image analysis](https://arxiv.org/abs/2407.19512)
20. [Visual Riddles: a Commonsense and World Knowledge Challenge for Large Vision and Language Models](https://arxiv.org/abs/2407.19474)
21. [LLAVADI: What Matters For Multimodal Large Language Models Distillation](https://arxiv.org/abs/2407.19409)
22. [Faster Image2Video Generation: A Closer Look at CLIP Image Embedding's Impact on Spatio-Temporal Cross-Attentions](https://arxiv.org/abs/2407.19205)
23. [LLaVA-Read: Enhancing Reading Ability of Multimodal Language Models](https://arxiv.org/abs/2407.19185)
24. [Region Guided Attention Network for Retinal Vessel Segmentation](https://arxiv.org/abs/2407.18970)
25. [Optimising Hard Prompts with Few-Shot Meta-Prompting](https://arxiv.org/abs/2407.18920)
26. [Diffusion Feedback Helps CLIP See Better](https://arxiv.org/abs/2407.20171)
27. [CLEFT: Language-Image Contrastive Learning with Efficient Large Language Model and Prompt Fine-Tuning](https://arxiv.org/abs/2407.21011)
28. [GABInsight: Exploring Gender-Activity Binding Bias in Vision-Language Models](https://arxiv.org/abs/2407.21001)
29. [MoFO: Momentum-Filtered Optimizer for Mitigating Forgetting in LLM Fine-Tuning](https://arxiv.org/abs/2407.20999)
30. [An Effective Dynamic Gradient Calibration Method for Continual Learning](https://arxiv.org/abs/2407.20956)
31. [UniProcessor: A Text-induced Unified Low-level Image Processor](https://arxiv.org/abs/2407.20928)
32. [Diffusion Augmented Agents: A Framework for Efficient Exploration and Transfer Learning](https://arxiv.org/abs/2407.20798)
33. [SynthVLM: High-Efficiency and High-Quality Synthetic Data for Vision Language Models](https://arxiv.org/abs/2407.20756)
34. [Label-Guided Prompt for Multi-label Few-shot Aspect Category Detection](https://arxiv.org/abs/2407.20673)
35. [Machine Unlearning in Generative AI: A Survey](https://arxiv.org/abs/2407.20516)
36. [Generalized Out-of-Distribution Detection and Beyond in Vision Language Model Era: A Survey](https://arxiv.org/abs/2407.21794)
37. [The Llama 3 Herd of Models](https://arxiv.org/abs/2407.21783)
38. [Paying More Attention to Image: A Training-Free Method for Alleviating Hallucination in LVLMs](https://arxiv.org/abs/2407.21771)
39. [ReplanVLM: Replanning Robotic Tasks with Visual Language Models](https://arxiv.org/abs/2407.21762)
40. [HGOE: Hybrid External and Internal Graph Outlier Exposure for Graph Out-of-Distribution Detection](https://arxiv.org/abs/2407.21742)
41. [A Federated Learning-Friendly Approach for Parameter-Efficient Fine-Tuning of SAM in 3D Segmentation](https://arxiv.org/abs/2407.21739)
42. [Open-Vocabulary Audio-Visual Semantic Segmentation](https://arxiv.org/abs/2407.21721)
43. [Synthetic Simplicity: Unveiling Bias in Medical Data Augmentation](https://arxiv.org/abs/2407.21674)
44. [MTA-CLIP: Language-Guided Semantic Segmentation with Mask-Text Alignment](https://arxiv.org/abs/2407.21654)
45. [Evaluating SAM2's Role in Camouflaged Object Detection: From SAM to SAM2](https://arxiv.org/abs/2407.21596)
46. [Adaptive Mix for Semi-Supervised Medical Image Segmentation](https://arxiv.org/abs/2407.21586)
47. [PMoE: Progressive Mixture of Experts with Asymmetric Transformer for Continual Learning](https://arxiv.org/abs/2407.21571)
48. [ControlMLLM: Training-Free Visual Prompt Learning for Multimodal Large Language Models](https://arxiv.org/abs/2407.21534)
49. [VIPeR: Visual Incremental Place Recognition with Adaptive Mining and Lifelong Learning](https://arxiv.org/abs/2407.21416)
50. [Pathology Foundation Models](https://arxiv.org/abs/2407.21317)
51. [Robust Box Prompt based SAM for Medical Image Segmentation](https://arxiv.org/abs/2407.21284)
52. [Bailicai: A Domain-Optimized Retrieval-Augmented Generation Framework for Medical Applications](https://arxiv.org/abs/2407.21055)
53. [CP-Prompt: Composition-Based Cross-modal Prompting for Domain-Incremental Continual Learning](https://arxiv.org/abs/2407.21043)
54. [Direct Unlearning Optimization for Robust and Safe Text-to-Image Models](https://arxiv.org/abs/2407.21035)
55. [MSA2Net: Multi-scale Adaptive Attention-guided Network for Medical Image Segmentation](https://arxiv.org/abs/2407.21640)
56. [MIST: A Simple and Scalable End-To-End 3D Medical Imaging Segmentation Framework](https://arxiv.org/abs/2407.21343)
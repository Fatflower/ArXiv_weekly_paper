1. [The FIX Benchmark: Extracting Features Interpretable to eXperts](https://arxiv.org/abs/2409.13684)
2. [OATS: Outlier-Aware Pruning Through Sparse and Low Rank Decomposition](https://arxiv.org/abs/2409.13652)
3. [Beyond Accuracy Optimization: Computer Vision Losses for Large Language Model Fine-Tuning](https://arxiv.org/abs/2409.13641)
4. [Exploring Fine-Grained Image-Text Alignment for Referring Remote Sensing Image Segmentation](https://arxiv.org/abs/2409.13637)
5. [YesBut: A High-Quality Annotated Multimodal Dataset for evaluating Satire Comprehension capability of Vision-Language Models](https://arxiv.org/abs/2409.13592)
6. [Graph Similarity Regularized Softmax for Semi-Supervised Node Classification](https://arxiv.org/abs/2409.13544)
7. [Formula-Supervised Visual-Geometric Pre-training](https://arxiv.org/abs/2409.13535)
8. [A Survey on Moral Foundation Theory and Pre-Trained Language Models: Current Advances and Challenges](https://arxiv.org/abs/2409.13521)
9. [PointSAM: Pointly-Supervised Segment Anything Model for Remote Sensing Images](https://arxiv.org/abs/2409.13401)
10. [Adaptive Margin Global Classifier for Exemplar-Free Class-Incremental Learning](https://arxiv.org/abs/2409.13275)
11. [CFSP: An Efficient Structured Pruning Framework for LLMs with Coarse-to-Fine Activation Information](https://arxiv.org/abs/2409.13199)
12. [Multiscale Encoder and Omni-Dimensional Dynamic Convolution Enrichment in nnU-Net for Brain Tumor Segmentation](https://arxiv.org/abs/2409.13229)
13. [GASA-UNet: Global Axial Self-Attention U-Net for 3D Medical Image Segmentation](https://arxiv.org/abs/2409.13146)
14. [BrainDreamer: Reasoning-Coherent and Controllable Image Generation from EEG Brain Signals via Language Guidance](https://arxiv.org/abs/2409.14021)
15. [Multiple-Exit Tuning: Towards Inference-Efficient Adaptation for Vision Transformer](https://arxiv.org/abs/2409.13999)
16. [Enhanced Semantic Segmentation for Large-Scale and Imbalanced Point Clouds](https://arxiv.org/abs/2409.13983)
17. [Cycle-Consistency Uncertainty Estimation for Visual Prompting based One-Shot Defect Segmentation](https://arxiv.org/abs/2409.13984)
18. [Rule Extrapolation in Language Models: A Study of Compositional Generalization on OOD Prompts](https://arxiv.org/abs/2409.13728)
19. [Towards Ground-truth-free Evaluation of Any Segmentation in Medical Images](https://arxiv.org/abs/2409.14874)
20. [Region Mixup](https://arxiv.org/abs/2409.15028)
21. [Multi-Modal Generative AI: Multi-modal LLM, Diffusion and Beyond](https://arxiv.org/abs/2409.14993)
22. [Dynamic Integration of Task-Specific Adapters for Class Incremental Learning](https://arxiv.org/abs/2409.14983)
23. [A-VL: Adaptive Attention for Large Vision-Language Models](https://arxiv.org/abs/2409.14846)
24. [VLM's Eye Examination: Instruct and Inspect Visual Competency of Vision Language Models](https://arxiv.org/abs/2409.14759)
25. [MemeCLIP: Leveraging CLIP Representations for Multimodal Meme Classification](https://arxiv.org/abs/2409.14703)
26. [Patch Ranking: Efficient CLIP by Learning to Rank Local Patches](https://arxiv.org/abs/2409.14607)
27. [The Imperative of Conversation Analysis in the Era of LLMs: A Survey of Tasks, Techniques, and Trends](https://arxiv.org/abs/2409.14195)
28. [PixWizard: Versatile Image-to-Image Visual Assistant with Open-Language Instructions](https://arxiv.org/abs/2409.15278)
29. [A Preliminary Study of o1 in Medicine: Are We Closer to an AI Doctor?](https://arxiv.org/abs/2409.15277)
30. [ReVLA: Reverting Visual Domain Limitation of Robotic Foundation Models](https://arxiv.org/abs/2409.15250)
31. [Aided design of bridge aesthetics based on Stable Diffusion fine-tuning](https://arxiv.org/abs/2409.15812)
32. [DIAL: Dense Image-text ALignment for Weakly Supervised Semantic Segmentation](https://arxiv.org/abs/2409.15801)
33. [TFG: Unified Training-Free Guidance for Diffusion Models](https://arxiv.org/abs/2409.15761)
34. [Making Text Embedders Few-Shot Learners](https://arxiv.org/abs/2409.15700)
35. [Clinical-grade Multi-Organ Pathology Report Generation for Multi-scale Whole Slide Images via a Semantically Guided Medical Text Foundation Model](https://arxiv.org/abs/2409.15574)
36. [Critic Loss for Image Classification](https://arxiv.org/abs/2409.15565)
37. [VLMine: Long-Tail Data Mining with Vision Language Models](https://arxiv.org/abs/2409.15486)
38. [Visual Prompting in Multimodal Large Language Models: A Survey](https://arxiv.org/abs/2409.15310)
39. [CAD: Memory Efficient Convolutional Adapter for Segment Anything](https://arxiv.org/abs/2409.15889)
40. [Zero-Shot Detection of AI-Generated Images](https://arxiv.org/abs/2409.15875)
41. [Bridging Environments and Language with Rendering Functions and Vision-Language Models](https://arxiv.org/abs/2409.16024)
42. [Unleashing the Potential of Synthetic Images: A Study on Histopathology Image Classification](https://arxiv.org/abs/2409.16002)
43. [Exploring the Impact of Outlier Variability on Anomaly Detection Evaluation Metrics](https://arxiv.org/abs/2409.15986)
44. [Articulated Object Manipulation using Online Axis Estimation with SAM2-Based Tracking](https://arxiv.org/abs/2409.16287)
45. [Label-Augmented Dataset Distillation](https://arxiv.org/abs/2409.16239)
46. [Fine-Tuning is Fine, if Calibrated](https://arxiv.org/abs/2409.16223)
47. [Segmentation Strategies in Deep Learning for Prostate Cancer Diagnosis: A Comparative Study of Mamba, SAM, and YOLO](https://arxiv.org/abs/2409.16205)
48. [HA-FGOVD: Highlighting Fine-grained Attributes via Explicit Linear Composition for Open-Vocabulary Object Detection](https://arxiv.org/abs/2409.16136)
49. [VisioPhysioENet: Multimodal Engagement Detection using Visual and Physiological Signals](https://arxiv.org/abs/2409.16126)
50. [Multi-View and Multi-Scale Alignment for Contrastive Language-Image Pre-training in Mammography](https://arxiv.org/abs/2409.18119)
51. [Cascade Prompt Learning for Vision-Language Model Adaptation](https://arxiv.org/abs/2409.17805)
52. [EM-Net: Efficient Channel and Frequency Learning with Mamba for 3D Medical Image Segmentation](https://arxiv.org/abs/2409.17675)
53. [Revisiting Deep Ensemble Uncertainty for Enhanced Medical Anomaly Detection](https://arxiv.org/abs/2409.17485)
54. [AgMTR: Agent Mining Transformer for Few-shot Segmentation in Remote Sensing](https://arxiv.org/abs/2409.17453)
55. [Rejection Sampling IMLE: Designing Priors for Better Few-Shot Image Synthesis](https://arxiv.org/abs/2409.17439)
56. [Block Expanded DINORET: Adapting Natural Domain Foundation Models for Retinal Imaging Without Catastrophic Forgetting](https://arxiv.org/abs/2409.17332)
57. [VL4AD: Vision-Language Models Improve Pixel-wise Anomaly Detection](https://arxiv.org/abs/2409.17330)
58. [Global-Local Medical SAM Adaptor Based on Full Adaption](https://arxiv.org/abs/2409.17486)
59. [Attention Prompting on Image for Large Vision-Language Models](https://arxiv.org/abs/2409.17143)
60. [Text2CAD: Generating Sequential CAD Models from Beginner-to-Expert Level Text Prompts](https://arxiv.org/abs/2409.17106)
61. [DALDA: Data Augmentation Leveraging Diffusion Model and LLM with Adaptive Guidance Scaling](https://arxiv.org/abs/2409.16949)
62. [The Role of Language Models in Modern Healthcare: A Comprehensive Review](https://www.arxiv.org/abs/2409.16860)
63. [EAGLE: Towards Efficient Arbitrary Referring Visual Prompts Comprehension for Multimodal Large Language Models](https://arxiv.org/abs/2409.16723)
64. [Vision-Language Model Fine-Tuning via Simple Parameter-Efficient Modification](https://arxiv.org/abs/2409.16718)
65. [Prompt Sliders for Fine-Grained Control, Editing and Erasing of Concepts in Diffusion Models](https://arxiv.org/abs/2409.16535)
66. [A Unified Hallucination Mitigation Framework for Large Vision-Language Models](https://www.arxiv.org/abs/2409.16494)
67. [Classification of Gleason Grading in Prostate Cancer Histopathology Images Using Deep Learning Techniques: YOLO, Vision Transformers, and Vision Mamba](https://arxiv.org/abs/2409.17122)
68. [Scalable Ensemble Diversification for OOD Generalization and Detection](https://arxiv.org/abs/2409.16797)
69. [SDCL: Students Discrepancy-Informed Correction Learning for Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2409.16728)
70. [Lessons Learned from a Unifying Empirical Study of Parameter-Efficient Transfer Learning (PETL) in Visual Recognition](https://arxiv.org/abs/2409.16434)
71. [Patch-Based Contrastive Learning and Memory Consolidation for Online Unsupervised Continual Learning](https://arxiv.org/abs/2409.16391)
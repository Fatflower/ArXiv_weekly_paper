1. [The FIX Benchmark: Extracting Features Interpretable to eXperts](https://arxiv.org/abs/2409.13684)
2. [OATS: Outlier-Aware Pruning Through Sparse and Low Rank Decomposition](https://arxiv.org/abs/2409.13652)
3. [Beyond Accuracy Optimization: Computer Vision Losses for Large Language Model Fine-Tuning](https://arxiv.org/abs/2409.13641)
4. [Exploring Fine-Grained Image-Text Alignment for Referring Remote Sensing Image Segmentation](https://arxiv.org/abs/2409.13637)
5. [YesBut: A High-Quality Annotated Multimodal Dataset for evaluating Satire Comprehension capability of Vision-Language Models](https://arxiv.org/abs/2409.13592)
6. [Graph Similarity Regularized Softmax for Semi-Supervised Node Classification](https://arxiv.org/abs/2409.13544)
7. [Formula-Supervised Visual-Geometric Pre-training](https://arxiv.org/abs/2409.13535)
8. [A Survey on Moral Foundation Theory and Pre-Trained Language Models: Current Advances and Challenges](https://arxiv.org/abs/2409.13521)
9. [PointSAM: Pointly-Supervised Segment Anything Model for Remote Sensing Images](https://arxiv.org/abs/2409.13401)
10. [Adaptive Margin Global Classifier for Exemplar-Free Class-Incremental Learning](https://arxiv.org/abs/2409.13275)
11. [CFSP: An Efficient Structured Pruning Framework for LLMs with Coarse-to-Fine Activation Information](https://arxiv.org/abs/2409.13199)
12. [Multiscale Encoder and Omni-Dimensional Dynamic Convolution Enrichment in nnU-Net for Brain Tumor Segmentation](https://arxiv.org/abs/2409.13229)
13. [GASA-UNet: Global Axial Self-Attention U-Net for 3D Medical Image Segmentation](https://arxiv.org/abs/2409.13146)
14. [BrainDreamer: Reasoning-Coherent and Controllable Image Generation from EEG Brain Signals via Language Guidance](https://arxiv.org/abs/2409.14021)
15. [Multiple-Exit Tuning: Towards Inference-Efficient Adaptation for Vision Transformer](https://arxiv.org/abs/2409.13999)
16. [Enhanced Semantic Segmentation for Large-Scale and Imbalanced Point Clouds](https://arxiv.org/abs/2409.13983)
17. [Cycle-Consistency Uncertainty Estimation for Visual Prompting based One-Shot Defect Segmentation](https://arxiv.org/abs/2409.13984)
18. [Rule Extrapolation in Language Models: A Study of Compositional Generalization on OOD Prompts](https://arxiv.org/abs/2409.13728)
19. [Towards Ground-truth-free Evaluation of Any Segmentation in Medical Images](https://arxiv.org/abs/2409.14874)
20. [Region Mixup](https://arxiv.org/abs/2409.15028)
21. [Multi-Modal Generative AI: Multi-modal LLM, Diffusion and Beyond](https://arxiv.org/abs/2409.14993)
22. [Dynamic Integration of Task-Specific Adapters for Class Incremental Learning](https://arxiv.org/abs/2409.14983)
23. [A-VL: Adaptive Attention for Large Vision-Language Models](https://arxiv.org/abs/2409.14846)
24. [VLM's Eye Examination: Instruct and Inspect Visual Competency of Vision Language Models](https://arxiv.org/abs/2409.14759)
25. [MemeCLIP: Leveraging CLIP Representations for Multimodal Meme Classification](https://arxiv.org/abs/2409.14703)
26. [Patch Ranking: Efficient CLIP by Learning to Rank Local Patches](https://arxiv.org/abs/2409.14607)
27. [The Imperative of Conversation Analysis in the Era of LLMs: A Survey of Tasks, Techniques, and Trends](https://arxiv.org/abs/2409.14195)
28. [PixWizard: Versatile Image-to-Image Visual Assistant with Open-Language Instructions](https://arxiv.org/abs/2409.15278)
29. [A Preliminary Study of o1 in Medicine: Are We Closer to an AI Doctor?](https://arxiv.org/abs/2409.15277)
30. [ReVLA: Reverting Visual Domain Limitation of Robotic Foundation Models](https://arxiv.org/abs/2409.15250)
31. [Aided design of bridge aesthetics based on Stable Diffusion fine-tuning](https://arxiv.org/abs/2409.15812)
32. [DIAL: Dense Image-text ALignment for Weakly Supervised Semantic Segmentation](https://arxiv.org/abs/2409.15801)
33. [TFG: Unified Training-Free Guidance for Diffusion Models](https://arxiv.org/abs/2409.15761)
34. [Making Text Embedders Few-Shot Learners](https://arxiv.org/abs/2409.15700)
35. [Clinical-grade Multi-Organ Pathology Report Generation for Multi-scale Whole Slide Images via a Semantically Guided Medical Text Foundation Model](https://arxiv.org/abs/2409.15574)
36. [Critic Loss for Image Classification](https://arxiv.org/abs/2409.15565)
37. [VLMine: Long-Tail Data Mining with Vision Language Models](https://arxiv.org/abs/2409.15486)
38. [Visual Prompting in Multimodal Large Language Models: A Survey](https://arxiv.org/abs/2409.15310)
39. [CAD: Memory Efficient Convolutional Adapter for Segment Anything](https://arxiv.org/abs/2409.15889)
40. [Zero-Shot Detection of AI-Generated Images](https://arxiv.org/abs/2409.15875)
41. [Bridging Environments and Language with Rendering Functions and Vision-Language Models](https://arxiv.org/abs/2409.16024)
42. [Unleashing the Potential of Synthetic Images: A Study on Histopathology Image Classification](https://arxiv.org/abs/2409.16002)
43. [Exploring the Impact of Outlier Variability on Anomaly Detection Evaluation Metrics](https://arxiv.org/abs/2409.15986)
44. [Articulated Object Manipulation using Online Axis Estimation with SAM2-Based Tracking](https://arxiv.org/abs/2409.16287)
45. [Label-Augmented Dataset Distillation](https://arxiv.org/abs/2409.16239)
46. [Fine-Tuning is Fine, if Calibrated](https://arxiv.org/abs/2409.16223)
47. [Segmentation Strategies in Deep Learning for Prostate Cancer Diagnosis: A Comparative Study of Mamba, SAM, and YOLO](https://arxiv.org/abs/2409.16205)
48. [HA-FGOVD: Highlighting Fine-grained Attributes via Explicit Linear Composition for Open-Vocabulary Object Detection](https://arxiv.org/abs/2409.16136)
49. [VisioPhysioENet: Multimodal Engagement Detection using Visual and Physiological Signals](https://arxiv.org/abs/2409.16126)
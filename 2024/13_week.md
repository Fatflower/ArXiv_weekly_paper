1. [Defying Imbalanced Forgetting in Class Incremental Learning](https://arxiv.org/abs/2403.14910)
2. [VidLA: Video-Language Alignment at Scale](https://arxiv.org/abs/2403.14870)
3. [Few-Shot Adversarial Prompt Learning on Vision-Language Models](https://arxiv.org/abs/2403.14774)
4. [Foundation Models for Time Series Analysis: A Tutorial and Survey](https://arxiv.org/abs/2403.14735)
5. [A Moral Imperative: The Need for Continual Superalignment of Large Language Models](https://arxiv.org/abs/2403.14683)
6. [Analysing Diffusion Segmentation for Medical Images](https://arxiv.org/abs/2403.14440)
7. [DiffusionMTL: Learning Multi-Task Denoising Diffusion Model from Partially Annotated Data](https://arxiv.org/abs/2403.15389)
8. [Long-CLIP: Unlocking the Long-Text Capability of CLIP](https://arxiv.org/abs/2403.15378)
9. [Can large language models explore in-context?](https://arxiv.org/abs/2403.15371)
10. [Hyperbolic Metric Learning for Visual Outlier Detection](https://arxiv.org/abs/2403.15260)
11. [Early Period of Training Impacts Out-of-Distribution Generalization](https://arxiv.org/abs/2403.15210)
12. [IFSENet : Harnessing Sparse Iterations for Interactive Few-shot Segmentation Excellence](https://arxiv.org/abs/2403.15089)
13. [Continual Vision-and-Language Navigation](https://arxiv.org/abs/2403.15049)
14. [DreamLIP: Language-Image Pre-training with Long Captions](https://arxiv.org/abs/2403.17007)
15. [Be Yourself: Bounded Attention for Multi-Subject Text-to-Image Generation](https://arxiv.org/abs/2403.16990)
16. [Hyperspherical Classification with Dynamic Label-to-Prototype Assignment](https://arxiv.org/abs/2403.16937)
17. [Clustering Propagation for Universal Medical Image Segmentation](https://arxiv.org/abs/2403.16646)
18. [SegICL: A Universal In-context Learning Framework for Enhanced Segmentation in Medical Imaging](https://arxiv.org/abs/2403.16578)
19. [LLMs Are Few-Shot In-Context Low-Resource Language Learners](https://arxiv.org/abs/2403.16512)
20. [Learning To Guide Human Decision Makers With Vision-Language Models](https://arxiv.org/abs/2403.16501)
21. [FlashEval: Towards Fast and Accurate Evaluation of Text-to-image Diffusion Generative Models](https://arxiv.org/abs/2403.16379)
22. [Large Language Models in Biomedical and Health Informatics: A Bibliometric Review](https://arxiv.org/abs/2403.16303)
23. [Exemplar-Free Class Incremental Learning via Incremental Representation](https://arxiv.org/abs/2403.16221)
24. [ALoRA: Allocating Low-Rank Adaptation for Fine-tuning Large Language Models](https://arxiv.org/abs/2403.16187)
25. [Enhancing Visual Continual Learning with Language-Guided Supervision](https://arxiv.org/abs/2403.16124)
26. [Leveraging Zero-Shot Prompting for Efficient Language Model Distillation](https://arxiv.org/abs/2403.15886)
27. [G-ACIL: Analytic Learning for Exemplar-Free Generalized Class Incremental Learning](https://arxiv.org/abs/2403.15706)
28. [RetiGen: A Framework for Generalized Retinal Diagnosis Using Multi-View Fundus Images](https://arxiv.org/abs/2403.15647)
29. [FairerCLIP: Debiasing CLIP's Zero-Shot Predictions using Functions in RKHSs](https://arxiv.org/abs/2403.15593)
30. [MedPromptX: Grounded Multimodal Prompting for Chest X-ray Diagnosis](https://arxiv.org/abs/2403.15585)
31. [Learning to Infer Generative Template Programs for Visual Concepts](https://arxiv.org/abs/2403.15476)
32. [Unveiling the Anomalies in an Ever-Changing World: A Benchmark for Pixel-Level Anomaly Detection in Continual Learning](https://arxiv.org/abs/2403.15463)
33. [What Are Tools Anyway? A Survey from the Language Model Perspective](https://arxiv.org/abs/2403.15452)
34. [RSTAR: Rotational Streak Artifact Reduction in 4D CBCT using Separable and Circular Convolutions](https://arxiv.org/abs/2403.16361)
35. [Supervised Learning via Ensembles of Diverse Functional Representations: the Functional Voting Classifier](https://arxiv.org/abs/2403.15778)
36. [3D-TransUNet for Brain Metastases Segmentation in the BraTS2023 Challenge](https://arxiv.org/abs/2403.15735)
37. [RSMamba: Remote Sensing Image Classification with State Space Model](https://arxiv.org/abs/2403.19654)
38. [Siamese Vision Transformers are Scalable Audio-visual Learners](https://arxiv.org/abs/2403.19638)
39. [Enhance Image Classification via Inter-Class Image Mixup with Diffusion Model](https://arxiv.org/abs/2403.19600)
40. [DenseNets Reloaded: Paradigm Shift Beyond ResNets and ViTs](https://arxiv.org/abs/2403.19588)
41. [Sine Activated Low-Rank Matrices for Parameter Efficient Learning](https://arxiv.org/abs/2403.19243)
42. [CLAP4CLIP: Continual Learning with Probabilistic Finetuning for Vision-Language Models](https://arxiv.org/abs/2403.19137)
43. [Low-Rank Rescaled Vision Transformer Fine-Tuning: A Residual Design Approach](https://arxiv.org/abs/2403.19067)
44. [Envisioning MedCLIP: A Deep Dive into Explainability for Medical Vision-Language Models](https://arxiv.org/abs/2403.18996)
45. [Self-Expansion of Pre-trained Models with Mixture of Adapters for Continual Learning](https://arxiv.org/abs/2403.18886)
46. [Predicting risk of cardiovascular disease using retinal OCT imaging](https://arxiv.org/abs/2403.18873)
47. [Mini-Gemini: Mining the Potential of Multi-modality Vision Language Models](https://arxiv.org/abs/2403.18814)
48. [Projective Methods for Mitigating Gender Bias in Pre-trained Language Models](https://arxiv.org/abs/2403.18803)
49. [OrCo: Towards Better Generalization via Orthogonality and Contrast for Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2403.18550)
50. [I2CKD : Intra- and Inter-Class Knowledge Distillation for Semantic Segmentation](https://arxiv.org/abs/2403.18490)
51. [ECNet: Effective Controllable Text-to-Image Diffusion Models](https://arxiv.org/abs/2403.18417)
52. [Generative Multi-modal Models are Good Class-Incremental Learners](https://arxiv.org/abs/2403.18383)
53. [Towards Non-Exemplar Semi-Supervised Class-Incremental Learning](https://arxiv.org/abs/2403.18291)
54. [Branch-Tuning: Balancing Stability and Plasticity for Continual Self-Supervised Learning](https://arxiv.org/abs/2403.18266)
55. [Enhancing Generative Class Incremental Learning Performance with Model Forgetting Approach](https://arxiv.org/abs/2403.18258)
56. [Beyond Embeddings: The Promise of Visual Table in Multi-Modal Models](https://arxiv.org/abs/2403.18252)
57. [Few-shot Online Anomaly Detection and Segmentation](https://arxiv.org/abs/2403.18201)
58. [Multi-Layer Dense Attention Decoder for Polyp Segmentation](https://arxiv.org/abs/2403.18180)
59. [Tutorial on Diffusion Models for Imaging and Vision](https://arxiv.org/abs/2403.18103)
60. [Generative Medical Segmentation](https://arxiv.org/abs/2403.18198)
61. [AID: Attention Interpolation of Text-to-Image Diffusion](https://arxiv.org/abs/2403.17924)
62. [LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning](https://arxiv.org/abs/2403.17919)
63. [ELGC-Net: Efficient Local-Global Context Aggregation for Remote Sensing Change Detection](https://arxiv.org/abs/2403.17909)
64. [Improving Text-to-Image Consistency via Automatic Prompt Optimization](https://arxiv.org/abs/2403.17804)
65. [Multi-Task Dense Prediction via Mixture of Low-Rank Experts](https://arxiv.org/abs/2403.17749)
66. [The Solution for the CVPR 2023 1st foundation model challenge-Track2](https://arxiv.org/abs/2403.17702)
67. [On the Benefits of Over-parameterization for Out-of-Distribution Generalization](https://arxiv.org/abs/2403.17592)
68. [A Survey on Deep Learning and State-of-the-arts Applications](https://arxiv.org/abs/2403.17561)
69. [Boosting Few-Shot Learning with Disentangled Self-Supervised Learning and Meta-Learning for Medical Image Classification](https://arxiv.org/abs/2403.17530)
70. [DS-AL: A Dual-Stream Analytic Learning for Exemplar-Free Class-Incremental Learning](https://arxiv.org/abs/2403.17503)
71. [Neural Clustering based Visual Representation Learning](https://arxiv.org/abs/2403.17409)
72. [Boosting Few-Shot Learning via Attentive Feature Regularization](https://arxiv.org/abs/2403.17025)
73. [CT Synthesis with Conditional Diffusion Models for Abdominal Lymph Node Segmentation](https://arxiv.org/abs/2403.17770)
74. [Rotate to Scan: UNet-like Mamba with Triplet SSM Module for Medical Image Segmentation](https://arxiv.org/abs/2403.17701)
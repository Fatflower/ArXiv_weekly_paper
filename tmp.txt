https://arxiv.org/abs/2405.17427 | [2405.17427] Reason3D: Searching and Reasoning 3D Segmentation via Large Language Model
https://arxiv.org/abs/2405.17372 | [2405.17372] BehaviorGPT: Smart Agent Simulation for Autonomous Driving with Next-Patch Prediction
https://arxiv.org/abs/2405.17264 | [2405.17264] On the Noise Robustness of In-Context Learning for Text Generation
https://arxiv.org/abs/2405.17258 | [2405.17258] $\textit{Trans-LoRA}$: towards data-free Transferable Parameter Efficient Finetuning
https://arxiv.org/abs/2405.17220 | [2405.17220] RLAIF-V: Aligning MLLMs through Open-Source AI Feedback for Super GPT-4V Trustworthiness
https://arxiv.org/abs/2405.17394 | [2405.17394] The Expressive Capacity of State Space Models: A Formal Language Perspective
https://arxiv.org/abs/2405.17293 | [2405.17293] Efficient Ensembles Improve Training Data Attribution
https://arxiv.org/abs/2405.17247 | [2405.17247] An Introduction to Vision-Language Modeling
https://arxiv.org/abs/2405.17234 | [2405.17234] Benchmarking General Purpose In-Context Learning
https://arxiv.org/abs/2405.17202 | [2405.17202] Efficient multi-prompt evaluation of LLMs
https://arxiv.org/abs/2405.17164 | [2405.17164] WeiPer: OOD Detection using Weight Perturbations of Class Projections
https://arxiv.org/abs/2405.17069 | [2405.17069] Training-free Editioning of Text-to-Image Models
https://arxiv.org/abs/2405.17054 | [2405.17054] Improving Data-aware and Parameter-aware Robustness for Continual Learning
https://arxiv.org/abs/2405.17022 | [2405.17022] Compositional Few-Shot Class-Incremental Learning
https://arxiv.org/abs/2405.16994 | [2405.16994] Vision-and-Language Navigation Generative Pretrained Transformer
https://arxiv.org/abs/2405.16915 | [2405.16915] Multilingual Diversity Improves Vision-Language Representations
https://arxiv.org/abs/2405.16833 | [2405.16833] Safe LoRA: the Silver Lining of Reducing Safety Risks when Fine-tuning Large Language Models
https://arxiv.org/abs/2405.16819 | [2405.16819] Automatic Domain Adaptation by Transformers in In-Context Learning
https://arxiv.org/abs/2405.16815 | [2405.16815] Image-level Regression for Uncertainty-aware Retinal Image Segmentation
https://arxiv.org/abs/2405.16766 | [2405.16766] Reframing the Relationship in Out-of-Distribution Detection
https://arxiv.org/abs/2405.16754 | [2405.16754] Adaptive VIO: Deep Visual-Inertial Odometry with Online Continual Learning
https://arxiv.org/abs/2405.16625 | [2405.16625] Few-shot Tuning of Foundation Models for Class-incremental Learning
https://arxiv.org/abs/2405.16498 | [2405.16498] On Sequential Loss Approximation for Continual Learning
https://arxiv.org/abs/2405.16417 | [2405.16417] CRoFT: Robust Fine-Tuning with Concurrent Optimization for OOD Generalization and Open-Set OOD Detection
https://arxiv.org/abs/2405.16401 | [2405.16401] Understanding the Effect of using Semantically Meaningful Tokens for Visual Representation Learning
https://arxiv.org/abs/2405.16350 | [2405.16350] A Second-Order perspective on Compositionality and Incremental Learning
https://arxiv.org/abs/2405.16146 | [2405.16146] Dual-Adapter: Training-free Dual Adaptation for Few-shot Out-of-Distribution Detection
https://arxiv.org/abs/2405.16124 | [2405.16124] Unsupervised Meta-Learning via In-Context Learning
https://arxiv.org/abs/2405.15973 | [2405.15973] Enhancing Visual-Language Modality Alignment in Large Vision Language Models via Self-Improvement
https://arxiv.org/abs/2405.15953 | [2405.15953] Activator: GLU Activations as The Core Functions of a Vision Transformer
https://arxiv.org/abs/2405.16922 | [2405.16922] Theories of synaptic memory consolidation and intelligent plasticity for continual learning
https://arxiv.org/abs/2405.16516 | [2405.16516] Memory-efficient High-resolution OCT Volume Synthesis with Cascaded Amortized Latent Diffusion Models
https://arxiv.org/abs/2403.10245 | [2403.10245] CoLeCLIP: Open-Domain Continual Learning via Joint Task Prompt and Vocabulary Learning
https://arxiv.org/abs/2403.10097 | [2403.10097] Adaptive Random Feature Regularization on Fine-tuning Deep Neural Networks
https://arxiv.org/abs/2403.10056 | [2403.10056] Don't Half-listen: Capturing Key-part Information in Continual Instruction Tuning
https://arxiv.org/abs/2403.10053 | [2403.10053] Group-Mix SAM: Lightweight Solution for Industrial Assembly Line Applications
https://arxiv.org/abs/2403.10047 | [2403.10047] TextBlockV2: Towards Precise-Detection-Free Scene Text Spotting with Pre-trained Language Model
https://arxiv.org/abs/2403.10039 | [2403.10039] Rethinking Low-quality Optical Flow in Unsupervised Surgical Instrument Segmentation
https://arxiv.org/abs/2403.09977 | [2403.09977] EfficientVMamba: Atrous Selective Scan for Light Weight Visual Mamba
https://arxiv.org/abs/2403.09974 | [2403.09974] GET: Unlocking the Multi-modal Potential of CLIP for Generalized Category Discovery
https://arxiv.org/abs/2403.09948 | [2403.09948] RadCLIP: Enhancing Radiologic Image Analysis through Contrastive Language-Image Pre-training
https://arxiv.org/abs/2403.09850 | [2403.09850] MARVIS: Motion & Geometry Aware Real and Virtual Image Segmentation
https://arxiv.org/abs/2403.09766 | [2403.09766] An Image Is Worth 1000 Lies: Adversarial Transferability across Prompts on Vision-Language Models
https://arxiv.org/abs/2403.09672 | [2403.09672] COMPRER: A Multimodal Multi-Objective Pretraining Framework for Enhanced Medical Image Representation
https://arxiv.org/abs/2403.10009 | [2403.10009] Cardiac Magnetic Resonance 2D+T Short- and Long-axis Segmentation via Spatio-temporal SAM Adaptation
https://arxiv.org/abs/2403.10519 | [2403.10519] Frozen Feature Augmentation for Few-Shot Image Classification
https://arxiv.org/abs/2403.10403 | [2403.10403] Energy Correction Model in the Feature Space for Out-of-Distribution Detection
https://arxiv.org/abs/2403.10391 | [2403.10391] CDMAD: Class-Distribution-Mismatch-Aware Debiasing for Class-Imbalanced Semi-Supervised Learning
https://arxiv.org/abs/2403.10338 | [2403.10338] Investigating grammatical abstraction in language models using few-shot learning of novel noun gender
https://arxiv.org/abs/2403.10287 | [2403.10287] Few-Shot Image Classification and Segmentation as Visual Question Answering Using Vision-Language Models
https://arxiv.org/abs/2403.10097 | [2403.10097] Adaptive Random Feature Regularization on Fine-tuning Deep Neural Networks
https://arxiv.org/abs/2403.09857 | [2403.09857] Few-Shot Class Incremental Learning with Attention-Aware Self-Adaptive Prompt
https://arxiv.org/abs/2403.09827 | [2403.09827] FastSAM3D: An Efficient Segment Anything Model for 3D Volumetric Medical Images
https://arxiv.org/abs/2403.12040 | [2403.12040] Distilling Datasets Into Less Than One Image
https://arxiv.org/abs/2403.12038 | [2403.12038] Zero-Shot Image Feature Consensus with Deep Functional Maps
https://arxiv.org/abs/2403.12036 | [2403.12036] One-Step Image Translation with Text-to-Image Models
https://arxiv.org/abs/2403.12030 | [2403.12030] Expandable Subspace Ensemble for Pre-Trained Model-Based Class-Incremental Learning
https://arxiv.org/abs/2403.11887 | [2403.11887] SuperLoRA: Parameter-Efficient Unified Adaptation of Multi-Layer Attention Modules
https://arxiv.org/abs/2403.11808 | [2403.11808] Dynamic Tuning Towards Parameter and Inference Efficiency for ViT Adaptation
https://arxiv.org/abs/2403.11735 | [2403.11735] LSKNet: A Foundation Lightweight Backbone for Remote Sensing
https://arxiv.org/abs/2403.11667 | [2403.11667] Binary Noise for Binary Tasks: Masked Bernoulli Diffusion for Unsupervised Anomaly Detection
https://arxiv.org/abs/2403.11646 | [2403.11646] MedMerge: Merging Models for Effective Transfer Learning to Medical Imaging Tasks
https://arxiv.org/abs/2403.11627 | [2403.11627] LoRA-Composer: Leveraging Low-Rank Adaptation for Multi-Concept Customization in Training-Free Diffusion Models
https://arxiv.org/abs/2403.11614 | [2403.11614] CRS-Diff: Controllable Generative Remote Sensing Foundation Model
https://arxiv.org/abs/2403.10075 | [2403.10075] A survey of synthetic data augmentation methods in computer vision
https://arxiv.org/abs/2403.12966 | [2403.12966] Chain-of-Spot: Interactive Reasoning Improves Large Vision-Language Models
https://arxiv.org/abs/2403.12964 | [2403.12964] Negative Yields Positive: Unified Dual-Path Adapter for Vision-Language Models
https://arxiv.org/abs/2403.12894 | [2403.12894] MEDBind: Unifying Language and Multimodal Medical Data Embeddings
https://arxiv.org/abs/2403.12801 | [2403.12801] RelationVLM: Making Large Vision-Language Models Understand Visual Relations
https://arxiv.org/abs/2403.12803 | [2403.12803] DreamDA: Generative Data Augmentation with Diffusion Models
https://arxiv.org/abs/2403.12767 | [2403.12767] Inter- and intra-uncertainty based feature aggregation model for semi-supervised histopathology image segmentation
https://arxiv.org/abs/2403.12736 | [2403.12736] Towards Multimodal In-Context Learning for Vision & Language Models
https://arxiv.org/abs/2403.12580 | [2403.12580] Real-IAD: A Real-World Multi-View Dataset for Benchmarking Versatile Industrial Anomaly Detection
https://arxiv.org/abs/2403.12570 | [2403.12570] Adapting Visual-Language Models for Generalizable Anomaly Detection in Medical Images
https://arxiv.org/abs/2403.12559 | [2403.12559] Confidence Self-Calibration for Multi-Label Class-Incremental Learning
https://arxiv.org/abs/2403.12532 | [2403.12532] UniBind: LLM-Augmented Unified and Balanced Representation Space to Bind Them All
https://arxiv.org/abs/2403.12455 | [2403.12455] CLIP-VIS: Adapting CLIP for Open-Vocabulary Video Instance Segmentation
https://arxiv.org/abs/2403.12362 | [2403.12362] DMAD: Dual Memory Bank for Real-World Anomaly Detection
https://arxiv.org/abs/2403.12052 | [2403.12052] A Dataset and Benchmark for Copyright Protection from Text-to-Image Diffusion Models
https://arxiv.org/abs/2403.12481 | [2403.12481] TT-BLIP: Enhancing Fake News Detection Using BLIP and Tri-Transformer
https://arxiv.org/abs/2403.12459 | [2403.12459] Non-negative Contrastive Learning
https://arxiv.org/abs/2403.12448 | [2403.12448] Do Generated Data Always Help Contrastive Learning?
https://arxiv.org/abs/2403.12326 | [2403.12326] Removing Undesirable Concepts in Text-to-Image Generative Models with Learnable Prompts
https://arxiv.org/abs/2403.13807 | [2403.13807] Editing Massive Concepts in Text-to-Image Diffusion Models
https://arxiv.org/abs/2403.13804 | [2403.13804] Learning from Models and Data for Visual Grounding
https://arxiv.org/abs/2403.13802 | [2403.13802] ZigMa: Zigzag Mamba Diffusion Model
https://arxiv.org/abs/2403.13684 | [2403.13684] SPTNet: An Efficient Alternative Framework for Generalized Category Discovery with Spatial Prompt Tuning
https://arxiv.org/abs/2403.13677 | [2403.13677] Retina Vision Transformer (RetinaViT): Introducing Scaled Patches into Vision Transformers
https://arxiv.org/abs/2403.13660 | [2403.13660] ProMamba: Prompt-Mamba for polyp segmentation
https://arxiv.org/abs/2403.13647 | [2403.13647] Meta-Point Learning and Refining for Category-Agnostic Pose Estimation
https://arxiv.org/abs/2403.13642 | [2403.13642] H-vmunet: High-order Vision Mamba UNet for Medical Image Segmentation
https://arxiv.org/abs/2403.13600 | [2403.13600] VL-Mamba: Exploring State Space Models for Multimodal Learning
https://arxiv.org/abs/2403.13535 | [2403.13535] IDAdapter: Learning Mixed Features for Tuning-Free Personalization of Text-to-Image Models
https://arxiv.org/abs/2403.13512 | [2403.13512] Scale Decoupled Distillation
https://arxiv.org/abs/2403.13430 | [2403.13430] MTP: Advancing Remote Sensing Foundation Model via Multi-Task Pretraining
https://arxiv.org/abs/2403.13324 | [2403.13324] Out-of-Distribution Detection Using Peer-Class Generated by Large Language Model
https://arxiv.org/abs/2403.13167 | [2403.13167] Improved EATFormer: A Vision Transformer for Medical Image Classification
https://arxiv.org/abs/2403.13078 | [2403.13078] HuLP: Human-in-the-Loop for Prognosis
https://arxiv.org/abs/2403.13042 | [2403.13042] TAPTR: Tracking Any Point with Transformers as Detection
https://arxiv.org/abs/2403.12986 | [2403.12986] BaCon: Boosting Imbalanced Semi-supervised Learning via Balanced Feature-Level Contrastive Learning
https://arxiv.org/abs/2403.13797 | [2403.13797] Bridge the Modality and Capacity Gaps in Vision-Language Model Selection
https://arxiv.org/abs/2403.13522 | [2403.13522] REAL: Representation Enhanced Analytic Learning for Exemplar-free Class-incremental Learning
https://arxiv.org/abs/2403.13467 | [2403.13467] CLIPSwarm: Generating Drone Shows from Text Prompts with Vision-Language Models
https://arxiv.org/abs/2403.13447 | [2403.13447] HyperLLaVA: Dynamic Visual and Language Expert Tuning for Multimodal Large Language Models
https://arxiv.org/abs/2403.13349 | [2403.13349] Hierarchical Gaussian Mixture Normalizing Flow Modeling for Unified Anomaly Detection
https://arxiv.org/abs/2403.13249 | [2403.13249] A Unified and General Framework for Continual Learning
https://arxiv.org/abs/2403.13113 | [2403.13113] Trustworthiness of Pretrained Transformers for Lung Cancer Segmentation
https://arxiv.org/abs/2403.14616 | [2403.14616] Hierarchical Text-to-Vision Self Supervised Alignment for Improved Histopathology Representation Learning
https://arxiv.org/abs/2403.14610 | [2403.14610] T-Rex2: Towards Generic Object Detection via Text-Visual Prompt Synergy
https://arxiv.org/abs/2403.14599 | [2403.14599] MyVLM: Personalizing VLMs for User-Specific Queries
https://arxiv.org/abs/2403.14598 | [2403.14598] PSALM: Pixelwise SegmentAtion with Large Multi-Modal Model
https://arxiv.org/abs/2403.14548 | [2403.14548] DINO-Tracker: Taming DINO for Self-Supervised Point Tracking in a Single Video
https://arxiv.org/abs/2403.14494 | [2403.14494] Learning to Project for Cross-Task Knowledge Distillation
https://arxiv.org/abs/2403.14440 | [2403.14440] Analysing Diffusion Segmentation for Medical Images
https://arxiv.org/abs/2403.14392 | [2403.14392] A Bag of Tricks for Few-Shot Class-Incremental Learning
https://arxiv.org/abs/2403.14292 | [2403.14292] HySim: An Efficient Hybrid Similarity Measure for Patch Matching in Image Inpainting
https://arxiv.org/abs/2403.14213 | [2403.14213] Toward Multi-class Anomaly Detection: Exploring Class-aware Unified Model against Inter-class Interference
https://arxiv.org/abs/2403.14203 | [2403.14203] Unsupervised Audio-Visual Segmentation with Modality Alignment
https://arxiv.org/abs/2403.14158 | [2403.14158] Volumetric Environment Representation for Vision-Language Navigation
https://arxiv.org/abs/2403.14141 | [2403.14141] Empowering Segmentation Ability to Multi-modal Large Language Models
https://arxiv.org/abs/2403.14137 | [2403.14137] Improving Image Classification Accuracy through Complementary Intra-Class and Inter-Class Mixup
https://arxiv.org/abs/2403.14119 | [2403.14119] C-TPT: Calibrated Test-Time Prompt Tuning for Vision-Language Models via Text Feature Dispersion
https://arxiv.org/abs/2403.14103 | [2403.14103] MaskSAM: Towards Auto-prompt SAM with Mask Classification for Medical Image Segmentation
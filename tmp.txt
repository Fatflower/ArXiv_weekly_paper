https://arxiv.org/abs/2404.18201 | [2404.18201] What Foundation Models can Bring for Robot Learning in Manipulation : A Survey
https://arxiv.org/abs/2404.18152 | [2404.18152] Masked Attention as a Mechanism for Improving Interpretability of Vision Transformers
https://arxiv.org/abs/2404.18114 | [2404.18114] Deep Boosting Learning: A Brand-new Cooperative Approach for Image-Text Matching
https://arxiv.org/abs/2404.18060 | [2404.18060] Prompt Customization for Continual Learning
https://arxiv.org/abs/2404.18033 | [2404.18033] Exposing Text-Image Inconsistency Using Diffusion Models
https://arxiv.org/abs/2404.17912 | [2404.17912] SERPENT-VLM : Self-Refining Radiology Report Generation Using Vision Language Models
https://arxiv.org/abs/2404.17877 | [2404.17877] PromptCL: Improving Event Representation via Prompt Template and Contrastive Learning
https://arxiv.org/abs/2404.17753 | [2404.17753] Leveraging Cross-Modal Neighbor Representation for Improved CLIP Classification
https://arxiv.org/abs/2404.17747 | [2404.17747] MMA-UNet: A Multi-Modal Asymmetric UNet Architecture for Infrared and Visible Image Fusion
https://arxiv.org/abs/2404.18096 | [2404.18096] Snake with Shifted Window: Learning to Adapt Vessel Pattern for OCTA Segmentation
https://arxiv.org/abs/2404.17534 | [2404.17534] Exploring the Distinctiveness and Fidelity of the Descriptions Generated by Large Vision-Language Models
https://arxiv.org/abs/2404.17360 | [2404.17360] UniRGB-IR: A Unified Framework for Visible-Infrared Downstream Tasks via Adapter Tuning
https://arxiv.org/abs/2404.17245 | [2404.17245] Parameter Efficient Fine-tuning of Self-supervised ViTs without Catastrophic Forgetting
https://arxiv.org/abs/2404.17184 | [2404.17184] Low-Rank Knowledge Decomposition for Medical Foundation Models
https://arxiv.org/abs/2404.16954 | [2404.16954] Taming False Positives in Out-of-Distribution Detection with Human Feedback
https://arxiv.org/abs/2404.16852 | [2404.16852] A Disease Labeler for Chinese Chest X-Ray Report Generation
https://arxiv.org/abs/2404.17357 | [2404.17357] Simultaneous Tri-Modal Medical Image Fusion and Super-Resolution using Conditional Diffusion Model
https://arxiv.org/abs/2404.19289 | [2404.19289] On Improving the Algorithm-, Model-, and Data- Efficiency of Self-Supervised Learning
https://arxiv.org/abs/2404.19276 | [2404.19276] C2FDrone: Coarse-to-Fine Drone-to-Drone Detection using Vision Transformer Networks
https://arxiv.org/abs/2404.19245 | [2404.19245] HydraLoRA: An Asymmetric LoRA Architecture for Efficient Fine-Tuning
https://arxiv.org/abs/2404.19132 | [2404.19132] Integrating Present and Past in Unsupervised Continual Learning
https://arxiv.org/abs/2404.19128 | [2404.19128] Q-GroundCAM: Quantifying Grounding in Vision Language Models via GradCAM
https://arxiv.org/abs/2404.19094 | [2404.19094] In-Context Symbolic Regression: Leveraging Language Models for Function Discovery
https://arxiv.org/abs/2404.18975 | [2404.18975] M3H: Multimodal Multitask Machine Learning for Healthcare
https://arxiv.org/abs/2404.19723 | [2404.19723] Attention-Constrained Inference for Robust Decoder-Only Text-to-Speech
https://arxiv.org/abs/2404.18930 | [2404.18930] Hallucination of Multimodal Large Language Models: A Survey
https://arxiv.org/abs/2404.18466 | [2404.18466] HFT: Half Fine-Tuning for Large Language Models
https://arxiv.org/abs/2404.18279 | [2404.18279] Out-of-distribution Detection in Medical Image Analysis: A survey
https://arxiv.org/abs/2404.19756 | [2404.19756] KAN: Kolmogorov-Arnold Networks
https://arxiv.org/abs/2404.19527 | [2404.19527] Revealing the Two Sides of Data Augmentation: An Asymmetric Distillation-based Win-Win Solution for Open-Set Recognition
https://arxiv.org/abs/2404.19394 | [2404.19394] CLIP-Mamba: CLIP Pretrained Mamba Models with OOD and Hessian Evaluation
https://arxiv.org/abs/2405.00754 | [2405.00754] CLIPArTT: Light-weight Adaptation of CLIP to New Domains at Test Time
https://arxiv.org/abs/2405.00716 | [2405.00716] Large Language Models in Healthcare: A Comprehensive Benchmark
https://arxiv.org/abs/2405.01503 | [2405.01503] PAM-UNet: Shifting Attention on Region of Interest in Medical Images
https://arxiv.org/abs/2405.00672 | [2405.00672] TexSliders: Diffusion-Based Texture Editing in CLIP Space
https://arxiv.org/abs/2405.00452 | [2405.00452] Predictive Accuracy-Based Active Learning for Medical Image Segmentation
https://arxiv.org/abs/2405.00378 | [2405.00378] Adaptive Bidirectional Displacement for Semi-Supervised Medical Image Segmentation
https://arxiv.org/abs/2405.00361 | [2405.00361] AdaMoLE: Fine-Tuning Large Language Models with Adaptive Mixture of Low-Rank Adaptation Experts
https://arxiv.org/abs/2405.00293 | [2405.00293] MoPEFT: A Mixture-of-PEFTs for the Segment Anything Model
https://arxiv.org/abs/2405.00168 | [2405.00168] Revisiting RGBT Tracking Benchmarks from the Perspective of Modality Validity: A New Benchmark, Problem, and Method
https://arxiv.org/abs/2405.00156 | [2405.00156] Expanding the Horizon: Enabling Hybrid Quantum Transfer Learning for Long-Tailed Chest X-Ray Classification
https://arxiv.org/abs/2405.01008 | [2405.01008] On Mechanistic Knowledge Localization in Text-to-Image Generative Models
https://arxiv.org/abs/2405.00984 | [2405.00984] FREE: Faster and Better Data-Free Meta-Learning
https://arxiv.org/abs/2405.00949 | [2405.00949] The Role of Model Architecture and Scale in Predicting Molecular Properties: Insights from Fine-Tuning RoBERTa, BART, and LLaMA
https://arxiv.org/abs/2405.00899 | [2405.00899] Characterising the Creative Process in Humans and Large Language Models
https://arxiv.org/abs/2405.00878 | [2405.00878] SonicDiffusion: Audio-Driven Image Generation and Editing with Pretrained Diffusion Models
https://arxiv.org/abs/2405.00864 | [2405.00864] Math Multiple Choice Question Generation via Human-Large Language Model Collaboration
https://arxiv.org/abs/2405.01533 | [2405.01533] OmniDrive: A Holistic LLM-Agent Framework for Autonomous Driving with 3D Perception, Reasoning and Planning
https://arxiv.org/abs/2405.01536 | [2405.01536] Customizing Text-to-Image Models with a Single Image Pair
https://arxiv.org/abs/2405.01525 | [2405.01525] FLAME: Factuality-Aware Alignment for Large Language Models
https://arxiv.org/abs/2405.01507 | [2405.01507] Accelerating Convergence in Bayesian Few-Shot Classification
https://arxiv.org/abs/2405.01502 | [2405.01502] Analyzing the Role of Semantic Representations in the Era of Large Language Models
https://arxiv.org/abs/2405.01496 | [2405.01496] LocInv: Localization-aware Inversion for Text-Guided Image Editing
https://arxiv.org/abs/2405.01490 | [2405.01490] Controllable Text Generation in the Instruction-Tuning Era
https://arxiv.org/abs/2405.01468 | [2405.01468] Understanding Retrieval-Augmented Task Adaptation for Vision-Language Models
https://arxiv.org/abs/2405.01453 | [2405.01453] Creative Problem Solving in Large Language and Vision Models -- What Would it Take?
https://arxiv.org/abs/2405.01228 | [2405.01228] RaffeSDG: Random Frequency Filtering enabled Single-source Domain Generalization for Medical Image Segmentation
https://arxiv.org/abs/2405.01217 | [2405.01217] CromSS: Cross-modal pre-training with noisy labels for remote sensing image segmentation
https://arxiv.org/abs/2405.01186 | [2405.01186] Potential Energy based Mixture Model for Noisy Label Learning
https://arxiv.org/abs/2405.01040 | [2405.01040] Few Shot Class Incremental Learning using Vision-Language models
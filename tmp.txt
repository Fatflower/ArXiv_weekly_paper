https://arxiv.org/abs/2404.03658 | [2404.03658] Know Your Neighbors: Improving Single-View Reconstruction via Spatial Vision-Language Reasoning
https://arxiv.org/abs/2404.03657 | [2404.03657] OW-VISCap: Open-World Video Instance Segmentation and Captioning
https://arxiv.org/abs/2404.03653 | [2404.03653] CoMat: Aligning Text-to-Image Diffusion Model with Image-to-Text Concept Matching
https://arxiv.org/abs/2404.03650 | [2404.03650] OpenNeRF: Open Set 3D Neural Scene Segmentation with Pixel-Wise Features and Rendered Novel Views
https://arxiv.org/abs/2404.03646 | [2404.03646] Locating and Editing Factual Associations in Mamba
https://arxiv.org/abs/2404.03626 | [2404.03626] Training LLMs over Neurally Compressed Text
https://arxiv.org/abs/2404.03620 | [2404.03620] LCM-Lookahead for Encoder-based Text-to-Image Personalization
https://arxiv.org/abs/2404.03618 | [2404.03618] DeViDe: Faceted medical knowledge for improved medical vision-language pre-training
https://arxiv.org/abs/2404.03592 | [2404.03592] ReFT: Representation Finetuning for Language Models
https://arxiv.org/abs/2404.03570 | [2404.03570] Embodied AI with Two Arms: Zero-shot Learning, Safety and Modularity
https://arxiv.org/abs/2404.03539 | [2404.03539] Is CLIP the main roadblock for fine-grained open-world perception?
https://arxiv.org/abs/2404.03451 | [2404.03451] How Much Data are Enough? Investigating Dataset Requirements for Patch-Based Brain MRI Segmentation Tasks
https://arxiv.org/abs/2404.03411 | [2404.03411] Red Teaming GPT-4V: Are GPT-4V Safe Against Uni/Multi-Modal Jailbreak Attacks?
https://arxiv.org/abs/2404.03398 | [2404.03398] Scaling Up Video Summarization Pretraining with Large Language Models
https://arxiv.org/abs/2404.03392 | [2404.03392] Two Tricks to Improve Unsupervised Segmentation Learning
https://arxiv.org/abs/2404.03264 | [2404.03264] Foundation Model for Advancing Healthcare: Challenges, Opportunities, and Future Directions
https://arxiv.org/abs/2404.03263 | [2404.03263] On the Surprising Efficacy of Distillation as an Alternative to Pre-Training Small Models
https://arxiv.org/abs/2404.03248 | [2404.03248] Learning Transferable Negative Prompts for Out-of-Distribution Detection
https://arxiv.org/abs/2404.03200 | [2404.03200] Future-Proofing Class Incremental Learning
https://arxiv.org/abs/2404.03118 | [2404.03118] LVLM-Intrepret: An Interpretability Tool for Large Vision-Language Models
https://arxiv.org/abs/2404.03042 | [2404.03042] AWOL: Analysis WithOut synthesis using Language
https://arxiv.org/abs/2404.03027 | [2404.03027] JailBreakV-28K: A Benchmark for Assessing the Robustness of MultiModal Large Language Models against Jailbreak Attacks
https://arxiv.org/abs/2404.02936 | [2404.02936] Min-K%++: Improved Baseline for Detecting Pre-Training Data from Large Language Models
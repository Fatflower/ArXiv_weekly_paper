https://arxiv.org/abs/2404.16821 | [2404.16821] How Far Are We to GPT-4V? Closing the Gap to Commercial Multimodal Models with Open-Source Suites
https://arxiv.org/abs/2404.16814 | [2404.16814] Meta-Transfer Derm-Diagnosis: Exploring Few-Shot Learning and Transfer Learning for Skin Disease Classification in Long-Tail Distribution
https://arxiv.org/abs/2404.16804 | [2404.16804] AAPL: Adding Attributes to Prompt Learning for Vision-Language Models
https://arxiv.org/abs/2404.16792 | [2404.16792] Weak-to-Strong Extrapolation Expedites Alignment
https://arxiv.org/abs/2404.16790 | [2404.16790] SEED-Bench-2-Plus: Benchmarking Multimodal Large Language Models with Text-Rich Visual Comprehension
https://arxiv.org/abs/2404.16789 | [2404.16789] Continual Learning of Large Language Models: A Comprehensive Survey
https://arxiv.org/abs/2404.16776 | [2404.16776] Modeling Selective Feature Attention for Representation-based Siamese Text Matching
https://arxiv.org/abs/2404.16766 | [2404.16766] Prefix Text as a Yarn: Eliciting Non-English Alignment in Foundation Language Model
https://arxiv.org/abs/2404.16670 | [2404.16670] EmoVIT: Revolutionizing Emotion Insights with Visual Instruction Tuning
https://arxiv.org/abs/2404.16622 | [2404.16622] DAVE -- A Detect-and-Verify Paradigm for Low-Shot Counting
https://arxiv.org/abs/2404.16612 | [2404.16612] MuseumMaker: Continual Style Customization without Catastrophic Forgetting
https://arxiv.org/abs/2404.16609 | [2404.16609] SFMViT: SlowFast Meet ViT in Chaotic World
https://arxiv.org/abs/2404.16398 | [2404.16398] Revisiting Relevance Feedback for CLIP-based Interactive Image Retrieval
https://arxiv.org/abs/2404.16385 | [2404.16385] Efficiency in Focus: LayerNorm as a Catalyst for Fine-tuning Medical Visual Language Pre-trained Models
https://arxiv.org/abs/2404.16375 | [2404.16375] List Items One by One: A New Data Source and Learning Paradigm for Multimodal LLMs
https://arxiv.org/abs/2404.16371 | [2404.16371] Multimodal Information Interaction for Medical Image Segmentation
https://arxiv.org/abs/2404.16356 | [2404.16356] Integration of Mixture of Experts and Multimodal Generative AI in Internet of Vehicles: A Survey
https://arxiv.org/abs/2404.16348 | [2404.16348] Dual Expert Distillation Network for Generalized Zero-Shot Learning
https://arxiv.org/abs/2404.16339 | [2404.16339] Training-Free Unsupervised Prompt for Vision-Language Models
https://arxiv.org/abs/2404.16331 | [2404.16331] IMWA: Iterative Model Weight Averaging Benefits Class-Imbalanced Learning Tasks
https://arxiv.org/abs/2404.16325 | [2404.16325] Semantic Segmentation Refiner for Ultrasound Applications with Zero-Shot Foundation Models
https://arxiv.org/abs/2404.16306 | [2404.16306] TI2V-Zero: Zero-Shot Image Conditioning for Text-to-Video Diffusion Models
https://arxiv.org/abs/2404.16305 | [2404.16305] Semantically consistent Video-to-Audio Generation using Multimodal Language Large Model
https://arxiv.org/abs/2404.16301 | [2404.16301] Style Adaptation for Domain-adaptive Semantic Segmentation
https://arxiv.org/abs/2404.16297 | [2404.16297] When Fuzzing Meets LLMs: Challenges and Opportunities
https://arxiv.org/abs/2404.16198 | [2404.16198] Towards Efficient Patient Recruitment for Clinical Trials: Application of a Prompt-Based Learning Model
https://arxiv.org/abs/2404.16192 | [2404.16192] Fusion of Domain-Adapted Vision and Language Models for Medical Visual Question Answering
https://arxiv.org/abs/2404.16133 | [2404.16133] Quantitative Characterization of Retinal Features in Translated OCTA
https://arxiv.org/abs/2404.16123 | [2404.16123] FairDeDup: Detecting and Mitigating Vision-Language Fairness Disparities in Semantic Dataset Deduplication
https://arxiv.org/abs/2404.16069 | [2404.16069] Interactive Visual Learning for Stable Diffusion
https://arxiv.org/abs/2404.16038 | [2404.16038] A Survey on Generative AI and LLM for Video Generation, Understanding, and Streaming
https://arxiv.org/abs/2404.16033 | [2404.16033] Cantor: Inspiring Multimodal Chain-of-Thought of MLLM
https://arxiv.org/abs/2404.16030 | [2404.16030] MoDE: CLIP Data Experts via Clustering
https://arxiv.org/abs/2404.15971 | [2404.15971] Boosting Architectural Generation via Prompts: Report
https://arxiv.org/abs/2404.15946 | [2404.15946] Mammo-CLIP: Leveraging Contrastive Language-Image Pre-training (CLIP) for Enhanced Breast Cancer Diagnosis with Multi-view Mammography
https://arxiv.org/abs/2404.15777 | [2404.15777] A Comprehensive Survey on Evaluating Large Language Model Applications in the Medical Industry
https://arxiv.org/abs/2404.15770 | [2404.15770] ChEX: Interactive Localization and Region Description in Chest X-rays
https://arxiv.org/abs/2404.15737 | [2404.15737] No Train but Gain: Language Arithmetic for training-free Language Adapters enhancement
https://arxiv.org/abs/2404.15676 | [2404.15676] Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs
https://arxiv.org/abs/2404.15637 | [2404.15637] HybridVC: Efficient Voice Style Conversion with Text and Audio Prompts
https://arxiv.org/abs/2404.15593 | [2404.15593] A Survey of Deep Long-Tail Classification Advancements
https://arxiv.org/abs/2404.15580 | [2404.15580] MiM: Mask in Mask Self-Supervised Pre-Training for 3D Medical Image Analysis
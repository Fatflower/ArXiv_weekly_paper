https://arxiv.org/abs/2404.16123 | [2404.16123] FairDeDup: Detecting and Mitigating Vision-Language Fairness Disparities in Semantic Dataset Deduplication
https://arxiv.org/abs/2404.16814 | [2404.16814] Meta-Transfer Derm-Diagnosis: Exploring Few-Shot Learning and Transfer Learning for Skin Disease Classification in Long-Tail Distribution
https://arxiv.org/abs/2404.16804 | [2404.16804] AAPL: Adding Attributes to Prompt Learning for Vision-Language Models
https://arxiv.org/abs/2404.16790 | [2404.16790] SEED-Bench-2-Plus: Benchmarking Multimodal Large Language Models with Text-Rich Visual Comprehension
https://arxiv.org/abs/2404.16637 | [2404.16637] Zero-Shot Distillation for Image Encoders: How to Make Effective Use of Synthetic Data
https://arxiv.org/abs/2404.16635 | [2404.16635] TinyChart: Efficient Chart Understanding with Visual Token Merging and Program-of-Thoughts Learning
https://arxiv.org/abs/2404.16612 | [2404.16612] MuseumMaker: Continual Style Customization without Catastrophic Forgetting
https://arxiv.org/abs/2404.16556 | [2404.16556] Conditional Distribution Modelling for Few-Shot Image Synthesis with Diffusion Models
https://arxiv.org/abs/2404.16474 | [2404.16474] DiffSeg: A Segmentation Model for Skin Lesions Based on Diffusion Difference
https://arxiv.org/abs/2404.16385 | [2404.16385] Efficiency in Focus: LayerNorm as a Catalyst for Fine-tuning Medical Visual Language Pre-trained Models
https://arxiv.org/abs/2404.16375 | [2404.16375] List Items One by One: A New Data Source and Learning Paradigm for Multimodal LLMs
https://arxiv.org/abs/2404.16371 | [2404.16371] Multimodal Information Interaction for Medical Image Segmentation
https://arxiv.org/abs/2404.16348 | [2404.16348] Dual Expert Distillation Network for Generalized Zero-Shot Learning
https://arxiv.org/abs/2404.16339 | [2404.16339] Training-Free Unsupervised Prompt for Vision-Language Models
https://arxiv.org/abs/2404.16331 | [2404.16331] IMWA: Iterative Model Weight Averaging Benefits Class-Imbalanced Learning Tasks
https://arxiv.org/abs/2404.16133 | [2404.16133] Quantitative Characterization of Retinal Features in Translated OCTA
https://arxiv.org/abs/2404.16821 | [2404.16821] How Far Are We to GPT-4V? Closing the Gap to Commercial Multimodal Models with Open-Source Suites
https://arxiv.org/abs/2408.04619 | [2408.04619] Transformer Explainer: Interactive Learning of Text-Generative Models
https://arxiv.org/abs/2408.04594 | [2408.04594] Img-Diff: Contrastive Data Synthesis for Multimodal Large Language Models
https://arxiv.org/abs/2408.04590 | [2408.04590] Learn To Learn More Precisely
https://arxiv.org/abs/2408.04583 | [2408.04583] Unveiling the Power of Sparse Neural Networks for Feature Selection
https://arxiv.org/abs/2408.04579 | [2408.04579] SAM2-Adapter: Evaluating & Adapting Segment Anything 2 in Downstream Tasks: Camouflage, Shadow, Medical Image Segmentation, and More
https://arxiv.org/abs/2408.04532 | [2408.04532] How Transformers Utilize Multi-Head Attention in In-Context Learning? A Case Study on Sparse Linear Regression
https://arxiv.org/abs/2408.04471 | [2408.04471] What could go wrong? Discovering and describing failure modes in computer vision
https://arxiv.org/abs/2408.04388 | [2408.04388] MM-Forecast: A Multimodal Approach to Temporal Event Forecasting with Large Language Models
https://arxiv.org/abs/2408.04347 | [2408.04347] AggSS: An Aggregated Self-Supervised Approach for Class-Incremental Learning
https://arxiv.org/abs/2408.04262 | [2408.04262] CoBooM: Codebook Guided Bootstrapping for Medical Image Representation Learning
https://arxiv.org/abs/2408.04145 | [2408.04145] ComKD-CLIP: Comprehensive Knowledge Distillation for Contrastive Language-Image Pre-traning Model
https://arxiv.org/abs/2408.04212 | [2408.04212] Is SAM 2 Better than SAM in Medical Image Segmentation?
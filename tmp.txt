https://arxiv.org/abs/2408.05211 | [2408.05211] VITA: Towards Open-Source Interactive Omni Multimodal LLM
https://arxiv.org/abs/2408.05200 | [2408.05200] TaSL: Task Skill Localization and Consolidation for Language Model Continual Learning
https://arxiv.org/abs/2408.05120 | [2408.05120] Cautious Calibration in Binary Classification
https://arxiv.org/abs/2408.05093 | [2408.05093] Order Matters in Hallucination: Reasoning Order as Benchmark and Reflexive Prompting for Large-Language-Models
https://arxiv.org/abs/2408.05088 | [2408.05088] UNIC: Universal Classification Models via Multi-teacher Distillation
https://arxiv.org/abs/2408.04961 | [2408.04961] In Defense of Lazy Visual Grounding for Open-Vocabulary Semantic Segmentation
https://arxiv.org/abs/2408.04917 | [2408.04917] Avoid Wasted Annotation Costs in Open-set Active Learning with Pre-trained Vision-Language Model
https://arxiv.org/abs/2408.04914 | [2408.04914] GuidedNet: Semi-Supervised Multi-Organ Segmentation via Labeled Data Guide Unlabeled Data
https://arxiv.org/abs/2408.04883 | [2408.04883] ProxyCLIP: Proxy Attention Improves CLIP for Open-Vocabulary Segmentation
https://arxiv.org/abs/2408.04879 | [2408.04879] On the Element-Wise Representation and Reasoning in Zero-Shot Image Recognition: A Systematic Survey
https://arxiv.org/abs/2408.04851 | [2408.04851] Your Classifier Can Be Secretly a Likelihood-Based OOD Detector
https://arxiv.org/abs/2408.04664 | [2408.04664] Mitigating Hallucinations in Large Vision-Language Models (LVLMs) via Language-Contrastive Decoding (LCD)
https://arxiv.org/abs/2408.05117 | [2408.05117] Beyond the Eye: A Relational Model for Early Dementia Detection Using Retinal OCTA Images
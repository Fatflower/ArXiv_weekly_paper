https://arxiv.org/abs/2401.16422 | [2401.16422] Strategic Usage in a Multi-Learner Setting
https://arxiv.org/abs/2401.16420 | [2401.16420] InternLM-XComposer2: Mastering Free-form Text-Image Composition and Comprehension in Vision-Language Large Model
https://arxiv.org/abs/2401.16405 | [2401.16405] Scaling Sparse Fine-Tuning to Large Language Models
https://arxiv.org/abs/2401.16386 | [2401.16386] Continual Learning with Pre-Trained Models: A Survey
https://arxiv.org/abs/2401.16157 | [2401.16157] Spatial-Aware Latent Initialization for Controllable Image Generation
https://arxiv.org/abs/2401.15973 | [2401.15973] Sample Weight Estimation Using Meta-Updates for Online Continual Learning
https://arxiv.org/abs/2401.15947 | [2401.15947] MoE-LLaVA: Mixture of Experts for Large Vision-Language Models
https://arxiv.org/abs/2401.15914 | [2401.15914] Overcoming the Pitfalls of Vision-Language Model Finetuning for OOD Generalization
https://arxiv.org/abs/2401.15855 | [2401.15855] Cross-Scale MAE: A Tale of Multi-Scale Exploitation in Remote Sensing
https://arxiv.org/abs/2401.15834 | [2401.15834] Few and Fewer: Learning Better from Few Examples Using Fewer Base Classes
https://arxiv.org/abs/2401.15688 | [2401.15688] Divide and Conquer: Language Models can Plan and Self-Correct for Compositional Text-to-Image Generation
https://arxiv.org/abs/2401.15657 | [2401.15657] Data-Free Generalized Zero-Shot Learning
https://arxiv.org/abs/2401.15559 | [2401.15559] IntentTuner: An Interactive Framework for Integrating Human Intents in Fine-tuning Text-to-Image Generative Models
https://arxiv.org/abs/2401.15275 | [2401.15275] Dynamic Transformer Architecture for Continual Learning of Multimodal Tasks
https://arxiv.org/abs/2401.15207 | [2401.15207] HiFT: A Hierarchical Full Parameter Fine-Tuning Strategy
https://arxiv.org/abs/2401.15111 | [2401.15111] Improving Fairness of Automated Chest X-ray Diagnosis by Contrastive Learning
https://arxiv.org/abs/2402.10896 | [2402.10896] PaLM2-VAdapter: Progressively Aligned Language Model Makes a Strong Vision-language Adapter
https://arxiv.org/abs/2402.10884 | [2402.10884] Multi-modal preference alignment remedies regression of visual instruction tuning on language model
https://arxiv.org/abs/2402.10882 | [2402.10882] Universal Prompt Optimizer for Safe Text-to-Image Generation
https://arxiv.org/abs/2402.10670 | [2402.10670] OpenFMNav: Towards Open-Set Zero-Shot Object Navigation via Vision-Language Foundation Models
https://arxiv.org/abs/2402.10595 | [2402.10595] Compact and De-biased Negative Instance Embedding for Multi-Instance Learning on Whole-Slide Image Classification
https://arxiv.org/abs/2402.10534 | [2402.10534] Using Left and Right Brains Together: Towards Vision and Language Planning
https://arxiv.org/abs/2402.10887 | [2402.10887] Weak-Mamba-UNet: Visual Mamba Makes CNN and ViT Work Better for Scribble-based Medical Image Segmentation
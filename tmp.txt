https://arxiv.org/abs/2402.10210 | [2402.10210] Self-Play Fine-Tuning of Diffusion Models for Text-to-Image Generation
https://arxiv.org/abs/2402.10208 | [2402.10208] Recovering the Pre-Fine-Tuning Weights of Generative Models
https://arxiv.org/abs/2402.10211 | [2402.10211] Hierarchical State Space Models for Continuous Sequence-to-Sequence Modeling
https://arxiv.org/abs/2402.10198 | [2402.10198] Unlocking the Potential of Transformers in Time Series Forecasting with Sharpness-Aware Minimization and Channel-Wise Attention
https://arxiv.org/abs/2402.10110 | [2402.10110] Selective Reflection-Tuning: Student-Selected Data Recycling for LLM Instruction-Tuning
https://arxiv.org/abs/2402.10100 | [2402.10100] Tuning In: Analysis of Audio Classifier Performance in Clinical Settings with Limited Data
https://arxiv.org/abs/2402.10063 | [2402.10063] Balancing the Causal Effects in Class-Incremental Learning
https://arxiv.org/abs/2402.10062 | [2402.10062] Optimal Parameter and Neuron Pruning for Out-of-Distribution Detection
https://arxiv.org/abs/2402.09966 | [2402.09966] Textual Localization: Decomposing Multi-concept Images for Subject-Driven Text-to-Image Generation
https://arxiv.org/abs/2402.09906 | [2402.09906] Generative Representational Instruction Tuning
https://arxiv.org/abs/2402.09812 | [2402.09812] DreamMatcher: Appearance Matching Self-Attention for Semantically-Consistent Text-to-Image Personalization
https://arxiv.org/abs/2402.09801 | [2402.09801] EFUF: Efficient Fine-grained Unlearning Framework for Mitigating Hallucinations in Multimodal Large Language Models
https://arxiv.org/abs/2402.09748 | [2402.09748] Model Compression and Efficient Inference for Large Language Models: A Survey
https://arxiv.org/abs/2402.09739 | [2402.09739] QuRating: Selecting High-Quality Data for Training Language Models
https://arxiv.org/abs/2402.09677 | [2402.09677] Prompt-based Personalized Federated Learning for Medical Visual Question Answering
https://arxiv.org/abs/2402.09668 | [2402.09668] How to Train Data-Efficient LLMs
https://arxiv.org/abs/2402.09635 | [2402.09635] VisIRNet: Deep Image Alignment for UAV-taken Visible and Infrared Image Pairs
https://arxiv.org/abs/2402.09613 | [2402.09613] Quantified Task Misalignment to Inform PEFT: An Exploration of Domain Generalization and Catastrophic Forgetting in CLIP
https://arxiv.org/abs/2402.09585 | [2402.09585] Domain Adaptation for Contrastive Audio-Language Models
https://arxiv.org/abs/2402.09538 | [2402.09538] Learning From Lessons Learned: Preliminary Findings From a Study of Learning From Failure
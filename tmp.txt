https://arxiv.org/abs/2402.14020 | [2402.14020] Coercing LLMs to do and reveal (almost) anything
https://arxiv.org/abs/2402.14013 | [2402.14013] Misalignment, Learning, and Ranking: Harnessing Users Limited Attention
https://arxiv.org/abs/2402.14008 | [2402.14008] OlympiadBench: A Challenging Benchmark for Promoting AGI with Olympiad-Level Bilingual Multimodal Scientific Problems
https://arxiv.org/abs/2402.13991 | [2402.13991] Analysing The Impact of Sequence Composition on Language Model Pre-Training
https://arxiv.org/abs/2402.13932 | [2402.13932] Tumor segmentation on whole slide images: training or prompting?
https://arxiv.org/abs/2402.13918 | [2402.13918] BenchCloudVision: A Benchmark Analysis of Deep Learning Approaches for Cloud Detection and Segmentation in Remote Sensing Imagery
https://arxiv.org/abs/2402.13831 | [2402.13831] MLXP: A framework for conducting replicable Machine Learning eXperiments in Python
https://arxiv.org/abs/2402.13636 | [2402.13636] A Unified Framework and Dataset for Assessing Gender Bias in Vision-Language Models
https://arxiv.org/abs/2402.13607 | [2402.13607] CODIS: Benchmarking Context-Dependent Visual Comprehension for Multimodal Large Language Models
https://arxiv.org/abs/2402.13577 | [2402.13577] BBA: Bi-Modal Behavioral Alignment for Reasoning with Large Vision-Language Models
https://arxiv.org/abs/2402.13524 | [2402.13524] OMGEval: An Open Multilingual Generative Evaluation Benchmark for Large Language Models
https://arxiv.org/abs/2402.13505 | [2402.13505] SimPro: A Simple Probabilistic Framework Towards Realistic Long-Tailed Semi-Supervised Learning
https://arxiv.org/abs/2402.13490 | [2402.13490] Contrastive Prompts Improve Disentanglement in Text-to-Image Diffusion Models
https://arxiv.org/abs/2402.13459 | [2402.13459] Learning to Poison Large Language Models During Instruction Tuning
https://arxiv.org/abs/2402.13446 | [2402.13446] Large Language Models for Data Annotation: A Survey
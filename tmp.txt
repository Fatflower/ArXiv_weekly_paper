https://arxiv.org/abs/2402.00865 | [2402.00865] Towards Optimal Feature-Shaping Methods for Out-of-Distribution Detection
https://arxiv.org/abs/2402.00861 | [2402.00861] Evaluating Large Language Models for Generalization and Robustness via Data Compression
https://arxiv.org/abs/2402.00858 | [2402.00858] Can Large Language Models Understand Context?
https://arxiv.org/abs/2402.00751 | [2402.00751] Unlearnable Algorithms for In-context Learning
https://arxiv.org/abs/2402.00743 | [2402.00743] Benefits of Transformer: In-Context Learning in Linear Regression Tasks with Unstructured Data
https://arxiv.org/abs/2402.00606 | [2402.00606] Dynamic Texture Transfer using PatchMatch and Transformers
https://arxiv.org/abs/2402.00580 | [2402.00580] Continuous Unsupervised Domain Adaptation Using Stabilized Representations and Experience Replay
https://arxiv.org/abs/2402.00481 | [2402.00481] Bias Mitigating Few-Shot Class-Incremental Learning
https://arxiv.org/abs/2402.00448 | [2402.00448] Dual-Student Knowledge Distillation Networks for Unsupervised Anomaly Detection
https://arxiv.org/abs/2402.00450 | [2402.00450] CPT: Competence-progressive Training Strategy for Few-shot Node Classification
https://arxiv.org/abs/2402.00396 | [2402.00396] Efficient Exploration for LLMs
https://arxiv.org/abs/2402.00253 | [2402.00253] A Survey on Hallucination in Large Vision-Language Models
https://arxiv.org/abs/2402.00225 | [2402.00225] Geometry aware 3D generation from in-the-wild images in ImageNet
https://arxiv.org/abs/2402.00149 | [2402.00149] The Impact of Language Adapters in Cross-Lingual Transfer for NLU
https://arxiv.org/abs/2402.00092 | [2402.00092] Episodic-free Task Selection for Few-shot Learning
https://arxiv.org/abs/2402.00045 | [2402.00045] Detecting Multimedia Generated by Large AI Models: A Survey
https://arxiv.org/abs/2402.00033 | [2402.00033] LF-ViT: Reducing Spatial Redundancy in Vision Transformer for Efficient Image Recognition
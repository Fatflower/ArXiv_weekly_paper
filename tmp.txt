https://arxiv.org/abs/2403.09634 | [2403.09634] OneTracker: Unifying Visual Object Tracking with Foundation Models and Efficient Tuning
https://arxiv.org/abs/2403.09620 | [2403.09620] PosSAM: Panoptic Open-vocabulary Segment Anything
https://arxiv.org/abs/2403.09616 | [2403.09616] Explore In-Context Segmentation via Latent Diffusion Models
https://arxiv.org/abs/2403.09615 | [2403.09615] PrompTHis: Visualizing the Process and Influence of Prompt Editing during Text-to-Image Creation
https://arxiv.org/abs/2403.09593 | [2403.09593] Renovating Names in Open-Vocabulary Segmentation Benchmarks
https://arxiv.org/abs/2403.09572 | [2403.09572] Eyes Closed, Safety On: Protecting Multimodal LLMs via Image-to-Text Transformation
https://arxiv.org/abs/2403.09559 | [2403.09559] Less is More: Data Value Estimation for Visual Instruction Tuning
https://arxiv.org/abs/2403.09502 | [2403.09502] EquiAV: Leveraging Equivariance for Audio-Visual Contrastive Learning
https://arxiv.org/abs/2403.09493 | [2403.09493] Anomaly Detection by Adapting a pre-trained Vision Language Model
https://arxiv.org/abs/2403.09410 | [2403.09410] XCoOp: Explainable Prompt Learning for Computer-Aided Diagnosis via Concept-guided Context Optimization
https://arxiv.org/abs/2403.09377 | [2403.09377] Introducing Routing Functions to Vision-Language Parameter-Efficient Fine-Tuning with Low-Rank Bottlenecks
https://arxiv.org/abs/2403.09313 | [2403.09313] Knowledge Distillation in YOLOX-ViT for Side-Scan Sonar Object Detection
https://arxiv.org/abs/2403.09307 | [2403.09307] Annotation Free Semantic Segmentation with Vision Foundation Models
https://arxiv.org/abs/2403.09296 | [2403.09296] Select and Distill: Selective Dual-Teacher Knowledge Transfer for Continual Learning on Vision-Language Models
https://arxiv.org/abs/2403.09294 | [2403.09294] Anatomical Structure-Guided Medical Vision-Language Pre-training
https://arxiv.org/abs/2403.09257 | [2403.09257] WSI-SAM: Multi-resolution Segment Anything Model (SAM) for histopathology whole-slide images
https://arxiv.org/abs/2403.09199 | [2403.09199] Customizing Segmentation Foundation Model via Prompt Learning for Instance Segmentation
https://arxiv.org/abs/2403.09072 | [2403.09072] UniCode: Learning a Unified Codebook for Multimodal Large Language Models
https://arxiv.org/abs/2403.09057 | [2403.09057] A Continued Pretrained LLM Approach for Automatic Medical Note Generation
https://arxiv.org/abs/2403.09053 | [2403.09053] Towards a theory of model distillation
https://arxiv.org/abs/2403.09037 | [2403.09037] The First to Know: How Token Distributions Reveal Hidden Knowledge in Large Vision-Language Models?
https://arxiv.org/abs/2403.08967 | [2403.08967] PathM3: A Multimodal Multi-Task Multiple Instance Learning Framework for Whole Slide Image Classification and Captioning
https://arxiv.org/abs/2403.08946 | [2403.08946] Usable XAI: 10 Strategies Towards Exploiting Explainability in the LLM Era
https://arxiv.org/abs/2403.08857 | [2403.08857] DialogGen: Multi-modal Interactive Dialogue System for Multi-turn Text-to-Image Generation
https://arxiv.org/abs/2403.08833 | [2403.08833] TINA: Think, Interaction, and Action Framework for Zero-Shot Vision Language Navigation
https://arxiv.org/abs/2403.08822 | [2403.08822] LoRA-SP: Streamlined Partial Parameter Adaptation for Resource-Efficient Fine-Tuning of Large Language Models
https://arxiv.org/abs/2403.08801 | [2403.08801] CoBra: Complementary Branch Fusing Class and Semantic Knowledge for Robust Weakly Supervised Semantic Segmentation
https://arxiv.org/abs/2403.08793 | [2403.08793] Neural Loss Function Evolution for Large-Scale Image Classifier Convolutional Neural Networks
https://arxiv.org/abs/2403.08783 | [2403.08783] Image-Text Out-Of-Context Detection Using Synthetic Multimodal Misinformation
https://arxiv.org/abs/2403.08776 | [2403.08776] Leveraging Chat-Based Large Vision Language Models for Multimodal Out-Of-Context Detection
https://arxiv.org/abs/2403.08773 | [2403.08773] Veagle: Advancements in Multimodal Representation Learning
https://arxiv.org/abs/2403.09157 | [2403.09157] VM-UNET-V2 Rethinking Vision Mamba UNet for Medical Image Segmentation
https://arxiv.org/abs/2403.08851 | [2403.08851] PAPERCLIP: Associating Astronomical Observations and Natural Language with Multi-Modal Models
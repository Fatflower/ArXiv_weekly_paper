https://arxiv.org/abs/2410.12790 | [2410.12790] Dual Prototype Evolving for Test-Time Generalization of Vision-Language Models
https://arxiv.org/abs/2410.12694 | [2410.12694] VividMed: Vision Language Model with Versatile Visual Grounding for Medicine
https://arxiv.org/abs/2410.12669 | [2410.12669] 3DIS: Depth-Driven Decoupled Instance Synthesis for Text-to-Image Generation
https://arxiv.org/abs/2410.12662 | [2410.12662] Cross-Modal Safety Mechanism Transfer in Large Vision-Language Models
https://arxiv.org/abs/2410.12595 | [2410.12595] CMAL: A Novel Cross-Modal Associative Learning Framework for Vision-Language Pre-Training
https://arxiv.org/abs/2410.12388 | [2410.12388] Prompt Compression for Large Language Models: A Survey
https://arxiv.org/abs/2410.12268 | [2410.12268] VisAnatomy: An SVG Chart Corpus with Fine-Grained Semantic Labels
https://arxiv.org/abs/2410.12178 | [2410.12178] Model Balancing Helps Low-data Training and Fine-tuning
https://arxiv.org/abs/2410.11963 | [2410.11963] CtrlSynth: Controllable Image Text Synthesis for Data-Efficient Multimodal Learning
https://arxiv.org/abs/2410.12567 | [2410.12567] SeQuiFi: Mitigating Catastrophic Forgetting in Speech Emotion Recognition with Sequential Class-Finetuning
https://arxiv.org/abs/2410.11910 | [2410.11910] Explainable AI Methods for Multi-Omics Analysis: A Survey
https://arxiv.org/abs/2410.11842 | [2410.11842] MoH: Multi-Head Attention as Mixture-of-Head Attention
https://arxiv.org/abs/2406.07550 | [2406.07550] An Image is Worth 32 Tokens for Reconstruction and Generation
https://arxiv.org/abs/2406.07543 | [2406.07543] Vision Model Pre-training on Interleaved Image-Text Data via Latent Compression Learning
https://arxiv.org/abs/2406.07537 | [2406.07537] Autoregressive Pretraining with Mamba in Vision
https://arxiv.org/abs/2406.07450 | [2406.07450] Benchmarking Vision-Language Contrastive Methods for Medical Representation Learning
https://arxiv.org/abs/2406.07287 | [2406.07287] Bilingual Sexism Classification: Fine-Tuned XLM-RoBERTa and GPT-3.5 Few-Shot Learning
https://arxiv.org/abs/2406.07168 | [2406.07168] Teaching Language Models to Self-Improve by Learning from Language Feedback
https://arxiv.org/abs/2406.07085 | [2406.07085] CAT: Coordinating Anatomical-Textual Prompts for Multi-Organ and Tumor Segmentation
https://arxiv.org/abs/2406.07056 | [2406.07056] Effectively Compress KV Heads for LLM
https://arxiv.org/abs/2406.06558 | [2406.06558] Enhancing Text Authenticity: A Novel Hybrid Approach for AI-Generated Text Detection
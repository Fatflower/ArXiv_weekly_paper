1. [VL-GPT: A Generative Pre-trained Transformer for Vision and Language Understanding and Generation](https://arxiv.org/abs/2312.09251)
2. [Pixel Aligned Language Models](https://arxiv.org/abs/2312.09237)
3. [Mitigating Outlier Activations in Low-Precision Fine-Tuning of Language Models](https://arxiv.org/abs/2312.09211)
4. [General Object Foundation Model for Images and Videos at Scale](https://arxiv.org/abs/2312.09158)
5. [Split-Ensemble: Efficient OOD-aware Ensemble via Task and Model Splitting](https://arxiv.org/abs/2312.09148)
6. [Class-Wise Buffer Management for Incremental Object Detection: An Effective Buffer Training Strategy](https://arxiv.org/abs/2312.09139)
7. [Tokenize Anything via Prompting](https://arxiv.org/abs/2312.09128)
8. [Context-PEFT: Efficient Multi-Modal, Multi-Task Fine-Tuning](https://arxiv.org/abs/2312.08900)
9. [TiMix: Text-aware Image Mixing for Effective Vision-Language Pre-training](https://arxiv.org/abs/2312.08846)
10. [Exploration of visual prompt in Grounded pre-trained open-set detection](https://arxiv.org/abs/2312.08839)
11. [Learning a Low-Rank Feature Representation: Achieving Better Trade-Off between Stability and Plasticity in Continual Learning](https://arxiv.org/abs/2312.08740)
12. [MmAP : Multi-modal Alignment Prompt for Cross-domain Multi-task Learning](https://arxiv.org/abs/2312.08636)
13. [DIRECT: Deep Active Learning under Imbalance and Label Noise](https://arxiv.org/abs/2312.09196)
14. [Weighted Ensemble Models Are Strong Continual Learners](https://arxiv.org/abs/2312.08977)
15. [EAT: Towards Long-Tailed Out-of-Distribution Detection](https://arxiv.org/abs/2312.08939)
16. [Prompting LLMs with content plans to enhance the summarization of scientific articles](https://arxiv.org/abs/2312.08282)
17. [LAMM: Label Alignment for Multi-Modal Prompt Learning](https://arxiv.org/abs/2312.08212)
18. [Helping Language Models Learn More: Multi-dimensional Task Prompt for Few-shot Tuning](https://arxiv.org/abs/2312.08027)
19. [Learn or Recall? Revisiting Incremental Learning with Pre-trained Language Models](https://arxiv.org/abs/2312.07887)
20. [DTL: Disentangled Transfer Learning for Visual Recognition](https://arxiv.org/abs/2312.07856)
21. [Saturn Platform: Foundation Model Operations and Generative AI for Financial Services](https://arxiv.org/abs/2312.07721)
22. [Pre-trained Universal Medical Image Transformer](https://arxiv.org/abs/2312.07630)
23. [**CLIP in Medical Imaging: A Comprehensive Survey**](https://arxiv.org/abs/2312.07353)
24. [SemiSAM: Exploring SAM for Enhancing Semi-Supervised Medical Image Segmentation with Extremely Limited Annotations](https://arxiv.org/abs/2312.06316)
25. [VILA: On Pre-training for Visual Language Models](https://arxiv.org/abs/2312.07533)
26. [Exploring Plain ViT Reconstruction for Multi-class Unsupervised Anomaly Detection](https://arxiv.org/abs/2312.07495)
27. [Unsupervised Temporal Action Localization via Self-paced Incremental Learning](https://arxiv.org/abs/2312.07384)
28. [**ScribblePrompt: Fast and Flexible Interactive Segmentation for Any Medical Image**](https://arxiv.org/abs/2312.07381)
29. [NVS-Adapter: Plug-and-Play Novel View Synthesis from a Single Image](https://arxiv.org/abs/2312.07315)
30. [Dual Structure-Preserving Image Filterings for Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2312.07264)
31. [**Brain-inspired Computing Based on Machine Learning And Deep Learning:A Review**](https://arxiv.org/abs/2312.07213)
32. [More than Vanilla Fusion: a Simple, Decoupling-free, Attention Module for Multimodal Fusion Based on Signal Theory](https://arxiv.org/abs/2312.07212)
33. [MS-Twins: Multi-Scale Deep Self-Attention Networks for Medical Image Segmentation](https://arxiv.org/abs/2312.07128)
34. [OpenSD: Unified Open-Vocabulary Segmentation and Detection](https://arxiv.org/abs/2312.06703)
35. [RAFIC: Retrieval-Augmented Few-shot Image Classification](https://arxiv.org/abs/2312.06868)
36. [LoRA-Enhanced Distillation on Guided Diffusion Models](https://arxiv.org/abs/2312.06899)
37. [READ-PVLA: Recurrent Adapter with Partial Video-Language Alignment for Parameter-Efficient Transfer Learning in Low-Resource Video-Language Modeling](https://arxiv.org/abs/2312.06950)
38. [**Anytime Approximate Formal Feature Attribution**](https://arxiv.org/abs/2312.06973)
39. [HyperRouter: Towards Efficient Training and Inference of Sparse Mixture of Experts](https://arxiv.org/abs/2312.07035)
40. [Class-Prototype Conditional Diffusion Model for Continual Learning with Generative Replay](https://arxiv.org/abs/2312.06710)
41. [4M: Massively Multimodal Masked Modeling](https://arxiv.org/abs/2312.06647)
42. [**AttenScribble: Attentive Similarity Learning for Scribble-Supervised Medical Image Segmentation**](https://arxiv.org/abs/2312.06614)
43. [DiAD: A Diffusion-based Framework for Multi-class Anomaly Detection](https://arxiv.org/abs/2312.06607)
44. [Relevant Intrinsic Feature Enhancement Network for Few-Shot Semantic Segmentation](https://arxiv.org/abs/2312.06474)
45. [Compound Text-Guided Prompt Tuning via Image-Adaptive Cues](https://arxiv.org/abs/2312.06401)
46. [U-MixFormer: UNet-like Transformer with Mix-Attention for Efficient Semantic Segmentation](https://arxiv.org/abs/2312.06272)
47. [Ensemble Interpretation: A Unified Method for Interpretable Machine Learning](https://arxiv.org/abs/2312.06255)
48. [**Vary: Scaling up the Vision Vocabulary for Large Vision-Language Models**](https://arxiv.org/abs/2312.06109)
49. [**RepViT-SAM: Towards Real-Time Segmenting Anything**](https://arxiv.org/abs/2312.05760)
50. [**Open World Object Detection in the Era of Foundation Models**](https://arxiv.org/abs/2312.05745)
51. [**Batched Low-Rank Adaptation of Foundation Models**](https://arxiv.org/abs/2312.05677)
52. [PILLOW: Enhancing Efficient Instruction Fine-tuning via Prompt Matching](https://arxiv.org/abs/2312.05621)
53. [**Identifying and Mitigating Model Failures through Few-shot CLIP-aided Diffusion Generation**](https://arxiv.org/abs/2312.05464)
54. [Exploring 3D U-Net Training Configurations and Post-Processing Strategies for the MICCAI 2023 Kidney and Tumor Segmentation Challenge](https://arxiv.org/abs/2312.05528)
55. [**Holistic Evaluation of GPT-4V for Biomedical Imaging**](https://arxiv.org/abs/2312.05256)
56. [**Medical Vision Language Pretraining: A survey**](https://arxiv.org/abs/2312.06224)
57. [TaskMet: Task-Driven Metric Learning for Model Learning](https://arxiv.org/abs/2312.05250)
58. [Few-Shot Class-Incremental Learning via Training-Free Prototype Calibration](https://arxiv.org/abs/2312.05229)
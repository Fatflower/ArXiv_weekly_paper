# ArXiv_weekly_paper
This repository records interesting articles on the arXiv website every week (based on my own opinions only).
If you find some interesting articles in this week's arxiv that I've missed, feel free to email me (z1282429194@163.com) or ask a question and I'll add it later.

## Summary of recommended papers in 2024
<!-- | | | | |
|--------|--------|--------|--------| -->
|[1_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/1_week.md)|[2_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/2_week.md)|[3_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/3_week.md)|[4_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/4_week.md)|[5_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/5_week.md)|[6_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/6_week.md)|[7_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/7_week.md)|[8_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/8_week.md)|[9_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/9_week.md)|[10_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/10_week.md)|[11_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/11_week.md)|[12_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/12_week.md)|[13_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/13_week.md)|[14_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/14_week.md)|[15_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/15_week.md)|[16_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/16_week.md)|[17_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/17_week.md)|[18_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/18_week.md)|[19_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/19_week.md)|[20_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/20_week.md)|[21_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/21_week.md)|[22_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/22_week.md)|[23_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/23_week.md)|[24_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/24_week.md)|[25_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/25_week.md)|[26_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/26_week.md)|[27_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/27_week.md)|[28_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/28_week.md)|[29_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/29_week.md)|[30_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/30_week.md)|[31_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/31_week.md)



<!-- | | | | | -->

## Recommended Papers for Week 31, 2024
1. [Benchmarking Dependence Measures to Prevent Shortcut Learning in Medical Imaging](https://arxiv.org/abs/2407.18792)
2. [Constructing Enhanced Mutual Information for Online Class-Incremental Learning](https://arxiv.org/abs/2407.18526)
3. [AI Safety in Generative AI Large Language Models: A Survey](https://arxiv.org/abs/2407.18369)
4. [Towards A Generalizable Pathology Foundation Model via Unified Knowledge Distillation](https://arxiv.org/abs/2407.18449)
5. [Reproducibility Study of "ITI-GEN: Inclusive Text-to-Image Generation"](https://arxiv.org/abs/2407.19996)
6. [HOBOTAN: Efficient Higher Order Binary Optimization Solver with Tensor Networks and PyTorch](https://arxiv.org/abs/2407.19987)
7. [Mixture of Nested Experts: Adaptive Processing of Visual Tokens](https://arxiv.org/abs/2407.19985)
8. [Self-Supervised Learning for Text Recognition: A Critical Survey](https://arxiv.org/abs/2407.19889)
9. [Yucca: A Deep Learning Framework For Medical Image Analysis](https://arxiv.org/abs/2407.19888)
10. [Normality Addition via Normality Detection in Industrial Image Anomaly Detection Models](https://arxiv.org/abs/2407.19849)
11. [ML-Mamba: Efficient Multi-Modal Large Language Model Utilizing Mamba-2](https://arxiv.org/abs/2407.19832)
12. [Cool-Fusion: Fuse Large Language Models without Training](https://arxiv.org/abs/2407.19807)
13. [VolDoGer: LLM-assisted Datasets for Domain Generalization in Vision-Language Tasks](https://arxiv.org/abs/2407.19795)
14. [Multimodal Large Language Models for Bioimage Analysis](https://arxiv.org/abs/2407.19778)
15. [Harnessing Large Vision and Language Models in Agriculture: A Review](https://arxiv.org/abs/2407.19679)
16. [ComNeck: Bridging Compressed Image Latents and Multimodal LLMs via Universal Transform-Neck](https://arxiv.org/abs/2407.19651)
17. [Forecast-PEFT: Parameter-Efficient Fine-Tuning for Pre-trained Motion Forecasting Models](https://arxiv.org/abs/2407.19564)
18. [XLIP: Cross-modal Attention Masked Modelling for Medical Language-Image Pre-Training](https://arxiv.org/abs/2407.19546)
19. [Large-scale cervical precancerous screening via AI-assisted cytology whole slide image analysis](https://arxiv.org/abs/2407.19512)
20. [Visual Riddles: a Commonsense and World Knowledge Challenge for Large Vision and Language Models](https://arxiv.org/abs/2407.19474)
21. [LLAVADI: What Matters For Multimodal Large Language Models Distillation](https://arxiv.org/abs/2407.19409)
22. [Faster Image2Video Generation: A Closer Look at CLIP Image Embedding's Impact on Spatio-Temporal Cross-Attentions](https://arxiv.org/abs/2407.19205)
23. [LLaVA-Read: Enhancing Reading Ability of Multimodal Language Models](https://arxiv.org/abs/2407.19185)
24. [Region Guided Attention Network for Retinal Vessel Segmentation](https://arxiv.org/abs/2407.18970)
25. [Optimising Hard Prompts with Few-Shot Meta-Prompting](https://arxiv.org/abs/2407.18920)
26. [Diffusion Feedback Helps CLIP See Better](https://arxiv.org/abs/2407.20171)
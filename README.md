# ArXiv_weekly_paper
This repository records interesting articles on the arXiv website every week (based on my own opinions only).
If you find some interesting articles in this week's arxiv that I've missed, feel free to email me (z1282429194@163.com) or ask a question and I'll add it later.

## Summary of recommended papers in 2024
<!-- | | | | |
|--------|--------|--------|--------| -->
|[1_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/1_week.md)|[2_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/2_week.md)|[3_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/3_week.md)|[4_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/4_week.md)|[5_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/5_week.md)|[6_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/6_week.md)|[7_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/7_week.md)|[8_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/8_week.md)|[9_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/9_week.md)|[10_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/10_week.md)|[11_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/11_week.md)|[12_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/12_week.md)|[13_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/13_week.md)|[14_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/14_week.md)|[15_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/15_week.md)|[16_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/16_week.md)|[17_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/17_week.md)|[18_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/18_week.md)|[19_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/19_week.md)|[20_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/20_week.md)|[21_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/21_week.md)|[22_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/22_week.md)|[23_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/23_week.md)|[24_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/24_week.md)|[25_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/25_week.md)|[26_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/26_week.md)|[27_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/27_week.md)|[28_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/28_week.md)|[29_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/29_week.md)|[30_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/30_week.md)|[31_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/31_week.md)|[32_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/32_week.md)|[33_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/33_week.md)|[34_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/34_week.md)|[35_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/35_week.md)|[36_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/36_week.md)|[37_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/37_week.md)



<!-- | | | | | -->

## Recommended Papers for Week 37, 2024
1. [Resultant: Incremental Effectiveness on Likelihood for Unsupervised Out-of-Distribution Detection](https://arxiv.org/abs/2409.03801)
2. [Evaluating Machine Learning-based Skin Cancer Diagnosis](https://arxiv.org/abs/2409.03794)
3. [Learning vs Retrieval: The Role of In-Context Examples in Regression with LLMs](https://arxiv.org/abs/2409.04318)
4. [FS-MedSAM2: Exploring the Potential of SAM2 for Few-Shot Medical Image Segmentation without Fine-tuning](https://arxiv.org/abs/2409.04298)
5. [Fast Forwarding Low-Rank Training](https://arxiv.org/abs/2409.04206)
6. [Can OpenSource beat ChatGPT? -- A Comparative Study of Large Language Models for Text-to-Code Generation](https://arxiv.org/abs/2409.04164)
7. [A Coin Has Two Sides: A Novel Detector-Corrector Framework for Chinese Spelling Correction](https://arxiv.org/abs/2409.04150)
8. [Large Margin Prototypical Network for Few-shot Relation Classification with Fine-grained Features](https://arxiv.org/abs/2409.04009)
9. [Qihoo-T2X: An Efficiency-Focused Diffusion Transformer via Proxy Tokens for Text-to-Any-Task](https://arxiv.org/abs/2409.04005)
10. [Deep Clustering of Remote Sensing Scenes through Heterogeneous Transfer Learning](https://arxiv.org/abs/2409.03938)
11. [Data-Efficient Generation for Dataset Distillation](https://arxiv.org/abs/2409.03929)
12. [Few-shot Adaptation of Medical Vision-Language Models](https://arxiv.org/abs/2409.03868)
13. [Exploring Foundation Models for Synthetic Medical Imaging: A Study on Chest X-Rays and Fine-Tuning Techniques](https://arxiv.org/abs/2409.04424)
14. [Optical Coherence Tomography Angiography-OCTA dataset for the study of Diabetic Retinopathy](https://arxiv.org/abs/2409.04137)
15. [VILA-U: a Unified Foundation Model Integrating Visual Understanding and Generation](https://arxiv.org/abs/2409.04429)
16. [Theory, Analysis, and Best Practices for Sigmoid Self-Attention](https://arxiv.org/abs/2409.04431)
17. [LSVOS Challenge Report: Large-scale Complex and Long Video Object Segmentation](https://arxiv.org/abs/2409.05847)
18. [A CLIP-based siamese approach for meme classification](https://arxiv.org/abs/2409.05772)
19. [Zero-shot Outlier Detection via Prior-data Fitted Networks: Model Selection Bygone!](https://arxiv.org/abs/2409.05672)
20. [Joint Input and Output Coordination for Class-Incremental Learning](https://arxiv.org/abs/2409.05620)
21. [CustomContrast: A Multilevel Contrastive Perspective For Subject-Driven Text-to-Image Customization](https://arxiv.org/abs/2409.05606)
22. [StratXplore: Strategic Novelty-seeking and Instruction-aligned Exploration for Vision and Language Navigation](https://arxiv.org/abs/2409.05593)
23. [Seeing is Believing? Enhancing Vision-Language Navigation using Visual Perturbations](https://arxiv.org/abs/2409.05552)
24. [Elsevier Arena: Human Evaluation of Chemistry/Biology/Health Foundational Large Language Models](https://arxiv.org/abs/2409.05486)
25. [Proto-OOD: Enhancing OOD Object Detection with Prototype Feature Similarity](https://arxiv.org/abs/2409.05466)
26. [TextToucher: Fine-Grained Text-to-Touch Generation](https://arxiv.org/abs/2409.05427)
27. [TAVP: Task-Adaptive Visual Prompt for Cross-domain Few-shot Segmentation](https://arxiv.org/abs/2409.05393)
28. [Shaking Up VLMs: Comparing Transformers and Structured State Space Models for Vision & Language Modeling](https://arxiv.org/abs/2409.05395)
29. [Boosting CLIP Adaptation for Image Quality Assessment via Meta-Prompt Learning and Gradient Regularization](https://arxiv.org/abs/2409.05381)
30. [FIF-UNet: An Efficient UNet Using Feature Interaction and Fusion for Medical Image Segmentation](https://arxiv.org/abs/2409.05324)
31. [Open-World Dynamic Prompt and Continual Visual Representation Learning](https://arxiv.org/abs/2409.05312)
32. [A Survey on Mixup Augmentations and Beyond](https://arxiv.org/abs/2409.05202)
33. [Can OOD Object Detectors Learn from Foundation Models?](https://arxiv.org/abs/2409.05162)
34. [Deep Self-cleansing for Medical Image Segmentation with Noisy Labels](https://arxiv.org/abs/2409.05024)
35. [Visual Grounding with Multi-modal Conditional Adaptation](https://arxiv.org/abs/2409.04999)
36. [PatchAlign:Fair and Accurate Skin Disease Image Classification by Alignment with Clinical Labels](https://arxiv.org/abs/2409.04975)
37. [SGSeg: Enabling Text-free Inference in Language-guided Segmentation of Chest X-rays via Self-guidance](https://arxiv.org/abs/2409.04758)
38. [Cross-Organ Domain Adaptive Neural Network for Pancreatic Endoscopic Ultrasound Image Segmentation](https://arxiv.org/abs/2409.04718)
39. [MuAP: Multi-step Adaptive Prompt Learning for Vision-Language Model with Missing Modality](https://arxiv.org/abs/2409.04693)
40. [Multi-Conditioned Denoising Diffusion Probabilistic Model (mDDPM) for Medical Image Synthesis](https://arxiv.org/abs/2409.04670)
41. [Zero-Shot Whole Slide Image Retrieval in Histopathology Using Embeddings of Foundation Models](https://arxiv.org/abs/2409.04631)
42. [High-Performance Few-Shot Segmentation with Foundation Models: An Empirical Study](https://arxiv.org/abs/2409.06305)
43. [Revisiting Prompt Pretraining of Vision-Language Models](https://arxiv.org/abs/2409.06166)
44. [SVFit: Parameter-Efficient Fine-Tuning of Large Pre-Trained Models Using Singular Values](https://arxiv.org/abs/2409.05926)
45. [DA-MoE: Towards Dynamic Expert Allocation for Mixture-of-Experts Models](https://arxiv.org/abs/2409.06669)
46. [SaRA: High-Efficient Diffusion Model Fine-tuning with Progressive Sparse Low-Rank Adaptation](https://arxiv.org/abs/2409.06633)
47. [Elucidating Optimal Reward-Diversity Tradeoffs in Text-to-Image Diffusion Models](https://arxiv.org/abs/2409.06493)
48. [Knowledge Distillation via Query Selection for Detection Transformer](https://arxiv.org/abs/2409.06443)
49. [Recent Trends of Multimodal Affective Computing: A Survey from NLP Perspective](https://arxiv.org/abs/2409.07388)
50. [A Contrastive Symmetric Forward-Forward Algorithm (SFFA) for Continual Learning Tasks](https://arxiv.org/abs/2409.07387)
51. [Alignment of Diffusion Models: Fundamentals, Challenges, and Future](https://arxiv.org/abs/2409.07253)
52. [PiTe: Pixel-Temporal Alignment for Large Video-Language Model](https://arxiv.org/abs/2409.07239)
53. [Swin-LiteMedSAM: A Lightweight Box-Based Segment Anything Model for Large-Scale Medical Image Datasets](https://arxiv.org/abs/2409.07172)
54. [Native vs Non-Native Language Prompting: A Comparative Analysis](https://arxiv.org/abs/2409.07054)
55. [Sam2Rad: A Segmentation Model for Medical Images with Learnable Prompts](https://arxiv.org/abs/2409.06821)
56. [DetailCLIP: Detail-Oriented CLIP for Fine-Grained Tasks](https://arxiv.org/abs/2409.06809)
57. [Discovering Long-Term Effects on Parameter Efficient Fine-tuning](https://arxiv.org/abs/2409.06706)
58. [DreamMesh: Jointly Manipulating and Texturing Triangle Meshes for Text-to-3D Generation](https://arxiv.org/abs/2409.07454)
59. [Adaptive Adapter Routing for Long-Tailed Class-Incremental Learning](https://arxiv.org/abs/2409.07446)
60. [TextBoost: Towards One-Shot Personalization of Text-to-Image Models via Fine-tuning Text Encoder](https://arxiv.org/abs/2409.08248)
61. [IFAdapter: Instance Feature Control for Grounded Text-to-Image Generation](https://arxiv.org/abs/2409.08240)
62. [ComAlign: Compositional Alignment in Vision-Language Models](https://arxiv.org/abs/2409.08206)
63. [Open Source Infrastructure for Automatic Cell Segmentation](https://arxiv.org/abs/2409.08163)
64. [Scribble-Guided Diffusion for Training-free Text-to-Image Generation](https://arxiv.org/abs/2409.08026)
65. [Do Vision Foundation Models Enhance Domain Generalization in Medical Image Segmentation?](https://arxiv.org/abs/2409.07960)
66. [Efficient and Reliable Vector Similarity Search Using Asymmetric Encoding with NAND-Flash for Many-Class Few-Shot Learning](https://arxiv.org/abs/2409.07832)
67. [Lagrange Duality and Compound Multi-Attention Transformer for Semi-Supervised Medical Image Segmentation](https://arxiv.org/abs/2409.07793)
68. [ASSNet: Adaptive Semantic Segmentation Network for Microtumors and Multi-Organ Segmentation](https://arxiv.org/abs/2409.07779)
69. [From Uncertainty to Clarity: Uncertainty-Guided Class-Incremental Learning for Limited Biomedical Samples via Semantic Expansion](https://arxiv.org/abs/2409.07757)
70. [Learn from Balance: Rectifying Knowledge Transfer for Long-Tailed Scenarios](https://arxiv.org/abs/2409.07694)
71. [Minimizing Embedding Distortion for Robust Out-of-Distribution Performance](https://arxiv.org/abs/2409.07582)
72. [OCTAMamba: A State-Space Model Approach for Precision OCTA Vasculature Segmentation](https://arxiv.org/abs/2409.08000)
73. [Context-Aware Optimal Transport Learning for Retinal Fundus Image Enhancement](https://arxiv.org/abs/2409.07862)
# ArXiv_weekly_paper
This repository records interesting articles on the arXiv website every week (based on my own opinions only).
If you find some interesting articles in this week's arxiv that I've missed, feel free to email me (z1282429194@163.com) or ask a question and I'll add it later.

## Summary of recommended papers in 2024
<!-- | | | | |
|--------|--------|--------|--------| -->
|[1_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/1_week.md)|[2_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/2_week.md)|[3_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/3_week.md)|[4_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/4_week.md)|[5_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/5_week.md)|[6_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/6_week.md)|[7_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/7_week.md)|[8_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/8_week.md)|[9_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/9_week.md)|[10_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/10_week.md)|[11_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/11_week.md)|[12_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/12_week.md)|[13_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/13_week.md)|[14_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/14_week.md)|[15_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/15_week.md)|[16_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/16_week.md)|[17_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/17_week.md)|[18_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/18_week.md)|[19_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/19_week.md)|[20_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/20_week.md)|[21_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/21_week.md)|[22_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/22_week.md)

<!-- | | | | | -->

## Recommended Papers for Week 22, 2024
1. [FastDrag: Manipulate Anything in One Step](https://arxiv.org/abs/2405.15769)
2. [Scaling Laws for Discriminative Classification in Large Language Models](https://arxiv.org/abs/2405.15765)
3. [GPT is Not an Annotator: The Necessity of Human Annotation in Fairness Benchmark Construction](https://arxiv.org/abs/2405.15760)
4. [Data Reconstruction: When You See It and When You Don't](https://arxiv.org/abs/2405.15753)
5. [ConvLLaVA: Hierarchical Backbones as Visual Encoder for Large Multimodal Models](https://arxiv.org/abs/2405.15738)
6. [LM4LV: A Frozen Large Language Model for Low-level Vision Tasks](https://arxiv.org/abs/2405.15734)
7. [Disease-informed Adaptation of Vision-Language Models](https://arxiv.org/abs/2405.15728)
8. [Prompt-Aware Adapter: Towards Learning Adaptive Visual Tokens for Multimodal Large Language Models](https://arxiv.org/abs/2405.15684)
9. [Less is more: Summarizing Patch Tokens for efficient Multi-Label Class-Incremental Learning](https://arxiv.org/abs/2405.15633)
10. [MLPs Learn In-Context](https://arxiv.org/abs/2405.15618)
11. [Composed Image Retrieval for Remote Sensing](https://arxiv.org/abs/2405.15587)
12. [Meteor: Mamba-based Traversal of Rationale for Large Language and Vision Models](https://arxiv.org/abs/2405.15574)
13. [Thinking Forward: Memory-Efficient Federated Finetuning of Language Models](https://arxiv.org/abs/2405.15551)
14. [SEP: Self-Enhanced Prompt Tuning for Visual-Language Model](https://arxiv.org/abs/2405.15549)
15. [Sparse Matrix in Large Language Model Fine-tuning](https://arxiv.org/abs/2405.15525)
16. [Polyp Segmentation Generalisability of Pretrained Backbones](https://arxiv.org/abs/2405.15524)
17. [Efficient Degradation-aware Any Image Restoration](https://arxiv.org/abs/2405.15475)
18. [HyperInterval: Hypernetwork approach to training weight interval regions in continual learning](https://arxiv.org/abs/2405.15444)
19. [Smoothed Online Classification can be Harder than Batch Classification](https://arxiv.org/abs/2405.15424)
20. [U3M: Unbiased Multiscale Modal Fusion Model for Multimodal Semantic Segmentation](https://arxiv.org/abs/2405.15365)
21. [Towards Understanding the Working Mechanism of Text-to-Image Diffusion Model](https://arxiv.org/abs/2405.15330)
22. [Stacking Your Transformers: A Closer Look at Model Growth for Efficient LLM Pre-Training](https://arxiv.org/abs/2405.15319)
23. [Are Long-LLMs A Necessity For Long-Context Tasks?](https://arxiv.org/abs/2405.15318)
24. [Prompt Tuning Strikes Back: Customizing Foundation Models with Low-Rank Prompt Adaptation](https://arxiv.org/abs/2405.15282)
25. [Towards Global Optimal Visual In-Context Learning Prompt Selection](https://arxiv.org/abs/2405.15279)
26. [Cross-Domain Few-Shot Semantic Segmentation via Doubly Matching Transformation](https://arxiv.org/abs/2405.15265)
27. [Self-Contrastive Weakly Supervised Learning Framework for Prognostic Prediction Using Whole Slide Images](https://arxiv.org/abs/2405.15264)
28. [DEEM: Diffusion Models Serve as the Eyes of Large Language Models for Image Perception](https://arxiv.org/abs/2405.15232)
29. [Exploring the Impact of Synthetic Data for Aerial-view Human Detection](https://arxiv.org/abs/2405.15203)
30. [VB-LoRA: Extreme Parameter Efficient Fine-Tuning with Vector Banks](https://arxiv.org/abs/2405.15179)
31. [Rethinking Class-Incremental Learning from a Dynamic Imbalanced Learning Perspective](https://arxiv.org/abs/2405.15157)
32. [CLIP model is an Efficient Online Lifelong Learner](https://arxiv.org/abs/2405.15155)
33. [Let Me Do It For You: Towards LLM Empowered Recommendation via Tool Learning](https://arxiv.org/abs/2405.15114)
34. [Music Genre Classification: Training an AI model](https://arxiv.org/abs/2405.15096)
35. [Credal Wrapper of Model Averaging for Uncertainty Estimation on Out-Of-Distribution Detection](https://arxiv.org/abs/2405.15047)
36. [What Variables Affect Out-Of-Distribution Generalization in Pretrained Models?](https://arxiv.org/abs/2405.15018)
37. [Extracting Prompts by Inverting LLM Outputs](https://arxiv.org/abs/2405.15012)
38. [Zero Shot Context-Based Object Segmentation using SLIP (SAM+CLIP)](https://arxiv.org/abs/2405.07284)
39. [Reason3D: Searching and Reasoning 3D Segmentation via Large Language Model](https://arxiv.org/abs/2405.17427)
40. [BehaviorGPT: Smart Agent Simulation for Autonomous Driving with Next-Patch Prediction](https://arxiv.org/abs/2405.17372)
41. [On the Noise Robustness of In-Context Learning for Text Generation](https://arxiv.org/abs/2405.17264)
42. [$\textit{Trans-LoRA}$: towards data-free Transferable Parameter Efficient Finetuning](https://arxiv.org/abs/2405.17258)
43. [RLAIF-V: Aligning MLLMs through Open-Source AI Feedback for Super GPT-4V Trustworthiness](https://arxiv.org/abs/2405.17220)
44. [The Expressive Capacity of State Space Models: A Formal Language Perspective](https://arxiv.org/abs/2405.17394)
45. [Efficient Ensembles Improve Training Data Attribution](https://arxiv.org/abs/2405.17293)
46. [An Introduction to Vision-Language Modeling](https://arxiv.org/abs/2405.17247)
47. [Benchmarking General Purpose In-Context Learning](https://arxiv.org/abs/2405.17234)
48. [Efficient multi-prompt evaluation of LLMs](https://arxiv.org/abs/2405.17202)
49. [WeiPer: OOD Detection using Weight Perturbations of Class Projections](https://arxiv.org/abs/2405.17164)
50. [Training-free Editioning of Text-to-Image Models](https://arxiv.org/abs/2405.17069)
51. [Improving Data-aware and Parameter-aware Robustness for Continual Learning](https://arxiv.org/abs/2405.17054)
52. [Compositional Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2405.17022)
53. [Vision-and-Language Navigation Generative Pretrained Transformer](https://arxiv.org/abs/2405.16994)
54. [Multilingual Diversity Improves Vision-Language Representations](https://arxiv.org/abs/2405.16915)
55. [Safe LoRA: the Silver Lining of Reducing Safety Risks when Fine-tuning Large Language Models](https://arxiv.org/abs/2405.16833)
56. [Automatic Domain Adaptation by Transformers in In-Context Learning](https://arxiv.org/abs/2405.16819)
57. [Image-level Regression for Uncertainty-aware Retinal Image Segmentation](https://arxiv.org/abs/2405.16815)
58. [Reframing the Relationship in Out-of-Distribution Detection](https://arxiv.org/abs/2405.16766)
59. [Adaptive VIO: Deep Visual-Inertial Odometry with Online Continual Learning](https://arxiv.org/abs/2405.16754)
60. [Few-shot Tuning of Foundation Models for Class-incremental Learning](https://arxiv.org/abs/2405.16625)
61. [On Sequential Loss Approximation for Continual Learning](https://arxiv.org/abs/2405.16498)
62. [CRoFT: Robust Fine-Tuning with Concurrent Optimization for OOD Generalization and Open-Set OOD Detection](https://arxiv.org/abs/2405.16417)
63. [Understanding the Effect of using Semantically Meaningful Tokens for Visual Representation Learning](https://arxiv.org/abs/2405.16401)
64. [A Second-Order perspective on Compositionality and Incremental Learning](https://arxiv.org/abs/2405.16350)
65. [Dual-Adapter: Training-free Dual Adaptation for Few-shot Out-of-Distribution Detection](https://arxiv.org/abs/2405.16146)
66. [Unsupervised Meta-Learning via In-Context Learning](https://arxiv.org/abs/2405.16124)
67. [Enhancing Visual-Language Modality Alignment in Large Vision Language Models via Self-Improvement](https://arxiv.org/abs/2405.15973)
68. [Activator: GLU Activations as The Core Functions of a Vision Transformer](https://arxiv.org/abs/2405.15953)
69. [Theories of synaptic memory consolidation and intelligent plasticity for continual learning](https://arxiv.org/abs/2405.16922)
70. [Memory-efficient High-resolution OCT Volume Synthesis with Cascaded Amortized Latent Diffusion Models](https://arxiv.org/abs/2405.16516)
71. [X-VILA: Cross-Modality Alignment for Large Language Model](https://arxiv.org/abs/2405.19335)
72. [LLMs Meet Multimodal Generation and Editing: A Survey](https://arxiv.org/abs/2405.19334)
73. [Multi-Modal Generative Embedding Model](https://arxiv.org/abs/2405.19333)
74. [Nearest Neighbor Speculative Decoding for LLM Generation and Attribution](https://arxiv.org/abs/2405.19325)
75. [Matryoshka Query Transformer for Large Vision-Language Models](https://arxiv.org/abs/2405.19315)
76. [Expert-Guided Extinction of Toxic Tokens for Debiased Generation](https://arxiv.org/abs/2405.19299)
77. [PediatricsGPT: Large Language Models as Chinese Medical Assistants for Pediatric Applications](https://arxiv.org/abs/2405.19266)
78. [Weak-to-Strong Search: Align Large Language Models via Searching over Small Language Models](https://arxiv.org/abs/2405.19262)
79. [Comparative Study of Neighbor-based Methods for Local Outlier Detection](https://arxiv.org/abs/2405.19247)
80. [Forward-Backward Knowledge Distillation for Continual Clustering](https://arxiv.org/abs/2405.19234)
81. [Does learning the right latent variables necessarily improve in-context learning?](https://arxiv.org/abs/2405.19162)
82. [Multi-stage Retrieve and Re-rank Model for Automatic Medical Coding Recommendation](https://arxiv.org/abs/2405.19093)
83. [Benchmarking and Improving Detail Image Caption](https://arxiv.org/abs/2405.19092)
84. [MEMoE: Enhancing Model Editing with Mixture of Experts Adaptors](https://arxiv.org/abs/2405.19086)
85. [Patch-enhanced Mask Encoder Prompt Image Generation](https://arxiv.org/abs/2405.19085)
86. [Resurrecting Old Classes with New Data for Exemplar-Free Continual Learning](https://arxiv.org/abs/2405.19074)
87. [MLAE: Masked LoRA Experts for Parameter-Efficient Fine-Tuning](https://arxiv.org/abs/2405.18897)
88. [LLaMA-Reg: Using LLaMA 2 for Unsupervised Medical Image Registration](https://arxiv.org/abs/2405.18774)
89. [Provable Contrastive Continual Learning](https://arxiv.org/abs/2405.18756)
90. [Recent Advances of Foundation Language Models-based Continual Learning: A Survey](https://arxiv.org/abs/2405.18653)
91. [When and How Does In-Distribution Label Help Out-of-Distribution Detection?](https://arxiv.org/abs/2405.18635)
92. [Low-Rank Few-Shot Adaptation of Vision-Language Models](https://arxiv.org/abs/2405.18541)
93. [Transductive Zero-Shot and Few-Shot CLIP](https://arxiv.org/abs/2405.18437)
94. [Cardiovascular Disease Detection from Multi-View Chest X-rays with BI-Mamba](https://arxiv.org/abs/2405.18533)
95. [Would I Lie To You? Inference Time Alignment of Language Models using Direct Preference Heads](https://arxiv.org/abs/2405.20053)
96. [Efficient LLM-Jailbreaking by Introducing Visual Modality](https://arxiv.org/abs/2405.20015)
97. [MM-Lego: Modular Biomedical Multimodal Models with Minimal Fine-Tuning](https://arxiv.org/abs/2405.19950)
98. [Synthetic Patients: Simulating Difficult Conversations with Multimodal Generative AI for Medical Education](https://arxiv.org/abs/2405.19941)
99. [Learning Discriminative Dynamics with Label Corruption for Noisy Label Detection](https://arxiv.org/abs/2405.19902)
100. [Open-Set Domain Adaptation for Semantic Segmentation](https://arxiv.org/abs/2405.19899)
101. [PixOOD: Pixel-Level Out-of-Distribution Detection](https://arxiv.org/abs/2405.19882)
102. [Exploring Key Factors for Long-Term Vessel Incident Risk Prediction](https://arxiv.org/abs/2405.19804)
103. [Text Guided Image Editing with Automatic Concept Locating and Forgetting](https://arxiv.org/abs/2405.19708)
104. [One Token Can Help! Learning Scalable and Pluggable Virtual Tokens for Retrieval-Augmented Large Language Models](https://arxiv.org/abs/2405.19670)
105. [Learning Robust Correlation with Foundation Model for Weakly-Supervised Few-Shot Segmentation](https://arxiv.org/abs/2405.19638)
106. [SVFT: Parameter-Efficient Fine-Tuning with Singular Vectors](https://arxiv.org/abs/2405.19597)
107. [Why Larger Language Models Do In-context Learning Differently?](https://arxiv.org/abs/2405.19592)
108. [Organizing Background to Explore Latent Classes for Incremental Few-shot Semantic Segmentation](https://arxiv.org/abs/2405.19568)
109. [CLIPLoss and Norm-Based Data Selection Methods for Multimodal Contrastive Learning](https://arxiv.org/abs/2405.19547)
110. [Video Anomaly Detection in 10 Years: A Survey and Outlook](https://arxiv.org/abs/2405.19387)
111. [Recasting Continual Learning as Sequence Modeling](https://arxiv.org/abs/2310.11952)
112. [Disentangling and Mitigating the Impact of Task Similarity for Continual Learning](https://arxiv.org/abs/2405.20236)
113. [Visual Perception by Large Language Model's Weights](https://arxiv.org/abs/2405.20339)
114. [Xwin-LM: Strong and Scalable Alignment Practice for LLMs](https://arxiv.org/abs/2405.20335)
115. [SurgiTrack: Fine-Grained Multi-Class Multi-Tool Tracking in Surgical Videos](https://arxiv.org/abs/2405.20333)
116. [ParSEL: Parameterized Shape Editing with Language](https://arxiv.org/abs/2405.20319)
117. [ANAH: Analytical Annotation of Hallucinations in Large Language Models](https://arxiv.org/abs/2405.20315)
118. [Can't make an Omelette without Breaking some Eggs: Plausible Action Anticipation using Large Video-Language Models](https://arxiv.org/abs/2405.20305)
119. [Towards Hierarchical Multi-Agent Workflows for Zero-Shot Prompt Optimization](https://arxiv.org/abs/2405.20252)
120. [Context Injection Attacks on Large Language Models](https://arxiv.org/abs/2405.20234)
121. [TS-Align: A Teacher-Student Collaborative Framework for Scalable Iterative Finetuning of Large Language Models](https://arxiv.org/abs/2405.20215)
122. [Jina CLIP: Your CLIP Model Is Also Your Text Retriever](https://arxiv.org/abs/2405.20204)
123. [TAIA: Large Language Models are Out-of-Distribution Data Learners](https://arxiv.org/abs/2405.20192)
124. [InstructionCP: A fast approach to transfer Large Language Models into target language](https://arxiv.org/abs/2405.20175)
125. [OpenDAS: Domain Adaptation for Open-Vocabulary Segmentation](https://arxiv.org/abs/2405.20141)
126. [MSSC-BiMamba: Multimodal Sleep Stage Classification and Early Diagnosis of Sleep Disorders with Bidirectional Mamba](https://arxiv.org/abs/2405.20142)
127. [Defensive Prompt Patch: A Robust and Interpretable Defense of LLMs against Jailbreak Attacks](https://arxiv.org/abs/2405.20099)
128. [The Fine-Tuning Paradox: Boosting Translation Quality Without Sacrificing LLM Abilities](https://arxiv.org/abs/2405.20089)
129. [Spectral Mapping of Singing Voices: U-Net-Assisted Vocal Segmentation](https://arxiv.org/abs/2405.20059)
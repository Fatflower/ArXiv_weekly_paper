# ArXiv_weekly_paper
This repository records interesting articles on the arXiv website every week (based on my own opinions only).
If you find some interesting articles in this week's arxiv that I've missed, feel free to email me (z1282429194@163.com) or ask a question and I'll add it later.

## Summary of recommended papers in 2024
<!-- | | | | |
|--------|--------|--------|--------| -->
|[1_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/1_week.md)|[2_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/2_week.md)|[3_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/3_week.md)|[4_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/4_week.md)|[5_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/5_week.md)|[6_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/6_week.md)|[7_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/7_week.md)|[8_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/8_week.md)|[9_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/9_week.md)|[10_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/10_week.md)|[11_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/11_week.md)|[12_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/12_week.md)|[13_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/13_week.md)|[14_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/14_week.md)|[15_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/15_week.md)|[16_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/16_week.md)|[17_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/17_week.md)|[18_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/18_week.md)|[19_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/19_week.md)|[20_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/20_week.md)|[21_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/21_week.md)|[22_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/22_week.md)

<!-- | | | | | -->

## Recommended Papers for Week 22, 2024
1. [FastDrag: Manipulate Anything in One Step](https://arxiv.org/abs/2405.15769)
2. [Scaling Laws for Discriminative Classification in Large Language Models](https://arxiv.org/abs/2405.15765)
3. [GPT is Not an Annotator: The Necessity of Human Annotation in Fairness Benchmark Construction](https://arxiv.org/abs/2405.15760)
4. [Data Reconstruction: When You See It and When You Don't](https://arxiv.org/abs/2405.15753)
5. [ConvLLaVA: Hierarchical Backbones as Visual Encoder for Large Multimodal Models](https://arxiv.org/abs/2405.15738)
6. [LM4LV: A Frozen Large Language Model for Low-level Vision Tasks](https://arxiv.org/abs/2405.15734)
7. [Disease-informed Adaptation of Vision-Language Models](https://arxiv.org/abs/2405.15728)
8. [Prompt-Aware Adapter: Towards Learning Adaptive Visual Tokens for Multimodal Large Language Models](https://arxiv.org/abs/2405.15684)
9. [Less is more: Summarizing Patch Tokens for efficient Multi-Label Class-Incremental Learning](https://arxiv.org/abs/2405.15633)
10. [MLPs Learn In-Context](https://arxiv.org/abs/2405.15618)
11. [Composed Image Retrieval for Remote Sensing](https://arxiv.org/abs/2405.15587)
12. [Meteor: Mamba-based Traversal of Rationale for Large Language and Vision Models](https://arxiv.org/abs/2405.15574)
13. [Thinking Forward: Memory-Efficient Federated Finetuning of Language Models](https://arxiv.org/abs/2405.15551)
14. [SEP: Self-Enhanced Prompt Tuning for Visual-Language Model](https://arxiv.org/abs/2405.15549)
15. [Sparse Matrix in Large Language Model Fine-tuning](https://arxiv.org/abs/2405.15525)
16. [Polyp Segmentation Generalisability of Pretrained Backbones](https://arxiv.org/abs/2405.15524)
17. [Efficient Degradation-aware Any Image Restoration](https://arxiv.org/abs/2405.15475)
18. [HyperInterval: Hypernetwork approach to training weight interval regions in continual learning](https://arxiv.org/abs/2405.15444)
19. [Smoothed Online Classification can be Harder than Batch Classification](https://arxiv.org/abs/2405.15424)
20. [U3M: Unbiased Multiscale Modal Fusion Model for Multimodal Semantic Segmentation](https://arxiv.org/abs/2405.15365)
21. [Towards Understanding the Working Mechanism of Text-to-Image Diffusion Model](https://arxiv.org/abs/2405.15330)
22. [Stacking Your Transformers: A Closer Look at Model Growth for Efficient LLM Pre-Training](https://arxiv.org/abs/2405.15319)
23. [Are Long-LLMs A Necessity For Long-Context Tasks?](https://arxiv.org/abs/2405.15318)
24. [Prompt Tuning Strikes Back: Customizing Foundation Models with Low-Rank Prompt Adaptation](https://arxiv.org/abs/2405.15282)
25. [Towards Global Optimal Visual In-Context Learning Prompt Selection](https://arxiv.org/abs/2405.15279)
26. [Cross-Domain Few-Shot Semantic Segmentation via Doubly Matching Transformation](https://arxiv.org/abs/2405.15265)
27. [Self-Contrastive Weakly Supervised Learning Framework for Prognostic Prediction Using Whole Slide Images](https://arxiv.org/abs/2405.15264)
28. [DEEM: Diffusion Models Serve as the Eyes of Large Language Models for Image Perception](https://arxiv.org/abs/2405.15232)
29. [Exploring the Impact of Synthetic Data for Aerial-view Human Detection](https://arxiv.org/abs/2405.15203)
30. [VB-LoRA: Extreme Parameter Efficient Fine-Tuning with Vector Banks](https://arxiv.org/abs/2405.15179)
31. [Rethinking Class-Incremental Learning from a Dynamic Imbalanced Learning Perspective](https://arxiv.org/abs/2405.15157)
32. [CLIP model is an Efficient Online Lifelong Learner](https://arxiv.org/abs/2405.15155)
33. [Let Me Do It For You: Towards LLM Empowered Recommendation via Tool Learning](https://arxiv.org/abs/2405.15114)
34. [Music Genre Classification: Training an AI model](https://arxiv.org/abs/2405.15096)
35. [Credal Wrapper of Model Averaging for Uncertainty Estimation on Out-Of-Distribution Detection](https://arxiv.org/abs/2405.15047)
36. [What Variables Affect Out-Of-Distribution Generalization in Pretrained Models?](https://arxiv.org/abs/2405.15018)
37. [Extracting Prompts by Inverting LLM Outputs](https://arxiv.org/abs/2405.15012)
38. [Zero Shot Context-Based Object Segmentation using SLIP (SAM+CLIP)](https://arxiv.org/abs/2405.07284)
39. [Reason3D: Searching and Reasoning 3D Segmentation via Large Language Model](https://arxiv.org/abs/2405.17427)
40. [BehaviorGPT: Smart Agent Simulation for Autonomous Driving with Next-Patch Prediction](https://arxiv.org/abs/2405.17372)
41. [On the Noise Robustness of In-Context Learning for Text Generation](https://arxiv.org/abs/2405.17264)
42. [$\textit{Trans-LoRA}$: towards data-free Transferable Parameter Efficient Finetuning](https://arxiv.org/abs/2405.17258)
43. [RLAIF-V: Aligning MLLMs through Open-Source AI Feedback for Super GPT-4V Trustworthiness](https://arxiv.org/abs/2405.17220)
44. [The Expressive Capacity of State Space Models: A Formal Language Perspective](https://arxiv.org/abs/2405.17394)
45. [Efficient Ensembles Improve Training Data Attribution](https://arxiv.org/abs/2405.17293)
46. [An Introduction to Vision-Language Modeling](https://arxiv.org/abs/2405.17247)
47. [Benchmarking General Purpose In-Context Learning](https://arxiv.org/abs/2405.17234)
48. [Efficient multi-prompt evaluation of LLMs](https://arxiv.org/abs/2405.17202)
49. [WeiPer: OOD Detection using Weight Perturbations of Class Projections](https://arxiv.org/abs/2405.17164)
50. [Training-free Editioning of Text-to-Image Models](https://arxiv.org/abs/2405.17069)
51. [Improving Data-aware and Parameter-aware Robustness for Continual Learning](https://arxiv.org/abs/2405.17054)
52. [Compositional Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2405.17022)
53. [Vision-and-Language Navigation Generative Pretrained Transformer](https://arxiv.org/abs/2405.16994)
54. [Multilingual Diversity Improves Vision-Language Representations](https://arxiv.org/abs/2405.16915)
55. [Safe LoRA: the Silver Lining of Reducing Safety Risks when Fine-tuning Large Language Models](https://arxiv.org/abs/2405.16833)
56. [Automatic Domain Adaptation by Transformers in In-Context Learning](https://arxiv.org/abs/2405.16819)
57. [Image-level Regression for Uncertainty-aware Retinal Image Segmentation](https://arxiv.org/abs/2405.16815)
58. [Reframing the Relationship in Out-of-Distribution Detection](https://arxiv.org/abs/2405.16766)
59. [Adaptive VIO: Deep Visual-Inertial Odometry with Online Continual Learning](https://arxiv.org/abs/2405.16754)
60. [Few-shot Tuning of Foundation Models for Class-incremental Learning](https://arxiv.org/abs/2405.16625)
61. [On Sequential Loss Approximation for Continual Learning](https://arxiv.org/abs/2405.16498)
62. [CRoFT: Robust Fine-Tuning with Concurrent Optimization for OOD Generalization and Open-Set OOD Detection](https://arxiv.org/abs/2405.16417)
63. [Understanding the Effect of using Semantically Meaningful Tokens for Visual Representation Learning](https://arxiv.org/abs/2405.16401)
64. [A Second-Order perspective on Compositionality and Incremental Learning](https://arxiv.org/abs/2405.16350)
65. [Dual-Adapter: Training-free Dual Adaptation for Few-shot Out-of-Distribution Detection](https://arxiv.org/abs/2405.16146)
66. [Unsupervised Meta-Learning via In-Context Learning](https://arxiv.org/abs/2405.16124)
67. [Enhancing Visual-Language Modality Alignment in Large Vision Language Models via Self-Improvement](https://arxiv.org/abs/2405.15973)
68. [Activator: GLU Activations as The Core Functions of a Vision Transformer](https://arxiv.org/abs/2405.15953)
69. [Theories of synaptic memory consolidation and intelligent plasticity for continual learning](https://arxiv.org/abs/2405.16922)
70. [Memory-efficient High-resolution OCT Volume Synthesis with Cascaded Amortized Latent Diffusion Models](https://arxiv.org/abs/2405.16516)
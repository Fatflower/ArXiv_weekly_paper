# ArXiv_weekly_paper
This repository records interesting articles on the arXiv website every week (based on my own opinions only).
If you find some interesting articles in this week's arxiv that I've missed, feel free to email me (z1282429194@163.com) or ask a question and I'll add it later.

## Summary of recommended papers in 2024
<!-- | | | | |
|--------|--------|--------|--------| -->
|[1_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/1_week.md)|[2_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/2_week.md)|[3_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/3_week.md)|[4_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/4_week.md)|[5_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/5_week.md)|[6_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/6_week.md)|[7_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/7_week.md)|[8_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/8_week.md)|[9_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/9_week.md)|[10_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/10_week.md)|[11_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/11_week.md)|[12_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/12_week.md)|[13_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/13_week.md)|[14_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/14_week.md)|[15_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/15_week.md)|[16_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/16_week.md)|[17_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/17_week.md)|[18_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/18_week.md)|[19_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/19_week.md)|[20_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/20_week.md)|[21_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/21_week.md)|[22_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/22_week.md)|[23_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/23_week.md)|[24_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/24_week.md)|[25_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/25_week.md)|[26_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/26_week.md)|[27_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/27_week.md)|[28_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/28_week.md)|[29_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/29_week.md)|[30_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/30_week.md)|[31_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/31_week.md)|[32_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/32_week.md)|[33_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/33_week.md)|[34_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/34_week.md)|[35_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/35_week.md)|[36_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/36_week.md)|[37_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/37_week.md)|[38_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/38_week.md)



<!-- | | | | | -->

## Recommended Papers for Week 38, 2024
1. [Affective Computing Has Changed: The Foundation Model Disruption](https://arxiv.org/abs/2409.08907)
2. [Visual Language Tracking with Multi-modal Interaction: A Robust Benchmark](https://arxiv.org/abs/2409.08887)
3. [Task-Specific Data Preparation for Deep Learning to Reconstruct Structures of Interest from Severely Truncated CBCT Data](https://arxiv.org/abs/2409.08800)
4. [Eir: Thai Medical Large Language Models](https://arxiv.org/abs/2409.08523)
5. [Anytime Continual Learning for Open Vocabulary Classification](https://arxiv.org/abs/2409.08518)
6. [Mamba-YOLO-World: Marrying YOLO-World with Mamba for Open-Vocabulary Detection](https://arxiv.org/abs/2409.08513)
7. [VLTP: Vision-Language Guided Token Pruning for Task-Oriented Segmentation](https://arxiv.org/abs/2409.08464)
8. [Continual Learning in 3D Point Clouds: Employing Spectral Techniques for Exemplar Selection](https://arxiv.org/abs/2409.08388)
9. [Tri-Plane Mamba: Efficiently Adapting Segment Anything Model for 3D Medical Images](https://arxiv.org/abs/2409.08492)
10. [MedSegMamba: 3D CNN-Mamba Hybrid Architecture for Brain Segmentation](https://arxiv.org/abs/2409.08307)
11. [LogicPro: Improving Complex Logical Reasoning via Program-Guided Learning](https://arxiv.org/abs/2409.12929)
12. [Scaling Smart: Accelerating Large Language Model Pre-training with Small Model Initialization](https://arxiv.org/abs/2409.12903)
13. [Exploring Large Language Models for Product Attribute Value Identification](https://arxiv.org/abs/2409.12695)
14. [LARE: Latent Augmentation using Regional Embedding with Vision-Language Model](https://arxiv.org/abs/2409.12597)
15. [Prompting Segment Anything Model with Domain-Adaptive Prototype for Generalizable Medical Image Segmentation](https://arxiv.org/abs/2409.12522)
16. [Learning Multi-Manifold Embedding for Out-Of-Distribution Detection](https://arxiv.org/abs/2409.12479)
17. [A Novel Perspective for Multi-modal Multi-label Skin Lesion Classification](https://arxiv.org/abs/2409.12390)
18. [ReFu: Recursive Fusion for Exemplar-Free 3D Class-Incremental Learning](https://arxiv.org/abs/2409.12326)
19. [Large Language Models Are Strong Audio-Visual Speech Recognition Learners](https://arxiv.org/abs/2409.12319)
20. [MambaClinix: Hierarchical Gated Convolution and Mamba-Based U-Net for Enhanced 3D Medical Image Segmentation](https://arxiv.org/abs/2409.12533)
21. [I2I-Galip: Unsupervised Medical Image Translation Using Generative Adversarial CLIP](https://arxiv.org/abs/2409.12399)
22. [HEARTS: A Holistic Framework for Explainable, Sustainable and Robust Text Stereotype Detection](https://arxiv.org/abs/2409.11579)
23. [Preference Tuning with Human Feedback on Language, Speech, and Vision Tasks: A Survey](https://arxiv.org/abs/2409.11564)
24. [Cross-Organ and Cross-Scanner Adenocarcinoma Segmentation using Rein to Fine-tune Vision Foundation Models](https://arxiv.org/abs/2409.11752)
25. [Few-Shot Learning Approach on Tuberculosis Classification Based on Chest X-Ray Images](https://arxiv.org/abs/2409.11644)
26. [Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at Any Resolution](https://arxiv.org/abs/2409.12191)
27. [Qwen2.5-Coder Technical Report](https://arxiv.org/abs/2409.12186)
28. [MAgICoRe: Multi-Agent, Iterative, Coarse-to-Fine Refinement for Reasoning](https://arxiv.org/abs/2409.12147)
29. [Applications of Knowledge Distillation in Remote Sensing: A Survey](https://arxiv.org/abs/2409.12111)
30. [Mixture of Prompt Learning for Vision Language Models](https://arxiv.org/abs/2409.12011)
31. [LLM-wrapper: Black-Box Semantic-Aware Adaptation of Vision-Language Foundation Models](https://arxiv.org/abs/2409.11919)
32. [EFCM: Efficient Fine-tuning on Compressed Models for deployment of large models in medical image analysis](https://arxiv.org/abs/2409.11817)
33. [Knowledge Adaptation Network for Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2409.11770)
34. [Multi-OCT-SelfNet: Integrating Self-Supervised Learning with Multi-Source Data Fusion for Enhanced Multi-Class Retinal Disease Classification](https://arxiv.org/abs/2409.11375)
35. [Reducing Catastrophic Forgetting in Online Class Incremental Learning Using Self-Distillation](https://arxiv.org/abs/2409.11329)
36. [LPT++: Efficient Training on Mixture of Long-tailed Experts](https://arxiv.org/abs/2409.11323)
37. [MSDNet: Multi-Scale Decoder for Few-Shot Semantic Segmentation via Transformer-Guided Prototyping](https://arxiv.org/abs/2409.11316)
38. [Beyond LoRA: Exploring Efficient Fine-Tuning Techniques for Time Series Foundational Models](https://arxiv.org/abs/2409.11302)
39. [Towards Novel Malicious Packet Recognition: A Few-Shot Learning Approach](https://arxiv.org/abs/2409.11254)
40. [Diversity-grounded Channel Prototypical Learning for Out-of-Distribution Intent Detection](https://arxiv.org/abs/2409.11114)
41. [Versatile Incremental Learning: Towards Class and Domain-Agnostic Incremental Learning](https://arxiv.org/abs/2409.10956)
42. [Veridical Data Science for Medical Foundation Models](https://arxiv.org/abs/2409.10580)
43. [Convolutional Networks as Extremely Small Foundation Models: Visual Prompting and Theoretical Perspective](https://arxiv.org/abs/2409.10555)
44. [TTT-Unet: Enhancing U-Net with Test-Time Training Layers for biomedical image segmentation](https://arxiv.org/abs/2409.11299)
45. [MAISI: Medical AI for Synthetic Imaging](https://arxiv.org/abs/2409.11169)
46. [CUNSB-RFIE: Context-aware Unpaired Neural Schr"{o}dinger Bridge in Retinal Fundus Image Enhancement](https://arxiv.org/abs/2409.10966)
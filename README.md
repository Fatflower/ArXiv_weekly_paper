# ArXiv_weekly_paper
This repository records interesting articles on the arXiv website every week (based on my own opinions only).
If you find some interesting articles in this week's arxiv that I've missed, feel free to email me (z1282429194@163.com) or ask a question and I'll add it later.

## Summary of recommended papers in 2024
<!-- | | | | |
|--------|--------|--------|--------| -->
|[1_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/1_week.md)|[2_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/2_week.md)|[3_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/3_week.md)|[4_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/4_week.md)|

<!-- | | | | | -->

## Recommended Papers for Week 4, 2024
1. [Pruning for Protection: Increasing Jailbreak Resistance in Aligned LLMs Without Fine-Tuning](https://arxiv.org/abs/2401.10862)
2. [Removal and Selection: Improving RGB-Infrared Object Detection via Coarse-to-Fine Fusion](https://arxiv.org/abs/2401.10731)
3. [AutoChunk: Automated Activation Chunk for Memory-Efficient Long Sequence Inference](https://arxiv.org/abs/2401.10652)
4. [OrchMoE: Efficient Multi-Adapter Learning with Task-Skill Synergy](https://arxiv.org/abs/2401.10559)
5. [Unified View Imputation and Feature Selection Learning for Incomplete Multi-view Data](https://arxiv.org/abs/2401.10549)
6. [Mementos: A Comprehensive Benchmark for Multimodal Large Language Model Reasoning over Image Sequences](https://arxiv.org/abs/2401.10529)
7. [On mitigating stability-plasticity dilemma in CLIP-guided image morphing via geodesic distillation loss](https://arxiv.org/abs/2401.10526)
8. [Focaler-IoU: More Focused Intersection over Union Loss](https://arxiv.org/abs/2401.10525)
9. [LDReg: Local Dimensionality Regularized Self-Supervised Learning](https://arxiv.org/abs/2401.10474)
10. [Investigating Training Strategies and Model Robustness of Low-Rank Adaptation for Language Modeling in Speech Recognition](https://arxiv.org/abs/2401.10447)
11. [Vulnerabilities of Foundation Model Integrated Federated Learning Under Adversarial Threats](https://arxiv.org/abs/2401.10375)
12. [EEGFormer: Towards Transferable and Interpretable Large-Scale EEG Foundation Model](https://arxiv.org/abs/2401.10278)
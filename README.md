# ArXiv_weekly_paper
This repository records interesting articles on the arXiv website every week (based on my own opinions only).
If you find some interesting articles in this week's arxiv that I've missed, feel free to email me (z1282429194@163.com) or ask a question and I'll add it later.

## Summary of recommended papers in 2024
<!-- | | | | |
|--------|--------|--------|--------| -->
|[1_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/1_week.md)|[2_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/2_week.md)|[3_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/3_week.md)|[4_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/4_week.md)|[5_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/5_week.md)|[6_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/6_week.md)|[7_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/7_week.md)

<!-- | | | | | -->

## Recommended Papers for Week 7, 2024
1. [FaBERT: Pre-training BERT on Persian Blogs](https://arxiv.org/abs/2402.06617)
2. [More than the Sum of Its Parts: Ensembling Backbone Networks for Few-Shot Segmentation](https://arxiv.org/abs/2402.06581)
3. [Diffusion-ES: Gradient-free Planning with Diffusion for Autonomous Driving and Zero-Shot Instruction Following](https://arxiv.org/abs/2402.06559)
4. [Bryndza at ClimateActivism 2024: Stance, Target and Hate Event Detection via Retrieval-Augmented GPT-4 and LLaMA](https://arxiv.org/abs/2402.06549)
5. [Calibrating Long-form Generations from Large Language Models](https://arxiv.org/abs/2402.06544)
6. [Feature Density Estimation for Out-of-Distribution Detection via Normalizing Flows](https://arxiv.org/abs/2402.06537)
7. [Refining Myocardial Infarction Detection: A Novel Multi-Modal Composite Kernel Strategy in One-Class Classification](https://arxiv.org/abs/2402.06530)
8. [BarlowTwins-CXR : Enhancing Chest X-Ray abnormality localization in heterogeneous data with cross-domain self-supervised learning](https://arxiv.org/abs/2402.06499)
9. [Iris-SAM: Iris Segmentation Using a Foundational Model](https://arxiv.org/abs/2402.06497)
10. [Large Language Models for Captioning and Retrieving Remote Sensing Images](https://arxiv.org/abs/2402.06475)
11. [Where is the Truth? The Risk of Getting Confounded in a Continual World](https://arxiv.org/abs/2402.06434)
12. [Continual Learning on Graphs: A Survey](https://arxiv.org/abs/2402.06330)
13. [Taking Class Imbalance Into Account in Open Set Recognition Evaluation](https://arxiv.org/abs/2402.06331)
14. [A Unified Causal View of Instruction Tuning](https://arxiv.org/abs/2402.06220)
15. [ViGoR: Improving Visual Grounding of Large Vision Language Models with Fine-Grained Reward Modeling](https://arxiv.org/abs/2402.06118)
16. [Rethinking Data Selection for Supervised Fine-Tuning](https://arxiv.org/abs/2402.06094)
17. [Exploring Visual Culture Awareness in GPT-4V: A Comprehensive Probing](https://arxiv.org/abs/2402.06015)
18. [A Survey on Transformer Compression](https://arxiv.org/abs/2402.05964)
19. [EasyFS: an Efficient Model-free Feature Selection Framework via Elastic Transformation of Features](https://arxiv.org/abs/2402.05954)
20. [FAST: Factorizable Attention for Speeding up Transformers](https://arxiv.org/abs/2402.07901)
21. [Label-Efficient Model Selection for Text Generation](https://arxiv.org/abs/2402.07891)
22. [Scaling Laws for Fine-Grained Mixture of Experts](https://arxiv.org/abs/2402.07871)
23. [Prismatic VLMs: Investigating the Design Space of Visually-Conditioned Language Models](https://arxiv.org/abs/2402.07865)
24. [On Computationally Efficient Multi-Class Calibration](https://arxiv.org/abs/2402.07821)
25. [Multi-Intent Attribute-Aware Text Matching in Searching](https://arxiv.org/abs/2402.07788)
26. [HYPO: Hyperspherical Out-of-Distribution Generalization](https://arxiv.org/abs/2402.07785)
27. [Complete Instances Mining for Weakly Supervised Instance Segmentation](https://arxiv.org/abs/2402.07633)
28. [SLIT: Boosting Audio-Text Pre-Training via Multi-Stage Learning and Instruction Tuning](https://arxiv.org/abs/2402.07485)
29. [A Closer Look at the Robustness of Contrastive Language-Image Pre-Training (CLIP)](https://arxiv.org/abs/2402.07410)
30. [Make it more specific: A novel uncertainty based airway segmentation application on 3D U-Net and its variants](https://arxiv.org/abs/2402.07403)
31. [Deep Learning for Medical Image Segmentation with Imprecise Annotation](https://arxiv.org/abs/2402.07330)
32. [The Bias of Harmful Label Associations in Vision-Language Models](https://arxiv.org/abs/2402.07329)
33. [TransGPT: Multi-modal Generative Pre-trained Transformer for Transportation](https://arxiv.org/abs/2402.07233)
34. [A novel spatial-frequency domain network for zero-shot incremental learning](https://arxiv.org/abs/2402.07216)
35. [3D Gaussian as a New Vision Era: A Survey](https://arxiv.org/abs/2402.07181)
36. [Two-Stage Multi-task Self-Supervised Learning for Medical Image Segmentation](https://arxiv.org/abs/2402.07119)
37. [SpeechCLIP+: Self-supervised multi-task representation learning for speech via CLIP and speech-image data](https://arxiv.org/abs/2402.06959)
38. [Assessing Uncertainty Estimation Methods for 3D Image Segmentation under Distribution Shifts](https://arxiv.org/abs/2402.06937)
39. [ChemLLM: A Chemical Large Language Model](https://arxiv.org/abs/2402.06852)
40. [Reasoning Grasping via Multimodal Large Language Model](https://arxiv.org/abs/2402.06798)
41. [Private Knowledge Sharing in Distributed Learning: A Survey](https://arxiv.org/abs/2402.06682)
42. [Comparative Analysis of ImageNet Pre-Trained Deep Learning Models and DINOv2 in Medical Imaging Classification](https://arxiv.org/abs/2402.07595)
43. [Re-DiffiNet: Modeling discrepancies in tumor segmentation using diffusion](https://arxiv.org/abs/2402.07354)
44. [Semi-Mamba-UNet: Pixel-Level Contrastive Cross-Supervised Visual Mamba-based UNet for Semi-Supervised Medical Image Segmentation](https://arxiv.org/abs/2402.07245)
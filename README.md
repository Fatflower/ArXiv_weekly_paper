# ArXiv_weekly_paper
This repository records interesting articles on the arXiv website every week (based on my own opinions only).
If you find some interesting articles in this week's arxiv that I've missed, feel free to email me (z1282429194@163.com) or ask a question and I'll add it later.

## Summary of recommended papers in 2024
<!-- | | | | |
|--------|--------|--------|--------| -->
|[1_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/1_week.md)|[2_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/2_week.md)|[3_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/3_week.md)|[4_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/4_week.md)|[5_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/5_week.md)

<!-- | | | | | -->

## Recommended Papers for Week 5, 2024
1. [From GPT-4 to Gemini and Beyond: Assessing the Landscape of MLLMs on Generalizability, Trustworthiness and Causality through Four Modalities](https://arxiv.org/abs/2401.15071)
2. [Masked Pre-trained Model Enables Universal Zero-shot Denoiser](https://arxiv.org/abs/2401.14966)
3. [Memory-Inspired Temporal Prompt Interaction for Text-Image Classification](https://arxiv.org/abs/2401.14856)
4. [TIP-Editor: An Accurate 3D Editor Following Both Text-Prompts And Image-Prompts](https://arxiv.org/abs/2401.14828)
5. [PL-FSCIL: Harnessing the Power of Prompts for Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2401.14807)
6. [SSR: SAM is a Strong Regularizer for domain adaptive semantic segmentation](https://arxiv.org/abs/2401.14686)
7. [Revisiting Active Learning in the Era of Vision Foundation Models](https://arxiv.org/abs/2401.14555)
8. [K-QA: A Real-World Medical Q&A Benchmark](https://arxiv.org/abs/2401.14493)
9. [Strategic Usage in a Multi-Learner Setting](https://arxiv.org/abs/2401.16422)
10. [InternLM-XComposer2: Mastering Free-form Text-Image Composition and Comprehension in Vision-Language Large Model](https://arxiv.org/abs/2401.16420)
11. [Scaling Sparse Fine-Tuning to Large Language Models](https://arxiv.org/abs/2401.16405)
12. [Continual Learning with Pre-Trained Models: A Survey](https://arxiv.org/abs/2401.16386)
13. [Spatial-Aware Latent Initialization for Controllable Image Generation](https://arxiv.org/abs/2401.16157)
14. [Sample Weight Estimation Using Meta-Updates for Online Continual Learning](https://arxiv.org/abs/2401.15973)
15. [MoE-LLaVA: Mixture of Experts for Large Vision-Language Models](https://arxiv.org/abs/2401.15947)
16. [Overcoming the Pitfalls of Vision-Language Model Finetuning for OOD Generalization](https://arxiv.org/abs/2401.15914)
17. [Cross-Scale MAE: A Tale of Multi-Scale Exploitation in Remote Sensing](https://arxiv.org/abs/2401.15855)
18. [Few and Fewer: Learning Better from Few Examples Using Fewer Base Classes](https://arxiv.org/abs/2401.15834)
19. [Divide and Conquer: Language Models can Plan and Self-Correct for Compositional Text-to-Image Generation](https://arxiv.org/abs/2401.15688)
20. [Data-Free Generalized Zero-Shot Learning](https://arxiv.org/abs/2401.15657)
21. [IntentTuner: An Interactive Framework for Integrating Human Intents in Fine-tuning Text-to-Image Generative Models](https://arxiv.org/abs/2401.15559)
22. [Dynamic Transformer Architecture for Continual Learning of Multimodal Tasks](https://arxiv.org/abs/2401.15275)
23. [HiFT: A Hierarchical Full Parameter Fine-Tuning Strategy](https://arxiv.org/abs/2401.15207)
24. [Improving Fairness of Automated Chest X-ray Diagnosis by Contrastive Learning](https://arxiv.org/abs/2401.15111)
25. [YOLO-World: Real-Time Open-Vocabulary Object Detection](https://arxiv.org/abs/2401.17270)
26. [ReacLLaMA: Merging chemical and textual information in chemical reactivity AI models](https://arxiv.org/abs/2401.17267)
27. [Weaver: Foundation Models for Creative Writing](https://arxiv.org/abs/2401.17268)
28. [Embracing Language Inclusivity and Diversity in CLIP through Continual Language Learning](https://arxiv.org/abs/2401.17186)
29. [ViTree: Single-path Neural Tree for Step-wise Interpretable Fine-grained Visual Categorization](https://arxiv.org/abs/2401.17050)
30. [EarthGPT: A Universal Multi-modal Large Language Model for Multi-sensor Image Comprehension in Remote Sensing Domain](https://arxiv.org/abs/2401.16822)
31. [Pick-and-Draw: Training-free Semantic Guidance for Text-to-Image Personalization](https://arxiv.org/abs/2401.16762)
32. [MESA: Matching Everything by Segmenting Anything](https://arxiv.org/abs/2401.16741)
33. [Depth Anything in Medical Images: A Comparative Study](https://arxiv.org/abs/2401.16600)
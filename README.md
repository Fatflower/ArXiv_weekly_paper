# ArXiv_weekly_paper
This repository records interesting articles on the arXiv website every week (based on my own opinions only).
If you find some interesting articles in this week's arxiv that I've missed, feel free to email me (z1282429194@163.com) or ask a question and I'll add it later.

## Summary of recommended papers in 2024
<!-- | | | | |
|--------|--------|--------|--------| -->
|[1_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/1_week.md)|[2_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/2_week.md)|[3_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/3_week.md)|[4_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/4_week.md)|[5_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/5_week.md)|[6_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/6_week.md)|[7_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/7_week.md)|[8_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/8_week.md)|[9_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/9_week.md)|[10_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/10_week.md)|[11_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/11_week.md)|[12_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/12_week.md)|[13_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/13_week.md)|[14_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/14_week.md)|[15_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/15_week.md)|[16_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/16_week.md)|[17_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/17_week.md)|[18_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/18_week.md)|[19_week](https://github.com/Fatflower/ArXiv_weekly_paper/blob/main/2024/19_week.md)

<!-- | | | | | -->

## Recommended Papers for Week 19, 2024
1. [On the test-time zero-shot generalization of vision-language models: Do we really need prompt learning?](https://arxiv.org/abs/2405.02266)
2. [What matters when building vision-language models?](https://arxiv.org/abs/2405.02246)
3. [Training-Free Deepfake Voice Recognition by Leveraging Large-Scale Pre-Trained Models](https://arxiv.org/abs/2405.02179)
4. [Multi-method Integration with Confidence-based Weighting for Zero-shot Image Classification](https://arxiv.org/abs/2405.02155)
5. [EEG2TEXT: Open Vocabulary EEG-to-Text Decoding with EEG Pre-Training and Multi-View Transformer](https://arxiv.org/abs/2405.02165)
6. [MedReadMe: A Systematic Study for Fine-grained Sentence Readability in Medical Domain](https://arxiv.org/abs/2405.02144)
7. [Analyzing Narrative Processing in Large Language Models (LLMs): Using GPT4 to test BERT](https://arxiv.org/abs/2405.02024)
8. [The Trade-off between Performance, Efficiency, and Fairness in Adapter Modules for Text Classification](https://arxiv.org/abs/2405.02010)
9. [Enhancing Micro Gesture Recognition for Emotion Understanding via Context-aware Visual-Text Contrastive Learning](https://arxiv.org/abs/2405.01885)
10. [Improving Concept Alignment in Vision-Language Concept Bottleneck Models](https://arxiv.org/abs/2405.01825)
11. [A Survey on Large Language Models for Critical Societal Domains: Finance, Healthcare, and Law](https://arxiv.org/abs/2405.01769)
12. [Development of Skip Connection in Deep Neural Networks for Computer Vision and Medical Image Analysis: A Survey](https://arxiv.org/abs/2405.01725)
13. [Mapping the Unseen: Unified Promptable Panoptic Mapping with Dynamic Labeling using Foundation Models](https://arxiv.org/abs/2405.02162)
14. [Why is SAM Robust to Label Noise?](https://arxiv.org/abs/2405.03676)
15. [Liberating Seen Classes: Boosting Few-Shot and Zero-Shot Text Classification via Anchor Generation and Classification Reframing](https://arxiv.org/abs/2405.03565)
16. [CCDM: Continuous Conditional Diffusion Models for Image Generation](https://arxiv.org/abs/2405.03546)
17. [Knowledge-aware Text-Image Retrieval for Remote Sensing Images](https://arxiv.org/abs/2405.03373)
18. [Examining Changes in Internal Representations of Continual Learning Models Through Tensor Decomposition](https://arxiv.org/abs/2405.03244)
19. [Intra-task Mutual Attention based Vision Transformer for Few-Shot Learning](https://arxiv.org/abs/2405.03109)
20. [Tree-based Ensemble Learning for Out-of-distribution Detection](https://arxiv.org/abs/2405.03060)
21. [Source-Free Domain Adaptation Guided by Vision and Vision-Language Pre-Training](https://arxiv.org/abs/2405.02954)
22. [Beyond Unimodal Learning: The Importance of Integrating Multiple Modalities for Lifelong Learning](https://arxiv.org/abs/2405.02766)
23. [Efficient Exploration of Image Classifier Failures with Bayesian Optimization and Text-to-Image Models](https://arxiv.org/abs/2405.02332)
24. [DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model](https://arxiv.org/abs/2405.04434)
25. [On the Foundations of Earth and Climate Foundation Models](https://arxiv.org/abs/2405.04285)
26. [Semi-Supervised Disease Classification based on Limited Medical Image Data](https://arxiv.org/abs/2405.04295)
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73. [DeiT-LT Distillation Strikes Back for Vision Transformer Training on Long-Tailed Datasets](https://arxiv.org/abs/2404.02900)\n",
      "74. [On the Scalability of Diffusion-based Text-to-Image Generation](https://arxiv.org/abs/2404.02883)\n",
      "75. [End-To-End Self-tuning Self-supervised Time Series Anomaly Detection](https://arxiv.org/abs/2404.02865)\n",
      "76. [Toward Inference-optimal Mixture-of-Expert Large Language Models](https://arxiv.org/abs/2404.02852)\n",
      "77. [Cross-Modal Conditioned Reconstruction for Language-guided Medical Image Segmentation](https://arxiv.org/abs/2404.02845)\n",
      "78. [Enhancing Interpretability of Vertebrae Fracture Grading using Human-interpretable Prototypes](https://arxiv.org/abs/2404.02830)\n",
      "79. [BAdam: A Memory Efficient Full Parameter Training Method for Large Language Models](https://arxiv.org/abs/2404.02827)\n",
      "80. [MULAN: A Multi Layer Annotated Dataset for Controllable Text-to-Image Generation](https://arxiv.org/abs/2404.02790)\n",
      "81. [FPT: Feature Prompt Tuning for Few-shot Readability Assessment](https://arxiv.org/abs/2404.02772)\n",
      "82. [Cross-Attention Makes Inference Cumbersome in Text-to-Image Diffusion Models](https://arxiv.org/abs/2404.02747)\n",
      "83. [InstantStyle: Free Lunch towards Style-Preserving in Text-to-Image Generation](https://arxiv.org/abs/2404.02733)\n",
      "84. [Harnessing the Power of Large Vision Language Models for Synthetic Image Detection](https://arxiv.org/abs/2404.02726)\n",
      "85. [Automatic Prompt Selection for Large Language Models](https://arxiv.org/abs/2404.02717)\n",
      "86. [Model-agnostic Origin Attribution of Generated Images with Few-shot Examples](https://arxiv.org/abs/2404.02697)\n",
      "87. [Non-negative Subspace Feature Representation for Few-shot Learning in Medical Imaging](https://arxiv.org/abs/2404.02656)\n",
      "88. [SG-BEV: Satellite-Guided BEV Fusion for Cross-View Semantic Segmentation](https://arxiv.org/abs/2404.02638)\n",
      "89. [Diffexplainer: Towards Cross-modal Global Explanations with Diffusion Models](https://arxiv.org/abs/2404.02618)\n",
      "90. [PromptRPA: Generating Robotic Process Automation on Smartphones from Textual Prompts](https://arxiv.org/abs/2404.02475)\n",
      "91. [RS3Mamba: Visual State Space Model for Remote Sensing Images Semantic Segmentation](https://arxiv.org/abs/2404.02457)\n",
      "92. [Adaptive Cross-lingual Text Classification through In-Context One-Shot Demonstrations](https://arxiv.org/abs/2404.02452)\n",
      "93. [Enhancing Low-Resource LLMs Classification with PEFT and Synthetic Data](https://arxiv.org/abs/2404.02422)\n",
      "94. [What Are We Measuring When We Evaluate Large Vision-Language Models? An Analysis of Latent Factors and Biases](https://arxiv.org/abs/2404.02415)\n",
      "95. [Enhancing Human-Computer Interaction in Chest X-ray Analysis using Vision and Language Model with Eye Gaze Patterns](https://arxiv.org/abs/2404.02370)\n",
      "96. [Semantic Augmentation in Images using Language](https://arxiv.org/abs/2404.02353)\n",
      "97. [LP++: A Surprisingly Strong Linear Probe for Few-Shot CLIP](https://arxiv.org/abs/2404.02285)\n"
     ]
    }
   ],
   "source": [
    "def convert_text_in_file(file_path, cnt=1):\n",
    "    output_lines = []\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for i, line in enumerate(file):\n",
    "            url, title = line.strip().split(\" | \")\n",
    "            paper_title = title.split(\"] \")[1]\n",
    "            formatted_line = f\"{i+cnt+1}. [{paper_title}]({url})\"\n",
    "            output_lines.append(formatted_line)\n",
    "            \n",
    "\n",
    "    return \"\\n\".join(output_lines)\n",
    "\n",
    "\n",
    "# 请将 'path_to_your_file.txt' 替换为你的txt文件路径\n",
    "file_path = 'tmp.txt'\n",
    "converted_text = convert_text_in_file(file_path, cnt=72)\n",
    "print(converted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79. [Self-Play Fine-Tuning of Diffusion Models for Text-to-Image Generation](https://arxiv.org/abs/2402.10210)\n",
      "80. [Recovering the Pre-Fine-Tuning Weights of Generative Models](https://arxiv.org/abs/2402.10208)\n",
      "81. [Hierarchical State Space Models for Continuous Sequence-to-Sequence Modeling](https://arxiv.org/abs/2402.10211)\n",
      "82. [Unlocking the Potential of Transformers in Time Series Forecasting with Sharpness-Aware Minimization and Channel-Wise Attention](https://arxiv.org/abs/2402.10198)\n",
      "83. [Selective Reflection-Tuning: Student-Selected Data Recycling for LLM Instruction-Tuning](https://arxiv.org/abs/2402.10110)\n",
      "84. [Tuning In: Analysis of Audio Classifier Performance in Clinical Settings with Limited Data](https://arxiv.org/abs/2402.10100)\n",
      "85. [Balancing the Causal Effects in Class-Incremental Learning](https://arxiv.org/abs/2402.10063)\n",
      "86. [Optimal Parameter and Neuron Pruning for Out-of-Distribution Detection](https://arxiv.org/abs/2402.10062)\n",
      "87. [Textual Localization: Decomposing Multi-concept Images for Subject-Driven Text-to-Image Generation](https://arxiv.org/abs/2402.09966)\n",
      "88. [Generative Representational Instruction Tuning](https://arxiv.org/abs/2402.09906)\n",
      "89. [DreamMatcher: Appearance Matching Self-Attention for Semantically-Consistent Text-to-Image Personalization](https://arxiv.org/abs/2402.09812)\n",
      "90. [EFUF: Efficient Fine-grained Unlearning Framework for Mitigating Hallucinations in Multimodal Large Language Models](https://arxiv.org/abs/2402.09801)\n",
      "91. [Model Compression and Efficient Inference for Large Language Models: A Survey](https://arxiv.org/abs/2402.09748)\n",
      "92. [QuRating: Selecting High-Quality Data for Training Language Models](https://arxiv.org/abs/2402.09739)\n",
      "93. [Prompt-based Personalized Federated Learning for Medical Visual Question Answering](https://arxiv.org/abs/2402.09677)\n",
      "94. [How to Train Data-Efficient LLMs](https://arxiv.org/abs/2402.09668)\n",
      "95. [VisIRNet: Deep Image Alignment for UAV-taken Visible and Infrared Image Pairs](https://arxiv.org/abs/2402.09635)\n",
      "96. [Quantified Task Misalignment to Inform PEFT: An Exploration of Domain Generalization and Catastrophic Forgetting in CLIP](https://arxiv.org/abs/2402.09613)\n",
      "97. [Domain Adaptation for Contrastive Audio-Language Models](https://arxiv.org/abs/2402.09585)\n",
      "98. [Learning From Lessons Learned: Preliminary Findings From a Study of Learning From Failure](https://arxiv.org/abs/2402.09538)\n"
     ]
    }
   ],
   "source": [
    "def convert_text_in_file(file_path, cnt=1):\n",
    "    output_lines = []\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for i, line in enumerate(file):\n",
    "            url, title = line.strip().split(\" | \")\n",
    "            paper_title = title.split(\"] \")[1]\n",
    "            formatted_line = f\"{i+cnt+1}. [{paper_title}]({url})\"\n",
    "            output_lines.append(formatted_line)\n",
    "            \n",
    "\n",
    "    return \"\\n\".join(output_lines)\n",
    "\n",
    "\n",
    "# 请将 'path_to_your_file.txt' 替换为你的txt文件路径\n",
    "file_path = 'tmp.txt'\n",
    "converted_text = convert_text_in_file(file_path, cnt=78)\n",
    "print(converted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

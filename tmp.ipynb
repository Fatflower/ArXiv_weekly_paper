{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. [A Large-Scale Evaluation of Speech Foundation Models](https://arxiv.org/abs/2404.09385)\n",
      "5. [Diffusion Models Meet Remote Sensing: Principles, Methods, and Perspectives](https://arxiv.org/abs/2404.08926)\n",
      "6. [PM2: A New Prompting Multi-modal Model Paradigm for Few-shot Medical Image Classification](https://arxiv.org/abs/2404.08915)\n",
      "7. [EIVEN: Efficient Implicit Attribute Value Extraction using Multimodal LLM](https://arxiv.org/abs/2404.08886)\n",
      "8. [Is Next Token Prediction Sufficient for GPT? Exploration on Code Logic Comprehension](https://arxiv.org/abs/2404.08885)\n",
      "9. [Generative AI Agent for Next-Generation MIMO Design: Fundamentals, Challenges, and Vision](https://arxiv.org/abs/2404.08878)\n",
      "10. [Aligning LLMs for FL-free Program Repair](https://arxiv.org/abs/2404.08877)\n",
      "11. [LLM In-Context Recall is Prompt Dependent](https://arxiv.org/abs/2404.08865)\n",
      "12. [Voice Attribute Editing with Text Prompt](https://arxiv.org/abs/2404.08857)\n",
      "13. [The Illusion of State in State-Space Models](https://arxiv.org/abs/2404.08819)\n",
      "14. [Detecting AI-Generated Images via CLIP](https://arxiv.org/abs/2404.08788)\n",
      "15. [LLM-Seg: Bridging Image Segmentation and Large Language Model Reasoning](https://arxiv.org/abs/2404.08767)\n",
      "16. [`Eyes of a Hawk and Ears of a Fox': Part Prototype Network for Generalized Zero-Shot Learning](https://arxiv.org/abs/2404.08761)\n",
      "17. [Your Finetuned Large Language Model is Already a Powerful Out-of-distribution Detector](https://arxiv.org/abs/2404.08679)\n",
      "18. [MaxFusion: Plug&Play Multi-Modal Generation in Text-to-Image Diffusion Models](https://arxiv.org/abs/2404.09977)\n",
      "19. [How to build the best medical image segmentation algorithm using foundation models: a comprehensive empirical study with Segment Anything Model](https://arxiv.org/abs/2404.09957)\n",
      "20. [Evolving Interpretable Visual Classifiers with Large Language Models](https://arxiv.org/abs/2404.09941)\n",
      "21. [Foundational Challenges in Assuring Alignment and Safety of Large Language Models](https://arxiv.org/abs/2404.09932)\n",
      "22. [Evaluating the Explainability of Attributes and Prototypes for a Medical Classification Model](https://arxiv.org/abs/2404.09917)\n",
      "23. [Conditional Prototype Rectification Prompt Learning](https://arxiv.org/abs/2404.09872)\n",
      "24. [Impact of Preference Noise on the Alignment Performance of Generative Language Models](https://arxiv.org/abs/2404.09824)\n",
      "25. [TextCoT: Zoom In for Enhanced Multimodal Text-Rich Image Understanding](https://arxiv.org/abs/2404.09797)\n",
      "26. [The Devil is in the Few Shots: Iterative Visual Knowledge Completion for Few-shot Learning](https://arxiv.org/abs/2404.09778)\n",
      "27. [nnU-Net Revisited: A Call for Rigorous Validation in 3D Medical Image Segmentation](https://arxiv.org/abs/2404.09556)\n",
      "28. [State Space Model for New-Generation Network Alternative to Transformers: A Survey](https://arxiv.org/abs/2404.09516)\n",
      "29. [Q2A: Querying Implicit Fully Continuous Feature Pyramid to Align Features for Medical Image Segmentation](https://arxiv.org/abs/2404.09472)\n",
      "30. [RankCLIP: Ranking-Consistent Language-Image Pretraining](https://arxiv.org/abs/2404.09387)\n",
      "31. [Towards Practical Tool Usage for Continually Learning LLMs](https://arxiv.org/abs/2404.09339)\n",
      "32. [Weight Copy and Low-Rank Adaptation for Few-Shot Distillation of Vision Transformers](https://arxiv.org/abs/2404.09326)\n",
      "33. [DetCLIPv3: Towards Versatile Generative Open-vocabulary Object Detection](https://arxiv.org/abs/2404.09216)\n",
      "34. [TextHawk: Exploring Efficient Fine-Grained Perception of Multimodal Large Language Models](https://arxiv.org/abs/2404.09204)\n",
      "35. [Change Guiding Network: Incorporating Change Prior to Guide Change Detection in Remote Sensing Imagery](https://arxiv.org/abs/2404.09179)\n",
      "36. [GeMQuAD : Generating Multilingual Question Answering Datasets from Large Language Models using Few Shot Learning](https://arxiv.org/abs/2404.09163)\n",
      "37. [Fusion-Mamba for Cross-modality Object Detection](https://arxiv.org/abs/2404.09146)\n",
      "38. [MING-MOE: Enhancing Medical Multi-Task Learning in Large Language Models with Sparse Mixture of Low-Rank Adapter Experts](https://arxiv.org/abs/2404.09027)\n",
      "39. [Navigating the Landscape of Large Language Models: A Comprehensive Review and Analysis of Paradigms and Fine-Tuning Strategies](https://arxiv.org/abs/2404.09022)\n",
      "40. [Intuition-aware Mixture-of-Rank-1-Experts for Parameter Efficient Finetuning](https://arxiv.org/abs/2404.08985)\n",
      "41. [MCPNet: An Interpretable Classifier via Multi-Level Concept Prototypes](https://arxiv.org/abs/2404.08968)\n",
      "42. [AMU-Tuning: Effective Logit Bias for CLIP-based Few-shot Learning](https://arxiv.org/abs/2404.08958)\n",
      "43. [Constructing and Exploring Intermediate Domains in Mixed Domain Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2404.08951)\n",
      "44. [Label-free Anomaly Detection in Aerial Agricultural Images with Masked Image Modeling](https://arxiv.org/abs/2404.08931)\n"
     ]
    }
   ],
   "source": [
    "def convert_text_in_file(file_path, cnt=1):\n",
    "    output_lines = []\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for i, line in enumerate(file):\n",
    "            url, title = line.strip().split(\" | \")\n",
    "            paper_title = title.split(\"] \")[1]\n",
    "            formatted_line = f\"{i+cnt+1}. [{paper_title}]({url})\"\n",
    "            output_lines.append(formatted_line)\n",
    "            \n",
    "\n",
    "    return \"\\n\".join(output_lines)\n",
    "\n",
    "\n",
    "# 请将 'path_to_your_file.txt' 替换为你的txt文件路径\n",
    "file_path = 'tmp.txt'\n",
    "converted_text = convert_text_in_file(file_path, cnt=3)\n",
    "print(converted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
